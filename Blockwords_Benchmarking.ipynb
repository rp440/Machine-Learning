{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0638cb5d85b046a7b1c79a04b49e9056": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_135362abdd444624904cd74f841a211d",
              "IPY_MODEL_eb1dcb48d76f4d74ae0f3f18d14aafad",
              "IPY_MODEL_ffcd30672434422886003402c10b1aef"
            ],
            "layout": "IPY_MODEL_94bdf1e557334ff59c20e937bf67b5d8"
          }
        },
        "135362abdd444624904cd74f841a211d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d50d1ad25c8041e69e00dcf9e4c7baec",
            "placeholder": "​",
            "style": "IPY_MODEL_02ba9bdd812b4af7b85464a41c8a9cc9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "eb1dcb48d76f4d74ae0f3f18d14aafad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb47906c4ce4458b4c93551831c4571",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ca0b0e0ddfa43d5b99130c754fee8ae",
            "value": 3071
          }
        },
        "ffcd30672434422886003402c10b1aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2220e9e1ada943f4a0eba20e72180297",
            "placeholder": "​",
            "style": "IPY_MODEL_4a5b94bd08d34404bc82a8b9ed70366a",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 374kB/s]"
          }
        },
        "94bdf1e557334ff59c20e937bf67b5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d50d1ad25c8041e69e00dcf9e4c7baec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ba9bdd812b4af7b85464a41c8a9cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acb47906c4ce4458b4c93551831c4571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ca0b0e0ddfa43d5b99130c754fee8ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2220e9e1ada943f4a0eba20e72180297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a5b94bd08d34404bc82a8b9ed70366a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef963482c1e84b1bb20a2e5b5b00b2c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6430e3809be34fe1b3ae3c8e928b35c3",
              "IPY_MODEL_a0d7a051f8934881a89fdb199b5eeed1",
              "IPY_MODEL_0c6885546b1f461dacf786bcfea9b178"
            ],
            "layout": "IPY_MODEL_6e7d1bb150b54cde9c2dafb96f99f50d"
          }
        },
        "6430e3809be34fe1b3ae3c8e928b35c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6fda4ac604e4509b4cedfb83f1f7d3d",
            "placeholder": "​",
            "style": "IPY_MODEL_55bc8375137840079738526334b9169f",
            "value": "tokenizer.json: 100%"
          }
        },
        "a0d7a051f8934881a89fdb199b5eeed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff74c0a70996453193e3f0d9c80f9e1f",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cde9b81a310646548c4b174612e481b1",
            "value": 7031660
          }
        },
        "0c6885546b1f461dacf786bcfea9b178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9090acf7d704f03918814a9f41943dd",
            "placeholder": "​",
            "style": "IPY_MODEL_dd2672b6a329470a8b4312b9b03a276a",
            "value": " 7.03M/7.03M [00:01&lt;00:00, 6.38MB/s]"
          }
        },
        "6e7d1bb150b54cde9c2dafb96f99f50d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fda4ac604e4509b4cedfb83f1f7d3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55bc8375137840079738526334b9169f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff74c0a70996453193e3f0d9c80f9e1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cde9b81a310646548c4b174612e481b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9090acf7d704f03918814a9f41943dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd2672b6a329470a8b4312b9b03a276a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2273f2d68e04d25a63b94cd5a822d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_135e331958fd48caac821ac9ddbef887",
              "IPY_MODEL_e18c7f6974df4813aa6f1c7226f6da68",
              "IPY_MODEL_1b5ef91638b0446aabea4c49632ad8b9"
            ],
            "layout": "IPY_MODEL_36fbc2bcd1b04b6a9e21941851e9a67c"
          }
        },
        "135e331958fd48caac821ac9ddbef887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b2b9dd5d884c618ac269dd44a9a08f",
            "placeholder": "​",
            "style": "IPY_MODEL_a893ade49a4d4d89ad0bab2a37d1a174",
            "value": "config.json: 100%"
          }
        },
        "e18c7f6974df4813aa6f1c7226f6da68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31bf4cbdfdc64834adcccd65581d23ce",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe539e2c11614662a7c662ebbdf58263",
            "value": 679
          }
        },
        "1b5ef91638b0446aabea4c49632ad8b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97b25a3d00a048b5b8ff067ffd2d1555",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1a453208a14c29925a0dfb82b13c6f",
            "value": " 679/679 [00:00&lt;00:00, 88.5kB/s]"
          }
        },
        "36fbc2bcd1b04b6a9e21941851e9a67c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b2b9dd5d884c618ac269dd44a9a08f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a893ade49a4d4d89ad0bab2a37d1a174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31bf4cbdfdc64834adcccd65581d23ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe539e2c11614662a7c662ebbdf58263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97b25a3d00a048b5b8ff067ffd2d1555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1a453208a14c29925a0dfb82b13c6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d772aa50d13f40d68e71dd8c38ae5b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4fe1509d34b746bb84ab7e02bff26eaa",
              "IPY_MODEL_47b77bc2da92493ea9660b93c037619c",
              "IPY_MODEL_0fbff518c05c4e05aa1a3c337693c84f"
            ],
            "layout": "IPY_MODEL_0fcbdc7801c54a8eb44589b1d517e662"
          }
        },
        "4fe1509d34b746bb84ab7e02bff26eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2509247ae3f640338f9fa77b1b4792ff",
            "placeholder": "​",
            "style": "IPY_MODEL_014befbbfacf41eb9ef3c8ab8567f621",
            "value": "model.safetensors: 100%"
          }
        },
        "47b77bc2da92493ea9660b93c037619c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c511b4e642c6491ea3170636556d7516",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b570508086de4906b0a130d923b90be6",
            "value": 3554214621
          }
        },
        "0fbff518c05c4e05aa1a3c337693c84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1d327f827564b44bdd20a12246fdae4",
            "placeholder": "​",
            "style": "IPY_MODEL_5502d673c8a24885a2519bde0b9517f4",
            "value": " 3.55G/3.55G [00:16&lt;00:00, 232MB/s]"
          }
        },
        "0fcbdc7801c54a8eb44589b1d517e662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2509247ae3f640338f9fa77b1b4792ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "014befbbfacf41eb9ef3c8ab8567f621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c511b4e642c6491ea3170636556d7516": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b570508086de4906b0a130d923b90be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f1d327f827564b44bdd20a12246fdae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5502d673c8a24885a2519bde0b9517f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "839c703776d84da18315f108363ebf90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1c909d9f0ff4124afba5dcb9fe70d03",
              "IPY_MODEL_ab641fec4724463cb880a7aca89a9f99",
              "IPY_MODEL_973cccc60edc4910adc2720fc803cc6b"
            ],
            "layout": "IPY_MODEL_ed34297977054ebbaf5d312c3832535d"
          }
        },
        "d1c909d9f0ff4124afba5dcb9fe70d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05ad3f663d7240a68631588552c2e861",
            "placeholder": "​",
            "style": "IPY_MODEL_7772c82f1a5d44e8ba3a49656ea6da1f",
            "value": "generation_config.json: 100%"
          }
        },
        "ab641fec4724463cb880a7aca89a9f99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcc86d44fc4348fb9a007438b309b609",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b8c4b58264a48fa92c43a074b8d866b",
            "value": 181
          }
        },
        "973cccc60edc4910adc2720fc803cc6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de2268f74b3448438a312b1e5b9667df",
            "placeholder": "​",
            "style": "IPY_MODEL_39bf00e4553f447585fa2b087dbf8f5a",
            "value": " 181/181 [00:00&lt;00:00, 21.9kB/s]"
          }
        },
        "ed34297977054ebbaf5d312c3832535d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05ad3f663d7240a68631588552c2e861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7772c82f1a5d44e8ba3a49656ea6da1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcc86d44fc4348fb9a007438b309b609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b8c4b58264a48fa92c43a074b8d866b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de2268f74b3448438a312b1e5b9667df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39bf00e4553f447585fa2b087dbf8f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd343d244efe446782349f37a8c44b1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bef1acf39d514c1b9751ffe5f815bdec",
              "IPY_MODEL_dfa82d0846484668b6fa63ed2ed96ac1",
              "IPY_MODEL_a838650b36284fa081c0b084be9efcee"
            ],
            "layout": "IPY_MODEL_1d51d7bb864448bfb3a163384e367c81"
          }
        },
        "bef1acf39d514c1b9751ffe5f815bdec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b18e3ecbf3a9462eb50a4c8a9c72a6d4",
            "placeholder": "​",
            "style": "IPY_MODEL_9db5487c8f5445b79106709c99c5192a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "dfa82d0846484668b6fa63ed2ed96ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d5825fd0ca2482ebbf5f4949e71c098",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_089b62961ccf461598f7148117975cde",
            "value": 3071
          }
        },
        "a838650b36284fa081c0b084be9efcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c452a9f94c495985dc1e932e0df56d",
            "placeholder": "​",
            "style": "IPY_MODEL_c4b25004e6b64a0ba369ef269b5c707c",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 363kB/s]"
          }
        },
        "1d51d7bb864448bfb3a163384e367c81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b18e3ecbf3a9462eb50a4c8a9c72a6d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9db5487c8f5445b79106709c99c5192a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d5825fd0ca2482ebbf5f4949e71c098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "089b62961ccf461598f7148117975cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54c452a9f94c495985dc1e932e0df56d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4b25004e6b64a0ba369ef269b5c707c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff6fd2ca788c4501a8713e37e6f332c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62f4b17812f3471185aedf006d57240f",
              "IPY_MODEL_6d13c6a275df42d89c3b58ae1fcf0012",
              "IPY_MODEL_514ca0ff292e446d87a90af42989e9ba"
            ],
            "layout": "IPY_MODEL_4701b2c98e9d495e8045217d732a9731"
          }
        },
        "62f4b17812f3471185aedf006d57240f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f9422f44f654a428dcf7546f9d8e4ba",
            "placeholder": "​",
            "style": "IPY_MODEL_fe7db0a58ba24371a03f3bdca6fca024",
            "value": "tokenizer.json: 100%"
          }
        },
        "6d13c6a275df42d89c3b58ae1fcf0012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96ee735bb780404c90e2b197ad1d90a4",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5424171c24394ece9d16cca2c74fd8b1",
            "value": 7031660
          }
        },
        "514ca0ff292e446d87a90af42989e9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5d2d77807ba4af9bf471d46b1b4e567",
            "placeholder": "​",
            "style": "IPY_MODEL_180997ffd2894b6a889b14451cefcde8",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 7.82MB/s]"
          }
        },
        "4701b2c98e9d495e8045217d732a9731": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f9422f44f654a428dcf7546f9d8e4ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7db0a58ba24371a03f3bdca6fca024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96ee735bb780404c90e2b197ad1d90a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5424171c24394ece9d16cca2c74fd8b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5d2d77807ba4af9bf471d46b1b4e567": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180997ffd2894b6a889b14451cefcde8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11914b25865e4c92abba610765c55017": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c13b9ca6aae846d786b63c9fbfeac8c5",
              "IPY_MODEL_8c0b34df0e1c4f6ea121e2361394ed5d",
              "IPY_MODEL_800be8fb509d4e9eae57bae974c41416"
            ],
            "layout": "IPY_MODEL_6084c56abebd4ae48a9824a2045a2b80"
          }
        },
        "c13b9ca6aae846d786b63c9fbfeac8c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3203e29d18314f2b8dc9cf871bbd1c0f",
            "placeholder": "​",
            "style": "IPY_MODEL_c0099b03dfac43fd8aae48faba0e7142",
            "value": "config.json: 100%"
          }
        },
        "8c0b34df0e1c4f6ea121e2361394ed5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15289e49f49a438494fe7cc6b69a9a6f",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f25addd45da34893ac9015bb455f7e92",
            "value": 679
          }
        },
        "800be8fb509d4e9eae57bae974c41416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44e0b8af0adc4f2bb79a87d05a7b4c3f",
            "placeholder": "​",
            "style": "IPY_MODEL_8f2f52ba66b0410797426fa924e21c83",
            "value": " 679/679 [00:00&lt;00:00, 77.1kB/s]"
          }
        },
        "6084c56abebd4ae48a9824a2045a2b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3203e29d18314f2b8dc9cf871bbd1c0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0099b03dfac43fd8aae48faba0e7142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15289e49f49a438494fe7cc6b69a9a6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f25addd45da34893ac9015bb455f7e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44e0b8af0adc4f2bb79a87d05a7b4c3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f2f52ba66b0410797426fa924e21c83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dbe651647e744df80001b53f374f721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd70dc58b0db4ab2830418e48e52a82d",
              "IPY_MODEL_0d3a0387b9274ac19e45e158f04a4f5a",
              "IPY_MODEL_9e4e168fe18f4e798392b76b69798422"
            ],
            "layout": "IPY_MODEL_914a8565f3d04bccb304ff8ea9194d32"
          }
        },
        "dd70dc58b0db4ab2830418e48e52a82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd67825a4a249478bddcbc2a6181704",
            "placeholder": "​",
            "style": "IPY_MODEL_5a0ad8426a4f4676b093fea8ddef7c13",
            "value": "model.safetensors: 100%"
          }
        },
        "0d3a0387b9274ac19e45e158f04a4f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adb9353abebf4a6cad0882a172e876bc",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e74d86638074d28954e237067b53a73",
            "value": 3554214621
          }
        },
        "9e4e168fe18f4e798392b76b69798422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b31d28a92fd3499c910007506e34453b",
            "placeholder": "​",
            "style": "IPY_MODEL_ec68de18b0de45d4939ab24e981d15cd",
            "value": " 3.55G/3.55G [00:16&lt;00:00, 244MB/s]"
          }
        },
        "914a8565f3d04bccb304ff8ea9194d32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd67825a4a249478bddcbc2a6181704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a0ad8426a4f4676b093fea8ddef7c13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adb9353abebf4a6cad0882a172e876bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e74d86638074d28954e237067b53a73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b31d28a92fd3499c910007506e34453b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec68de18b0de45d4939ab24e981d15cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "461fea13ae194bf290ea082f202966b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8413afd7b78949a6bcec1c68939c6b8a",
              "IPY_MODEL_0ce75217dcde4e1ea61b57499696abde",
              "IPY_MODEL_7339d79da8784287995a204ce9a4a656"
            ],
            "layout": "IPY_MODEL_8a023b45f8064d4fb6cf3631f6cd3b53"
          }
        },
        "8413afd7b78949a6bcec1c68939c6b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb7ac77e2bdd449b80f70031b63305ba",
            "placeholder": "​",
            "style": "IPY_MODEL_6bb2e2112a40423d863c9d506af31d07",
            "value": "generation_config.json: 100%"
          }
        },
        "0ce75217dcde4e1ea61b57499696abde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e3bb8247ccd498cae329a91b67471dd",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_109bfe68d1684c1aadecd326ea186103",
            "value": 181
          }
        },
        "7339d79da8784287995a204ce9a4a656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82b4f7e581414ffdbaa8be2fdba87fb3",
            "placeholder": "​",
            "style": "IPY_MODEL_57767e6c8cc2480eb56208689623b468",
            "value": " 181/181 [00:00&lt;00:00, 18.4kB/s]"
          }
        },
        "8a023b45f8064d4fb6cf3631f6cd3b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb7ac77e2bdd449b80f70031b63305ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb2e2112a40423d863c9d506af31d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e3bb8247ccd498cae329a91b67471dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109bfe68d1684c1aadecd326ea186103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82b4f7e581414ffdbaa8be2fdba87fb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57767e6c8cc2480eb56208689623b468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64a1a93826484a69955d47b4dfeaba6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a801f4f4f90c4cc4815a5f18e9dd0b58",
              "IPY_MODEL_6d4808427e3142d2ac2702ddcfdce9d8",
              "IPY_MODEL_1b41db0dd39d40bd8d07074036bac250"
            ],
            "layout": "IPY_MODEL_13b4ddddf3f94fb3b9debfab21951538"
          }
        },
        "a801f4f4f90c4cc4815a5f18e9dd0b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf7515b47a104809a8b8c6059f2fbd14",
            "placeholder": "​",
            "style": "IPY_MODEL_f2f148fc4a6b48db9426833cb92b2018",
            "value": "README.md: 100%"
          }
        },
        "6d4808427e3142d2ac2702ddcfdce9d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfc43c1efc8f49e49d2b28547d168f0c",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05f38c0cb153435d8f72fe41ad1c1df7",
            "value": 7940
          }
        },
        "1b41db0dd39d40bd8d07074036bac250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52ad18a33e3740fa99984262e35f6d60",
            "placeholder": "​",
            "style": "IPY_MODEL_3de282c27bd84032be34d290ce53b0d4",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 991kB/s]"
          }
        },
        "13b4ddddf3f94fb3b9debfab21951538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf7515b47a104809a8b8c6059f2fbd14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2f148fc4a6b48db9426833cb92b2018": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfc43c1efc8f49e49d2b28547d168f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05f38c0cb153435d8f72fe41ad1c1df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52ad18a33e3740fa99984262e35f6d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3de282c27bd84032be34d290ce53b0d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12d0277a06084a36b6d40fd88ca50418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb77a68187714a91a9feec676a2fe01d",
              "IPY_MODEL_519c7bf1df494f03b8db6c096f10e0e0",
              "IPY_MODEL_cc081272143f4430a0a6d5920b90b6c0"
            ],
            "layout": "IPY_MODEL_b19b071b9723435094c45ef760b6e074"
          }
        },
        "cb77a68187714a91a9feec676a2fe01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cdedb23f144e8da05da8a19a6fec2d",
            "placeholder": "​",
            "style": "IPY_MODEL_e732c042ccba4727afe80fccfceaabc1",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "519c7bf1df494f03b8db6c096f10e0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf3631ffe774cf9812bacce7262533e",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f39470adb7b49f6955129252c756792",
            "value": 2306545
          }
        },
        "cc081272143f4430a0a6d5920b90b6c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b07b4c9c9134a5eb1678598ddf4da83",
            "placeholder": "​",
            "style": "IPY_MODEL_191a251d35b94e7bb9991a62219a826d",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 37.0MB/s]"
          }
        },
        "b19b071b9723435094c45ef760b6e074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cdedb23f144e8da05da8a19a6fec2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e732c042ccba4727afe80fccfceaabc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bf3631ffe774cf9812bacce7262533e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f39470adb7b49f6955129252c756792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b07b4c9c9134a5eb1678598ddf4da83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191a251d35b94e7bb9991a62219a826d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a504479262e94a459d9f3bb19448269c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41260f9d2f854389a35f18a8488e357b",
              "IPY_MODEL_55466afcd80648019af1f170835475c6",
              "IPY_MODEL_52c8ac63dea94b54acd47dfbd956a1a3"
            ],
            "layout": "IPY_MODEL_5bd81d2972f6433aa926a8b65762def1"
          }
        },
        "41260f9d2f854389a35f18a8488e357b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1a0482df424161879bbd3a20b2eed1",
            "placeholder": "​",
            "style": "IPY_MODEL_87b04eefe1fe4b41baa173928d81df7a",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "55466afcd80648019af1f170835475c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84178162a8db48e0abc60be1eee05546",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d7ccfc10746f41349769307962e22a47",
            "value": 419088
          }
        },
        "52c8ac63dea94b54acd47dfbd956a1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c55112ec224c2cb6362c35d26d24b4",
            "placeholder": "​",
            "style": "IPY_MODEL_98dac2f0f81145ce8d81048b713f636e",
            "value": " 419k/419k [00:00&lt;00:00, 49.5MB/s]"
          }
        },
        "5bd81d2972f6433aa926a8b65762def1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b1a0482df424161879bbd3a20b2eed1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b04eefe1fe4b41baa173928d81df7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84178162a8db48e0abc60be1eee05546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7ccfc10746f41349769307962e22a47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0c55112ec224c2cb6362c35d26d24b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98dac2f0f81145ce8d81048b713f636e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d82d549634b4614a27954a2dc102b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fcddc8268024d8abc4d2a70b6a94966",
              "IPY_MODEL_5c55922f0d1b4cb48ba148a553c4c857",
              "IPY_MODEL_babda70d1d5d49ebac15d33191d40a29"
            ],
            "layout": "IPY_MODEL_8f1c5440328f4b9498f8393bf605b021"
          }
        },
        "3fcddc8268024d8abc4d2a70b6a94966": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad10ac4db7d04603b877eb6ad86a6437",
            "placeholder": "​",
            "style": "IPY_MODEL_389d2b81257a4db8991acdafc7a3c00b",
            "value": "Generating train split: 100%"
          }
        },
        "5c55922f0d1b4cb48ba148a553c4c857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0381c3fb42c248f7af6dc14ce5b582d6",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_164d28a42b4647cda3d4d45a23bf89cf",
            "value": 7473
          }
        },
        "babda70d1d5d49ebac15d33191d40a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_635683a3f7a34794a0a2184192e8bbee",
            "placeholder": "​",
            "style": "IPY_MODEL_6261f6f1a4d743faac04281c0ff563ab",
            "value": " 7473/7473 [00:00&lt;00:00, 136421.35 examples/s]"
          }
        },
        "8f1c5440328f4b9498f8393bf605b021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad10ac4db7d04603b877eb6ad86a6437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "389d2b81257a4db8991acdafc7a3c00b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0381c3fb42c248f7af6dc14ce5b582d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "164d28a42b4647cda3d4d45a23bf89cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "635683a3f7a34794a0a2184192e8bbee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6261f6f1a4d743faac04281c0ff563ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331ebd97d4ea4902875b8976a0db4062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6056aebac181427b9ecea05210d14b07",
              "IPY_MODEL_0c85af66a1694ce6a2db40b44a923208",
              "IPY_MODEL_97b36e7cc4384687bce2f72ccbb933f8"
            ],
            "layout": "IPY_MODEL_187c7321268347b88dd5e468bf86df07"
          }
        },
        "6056aebac181427b9ecea05210d14b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39f8a993f6a942b0971608ebe538003d",
            "placeholder": "​",
            "style": "IPY_MODEL_eae2d1c12c4e4088b36a1c358ba18d0b",
            "value": "Generating test split: 100%"
          }
        },
        "0c85af66a1694ce6a2db40b44a923208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5373edae1d6d44c3b83d537501ac883e",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fe302a7098b348d282cbf6549cb131c3",
            "value": 1319
          }
        },
        "97b36e7cc4384687bce2f72ccbb933f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45741fcd9d48466f97ad0b6e1ec0646b",
            "placeholder": "​",
            "style": "IPY_MODEL_4fc6129aaf0947daa673ed2f5f9aa9ea",
            "value": " 1319/1319 [00:00&lt;00:00, 93219.32 examples/s]"
          }
        },
        "187c7321268347b88dd5e468bf86df07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39f8a993f6a942b0971608ebe538003d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eae2d1c12c4e4088b36a1c358ba18d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5373edae1d6d44c3b83d537501ac883e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe302a7098b348d282cbf6549cb131c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "45741fcd9d48466f97ad0b6e1ec0646b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fc6129aaf0947daa673ed2f5f9aa9ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b618ddb86ac14b3b9078e0ca46eaa628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b945717644546f38b7e71fca23d7bfa",
              "IPY_MODEL_05929196d983400f87e3b13e4fd086fd",
              "IPY_MODEL_60566639033549809e118e96eff8d460"
            ],
            "layout": "IPY_MODEL_0daa4dd3a03446c3adb7de013f7d569b"
          }
        },
        "5b945717644546f38b7e71fca23d7bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f262ba2ea734e439e423080b0e8c6d6",
            "placeholder": "​",
            "style": "IPY_MODEL_23a0a2ad5a7a41e1802add690a312c8c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "05929196d983400f87e3b13e4fd086fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e255b016ef544ae9b297e08b953d42a",
            "max": 3071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3056436c9f05425db18d8430d5effde0",
            "value": 3071
          }
        },
        "60566639033549809e118e96eff8d460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d804e76fcea4767884b15f3683c25ec",
            "placeholder": "​",
            "style": "IPY_MODEL_fbe518932528436b85531d7b0e1126ae",
            "value": " 3.07k/3.07k [00:00&lt;00:00, 361kB/s]"
          }
        },
        "0daa4dd3a03446c3adb7de013f7d569b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f262ba2ea734e439e423080b0e8c6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23a0a2ad5a7a41e1802add690a312c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e255b016ef544ae9b297e08b953d42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3056436c9f05425db18d8430d5effde0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d804e76fcea4767884b15f3683c25ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe518932528436b85531d7b0e1126ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d7bb1f02e346a2881a078f4577f7a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_de420b16e2554bc282e2ec9ae4e3b15d",
              "IPY_MODEL_337f50a93b094383b922d9264ceff83e",
              "IPY_MODEL_28453b54ac204ca4aa35d34d4456f242"
            ],
            "layout": "IPY_MODEL_7429fd93cabe40ceb96032680ad1c43f"
          }
        },
        "de420b16e2554bc282e2ec9ae4e3b15d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2576a8054e64192b3845d52291639a7",
            "placeholder": "​",
            "style": "IPY_MODEL_677107d1348c4e0b8fe22e9306f7c12f",
            "value": "tokenizer.json: 100%"
          }
        },
        "337f50a93b094383b922d9264ceff83e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8708d1b6934e18bafdb850c1a5e91a",
            "max": 7031660,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_07de03ce130d46d4b99b1afe8499d08e",
            "value": 7031660
          }
        },
        "28453b54ac204ca4aa35d34d4456f242": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc6733c82d5046b6b2aa114c5c6d2817",
            "placeholder": "​",
            "style": "IPY_MODEL_982cac743c964534b6e570f533b7904a",
            "value": " 7.03M/7.03M [00:00&lt;00:00, 24.1MB/s]"
          }
        },
        "7429fd93cabe40ceb96032680ad1c43f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2576a8054e64192b3845d52291639a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "677107d1348c4e0b8fe22e9306f7c12f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae8708d1b6934e18bafdb850c1a5e91a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07de03ce130d46d4b99b1afe8499d08e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc6733c82d5046b6b2aa114c5c6d2817": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "982cac743c964534b6e570f533b7904a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "434a2d7aa1a945c6938a9f15e0a0ba59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24301c71c24e49bd9b75911dedb0f40a",
              "IPY_MODEL_71ddb00f4a9944bf98012a013f8791d5",
              "IPY_MODEL_bb65ec63d7a44899a3ca91e98c24710f"
            ],
            "layout": "IPY_MODEL_49cda68d57a74b3fb2e4318b94ebee82"
          }
        },
        "24301c71c24e49bd9b75911dedb0f40a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_061b72cd47884fdc994e945ea4beea7f",
            "placeholder": "​",
            "style": "IPY_MODEL_961953911fc54b9eb4fd2492210f7419",
            "value": "config.json: 100%"
          }
        },
        "71ddb00f4a9944bf98012a013f8791d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb97ab4c51f441f4b5dc28022f65b3e2",
            "max": 679,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ebbca9bb868445fb10b52cb9edf58af",
            "value": 679
          }
        },
        "bb65ec63d7a44899a3ca91e98c24710f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_626c5a03a56e4ea7a3ef6c4a8029bd54",
            "placeholder": "​",
            "style": "IPY_MODEL_568c94b453d7491e8f9176c08a97e856",
            "value": " 679/679 [00:00&lt;00:00, 87.5kB/s]"
          }
        },
        "49cda68d57a74b3fb2e4318b94ebee82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061b72cd47884fdc994e945ea4beea7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961953911fc54b9eb4fd2492210f7419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb97ab4c51f441f4b5dc28022f65b3e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebbca9bb868445fb10b52cb9edf58af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "626c5a03a56e4ea7a3ef6c4a8029bd54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568c94b453d7491e8f9176c08a97e856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26c3572232904595b4cd8774e9c292c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3fc9968ebcb04384a2a947dae8e508e2",
              "IPY_MODEL_1c019cd7594c42beb053f1b04d752e60",
              "IPY_MODEL_0a461c13470248409daee7cdef58f98f"
            ],
            "layout": "IPY_MODEL_9d9d30cf32bd41d5a3406d493c293df7"
          }
        },
        "3fc9968ebcb04384a2a947dae8e508e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_460c13ffa55e46609f383d200286b7f7",
            "placeholder": "​",
            "style": "IPY_MODEL_17b561fc4aa44dfcbc068546639ee07d",
            "value": "model.safetensors: 100%"
          }
        },
        "1c019cd7594c42beb053f1b04d752e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d70042bd204e89a93a99843e9e0261",
            "max": 3554214621,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_400fe213db9b4f7eb53c1aa06827ab84",
            "value": 3554214621
          }
        },
        "0a461c13470248409daee7cdef58f98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c24b739a64cd4cf098ceb80f3ae515b4",
            "placeholder": "​",
            "style": "IPY_MODEL_cd75a9bbd3504de4bdce7a658988bb0d",
            "value": " 3.55G/3.55G [00:16&lt;00:00, 210MB/s]"
          }
        },
        "9d9d30cf32bd41d5a3406d493c293df7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "460c13ffa55e46609f383d200286b7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17b561fc4aa44dfcbc068546639ee07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d70042bd204e89a93a99843e9e0261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400fe213db9b4f7eb53c1aa06827ab84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c24b739a64cd4cf098ceb80f3ae515b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd75a9bbd3504de4bdce7a658988bb0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d0bef810e964a25adb3ddafcf006f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_778da6ec30d14d6b8320f4d8b7d55ae3",
              "IPY_MODEL_2db6a7edfd574d078e55d64f0261b8da",
              "IPY_MODEL_dbd63ab1bbf44234813b8c8df1a20be0"
            ],
            "layout": "IPY_MODEL_838b49b9175f4752a8c14895079b25d1"
          }
        },
        "778da6ec30d14d6b8320f4d8b7d55ae3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17fcd41a1deb4d3187324b2599faa1f9",
            "placeholder": "​",
            "style": "IPY_MODEL_658c259a989f493f8c9f02683693a5a2",
            "value": "generation_config.json: 100%"
          }
        },
        "2db6a7edfd574d078e55d64f0261b8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a8ea004c2a74d16bee8999d682e74e4",
            "max": 181,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53f7ccbb9b704b18959238034c8990c3",
            "value": 181
          }
        },
        "dbd63ab1bbf44234813b8c8df1a20be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79966d9f9b80419d910ed3098b441719",
            "placeholder": "​",
            "style": "IPY_MODEL_4f4a3d3f3e214375b285dc6e4ed31024",
            "value": " 181/181 [00:00&lt;00:00, 23.9kB/s]"
          }
        },
        "838b49b9175f4752a8c14895079b25d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17fcd41a1deb4d3187324b2599faa1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "658c259a989f493f8c9f02683693a5a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a8ea004c2a74d16bee8999d682e74e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53f7ccbb9b704b18959238034c8990c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79966d9f9b80419d910ed3098b441719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f4a3d3f3e214375b285dc6e4ed31024": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01e5d07ac38947fb8cfac5d7dac780e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9f8c0f2420ec4931af19be7df0ea1291",
              "IPY_MODEL_1891f8d02d3a44248ad03d73e082f3f4",
              "IPY_MODEL_086a72c4868043e2bfea5deb8369b82f"
            ],
            "layout": "IPY_MODEL_835640eb84614ae2948ab4429880ce75"
          }
        },
        "9f8c0f2420ec4931af19be7df0ea1291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d7d71d1b045436496c78418a7450748",
            "placeholder": "​",
            "style": "IPY_MODEL_a9805dc407ef44a6a14cccd3cb3189a9",
            "value": "README.md: 100%"
          }
        },
        "1891f8d02d3a44248ad03d73e082f3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb930387f16148eba75d088dff54e582",
            "max": 7940,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee8ec5bfcccb408bae39ba8ab5fcfafd",
            "value": 7940
          }
        },
        "086a72c4868043e2bfea5deb8369b82f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_877f683fd9594b708248877161893d43",
            "placeholder": "​",
            "style": "IPY_MODEL_c9098791327c4d42a148d01be33047b3",
            "value": " 7.94k/7.94k [00:00&lt;00:00, 987kB/s]"
          }
        },
        "835640eb84614ae2948ab4429880ce75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d7d71d1b045436496c78418a7450748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9805dc407ef44a6a14cccd3cb3189a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb930387f16148eba75d088dff54e582": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8ec5bfcccb408bae39ba8ab5fcfafd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "877f683fd9594b708248877161893d43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9098791327c4d42a148d01be33047b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67a0dc07b9cc43a3a8037146ac80cc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d84cfe1e306480ca2a583727493c974",
              "IPY_MODEL_eced3593afa947398d4a183532787bac",
              "IPY_MODEL_ec80074d1275435bb342eddec48a7e40"
            ],
            "layout": "IPY_MODEL_dfc647e676ee4a688233de567cc46458"
          }
        },
        "0d84cfe1e306480ca2a583727493c974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e24a3eadd41c499a95d8f04ace748b94",
            "placeholder": "​",
            "style": "IPY_MODEL_12362137b47649e09834f2fb75f2e97c",
            "value": "train-00000-of-00001.parquet: 100%"
          }
        },
        "eced3593afa947398d4a183532787bac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50895d27a505421784cb3c9fe4e006af",
            "max": 2306545,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6056f62f65c4a76989b2d6646a30be6",
            "value": 2306545
          }
        },
        "ec80074d1275435bb342eddec48a7e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b01b57576d41f1bfc973807be3527a",
            "placeholder": "​",
            "style": "IPY_MODEL_efb224d762aa4fdab4dbcb62cc32e278",
            "value": " 2.31M/2.31M [00:00&lt;00:00, 55.0MB/s]"
          }
        },
        "dfc647e676ee4a688233de567cc46458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e24a3eadd41c499a95d8f04ace748b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12362137b47649e09834f2fb75f2e97c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50895d27a505421784cb3c9fe4e006af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6056f62f65c4a76989b2d6646a30be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9b01b57576d41f1bfc973807be3527a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efb224d762aa4fdab4dbcb62cc32e278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfda57e0907442c98c4fa0866058975c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe34075248024515bd996a2293ece72e",
              "IPY_MODEL_1b74377d2f1740f9a9e424a096cdb6a9",
              "IPY_MODEL_b93549cfd222478fbcab758545d7d92e"
            ],
            "layout": "IPY_MODEL_d5f7c10e4c5e45d0889420182f440699"
          }
        },
        "fe34075248024515bd996a2293ece72e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb0dfaad67f4da997c787808b7f5c48",
            "placeholder": "​",
            "style": "IPY_MODEL_911bd745766748758f8955ac38fcc758",
            "value": "test-00000-of-00001.parquet: 100%"
          }
        },
        "1b74377d2f1740f9a9e424a096cdb6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_673eb025bd064827b53f5a6c63a573d0",
            "max": 419088,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52bff0fcdb1c47fba7b79d583d4ac443",
            "value": 419088
          }
        },
        "b93549cfd222478fbcab758545d7d92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f3de2642124b0eab8e4a8d8f1b57dd",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba06121b6f64c2d9153821e8dd4c27a",
            "value": " 419k/419k [00:00&lt;00:00, 43.0MB/s]"
          }
        },
        "d5f7c10e4c5e45d0889420182f440699": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb0dfaad67f4da997c787808b7f5c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "911bd745766748758f8955ac38fcc758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "673eb025bd064827b53f5a6c63a573d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bff0fcdb1c47fba7b79d583d4ac443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07f3de2642124b0eab8e4a8d8f1b57dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba06121b6f64c2d9153821e8dd4c27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f92721234ae84e11b0b16b84d1ff217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b77bca8be82c4451afc8dbf758d781ff",
              "IPY_MODEL_73ae8dfd8c2f4f89808f1a337746e755",
              "IPY_MODEL_0abddaa683f44bea912c4c5e2b45d91e"
            ],
            "layout": "IPY_MODEL_313d70dc06654636a9c64646a8c5290d"
          }
        },
        "b77bca8be82c4451afc8dbf758d781ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05c996940e7e41ecae1b828fff1abd81",
            "placeholder": "​",
            "style": "IPY_MODEL_b496b0449a414ea1bbe36825cfcd2b59",
            "value": "Generating train split: 100%"
          }
        },
        "73ae8dfd8c2f4f89808f1a337746e755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f191cd417ab4333992c821d439a7a62",
            "max": 7473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_653eba1f5dc843f48951ae4f0d9a1058",
            "value": 7473
          }
        },
        "0abddaa683f44bea912c4c5e2b45d91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15b51a0f84314383aadda1eeb753b329",
            "placeholder": "​",
            "style": "IPY_MODEL_322c2cdce4ff453eb6c4b84f4706bc48",
            "value": " 7473/7473 [00:00&lt;00:00, 123797.47 examples/s]"
          }
        },
        "313d70dc06654636a9c64646a8c5290d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c996940e7e41ecae1b828fff1abd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b496b0449a414ea1bbe36825cfcd2b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f191cd417ab4333992c821d439a7a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653eba1f5dc843f48951ae4f0d9a1058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "15b51a0f84314383aadda1eeb753b329": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "322c2cdce4ff453eb6c4b84f4706bc48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cd25d673726418bbb8bb4cc333d78ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62afb66abed04c79a80e5ec358c23731",
              "IPY_MODEL_faba9bd2538345cb8748f6b8b7e06b2d",
              "IPY_MODEL_5b8a210756e349d6b92b7ed5229c0272"
            ],
            "layout": "IPY_MODEL_cdcdd14483bc4bb7a6b66d74b4e46d19"
          }
        },
        "62afb66abed04c79a80e5ec358c23731": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f64612f065e14f7abf22e8587033c057",
            "placeholder": "​",
            "style": "IPY_MODEL_73b16be897fb4855aa9f79eb2b96f499",
            "value": "Generating test split: 100%"
          }
        },
        "faba9bd2538345cb8748f6b8b7e06b2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b189e044e9bf43908bde7a52743faed4",
            "max": 1319,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_191ee79266de486480dd3696040ca04f",
            "value": 1319
          }
        },
        "5b8a210756e349d6b92b7ed5229c0272": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc6cde09fb06496e808d0fa0749ec88d",
            "placeholder": "​",
            "style": "IPY_MODEL_ccc10687c8c444989ee9cc6f0e434942",
            "value": " 1319/1319 [00:00&lt;00:00, 96931.82 examples/s]"
          }
        },
        "cdcdd14483bc4bb7a6b66d74b4e46d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f64612f065e14f7abf22e8587033c057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73b16be897fb4855aa9f79eb2b96f499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b189e044e9bf43908bde7a52743faed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191ee79266de486480dd3696040ca04f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc6cde09fb06496e808d0fa0749ec88d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc10687c8c444989ee9cc6f0e434942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXBZlhaF_FmG",
        "outputId": "aa0c1c5d-f00c-479b-b99c-03b5c7afccd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "LXnydcb88DLV",
        "outputId": "813a77b3-a8cf-43d2-a964-ac5c5e25e12e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'CustomLLM' from 'deepeval.models' (/usr/local/lib/python3.11/dist-packages/deepeval/models/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3ae9820991e4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmarks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCustomLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Mount Google Drive for saving results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'CustomLLM' from 'deepeval.models' (/usr/local/lib/python3.11/dist-packages/deepeval/models/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# DeepSeek-R1-Distill-Qwen-1.5B GSM8K Benchmark with DeepEval and Token Blocking\n",
        "\n",
        "# Install required packages\n",
        "# !pip install -q transformers torch matplotlib pandas tqdm accelerate deepeval\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "from threading import Thread\n",
        "import gc\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from deepeval.benchmarks import GSM8K\n",
        "from deepeval.models import CustomLLM\n",
        "\n",
        "# Mount Google Drive for saving results\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create results directory in Google Drive\n",
        "base_dir = \"/content/drive/MyDrive/deepseek_gsm8k_results\"\n",
        "results_dir = os.path.join(base_dir, \"block_words_benchmark\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "# Create a timestamp for this run\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define the words to block (using only the original set from your code)\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words_to_block):\n",
        "    \"\"\"Get token IDs for words we want to block\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words_to_block:\n",
        "        # Get all possible token IDs for the word\n",
        "        word_tokens = tokenizer.encode(\" \" + word, add_special_tokens=False)\n",
        "        word_tokens.extend(tokenizer.encode(word, add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(\" \" + word.capitalize(), add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(word.capitalize(), add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(\" \" + word.upper(), add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(word.upper(), add_special_tokens=False))\n",
        "        blocked_ids.extend(word_tokens)\n",
        "\n",
        "    # Print the blocked words and their token IDs\n",
        "    print(f\"\\nBlocking these words: {words_to_block}\")\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "\n",
        "    # Print token representations for debugging\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "\n",
        "    return list(set(blocked_ids))\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"Custom logits processor for token blocking\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        # Create a mask of blocked tokens\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        # Set scores to -inf where mask is True\n",
        "        scores = scores.masked_fill(mask, float('-inf'))\n",
        "        return scores\n",
        "\n",
        "class TokenBlockingLLM(CustomLLM):\n",
        "    \"\"\"Custom LLM with token blocking for use with deepeval\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None, temperature=0.7, top_p=0.9, top_k=40, max_tokens=512, save_dir=None):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        # Track statistics\n",
        "        self.responses = []\n",
        "        self.generation_times = []\n",
        "        self.token_counts = []\n",
        "\n",
        "    def generate(self, prompt):\n",
        "        # Start timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Prepare input\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        input_tokens = inputs['input_ids'][0].cpu().tolist()\n",
        "\n",
        "        # Create logits processor if blocked tokens are provided\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        # Create streamer for token-by-token output\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "\n",
        "        # Prepare generation kwargs\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        # Collect streamed tokens\n",
        "        generated_text = \"\"\n",
        "        output_tokens = []\n",
        "\n",
        "        # Process streamed tokens\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "            # Approximate token tracking\n",
        "            new_token_ids = self.tokenizer.encode(new_text, add_special_tokens=False)\n",
        "            output_tokens.extend(new_token_ids)\n",
        "\n",
        "        # End timer\n",
        "        generation_time = time.time() - start_time\n",
        "\n",
        "        # Record stats\n",
        "        self.responses.append({\n",
        "            'prompt': prompt,\n",
        "            'response': generated_text,\n",
        "            'generation_time': generation_time,\n",
        "            'tokens': len(output_tokens)\n",
        "        })\n",
        "\n",
        "        self.generation_times.append(generation_time)\n",
        "        self.token_counts.append(len(output_tokens))\n",
        "\n",
        "        # Save response if directory is provided\n",
        "        if self.save_dir:\n",
        "            # Create a filename based on prompt hash (to identify the same problems across runs)\n",
        "            import hashlib\n",
        "            prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]\n",
        "            response_id = f\"response_{prompt_hash}_{'blocked' if self.blocked_token_ids is not None else 'unblocked'}\"\n",
        "\n",
        "            response_data = {\n",
        "                'prompt': prompt,\n",
        "                'response': generated_text,\n",
        "                'generation_time': generation_time,\n",
        "                'tokens': len(output_tokens),\n",
        "                'token_blocking': self.blocked_token_ids is not None\n",
        "            }\n",
        "\n",
        "            response_filepath = os.path.join(self.save_dir, f\"{response_id}.json\")\n",
        "            with open(response_filepath, 'w') as f:\n",
        "                json.dump(response_data, f, indent=2)\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        \"\"\"Get average statistics from all generated responses\"\"\"\n",
        "        if not self.generation_times:\n",
        "            return {'avg_time': 0, 'avg_tokens': 0}\n",
        "\n",
        "        return {\n",
        "            'avg_time': sum(self.generation_times) / len(self.generation_times),\n",
        "            'avg_tokens': sum(self.token_counts) / len(self.token_counts)\n",
        "        }\n",
        "\n",
        "# Load the DeepSeek model\n",
        "print(\"Loading DeepSeek-R1-Distill-Qwen-1.5B model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,  # Use half precision to fit in GPU memory\n",
        "    device_map=\"auto\"  # Automatically determine device mapping\n",
        ")\n",
        "\n",
        "# @title Run GSM8K Benchmark with DeepEval (With vs. Without Blocking)\n",
        "# @markdown Configure the benchmark parameters\n",
        "\n",
        "# @markdown ## Number of problems to test\n",
        "n_problems = 50  # @param {type:\"slider\", min:10, max:200, step:10}\n",
        "n_shots = 1  # @param {type:\"slider\", min:0, max:8, step:1}\n",
        "\n",
        "# @markdown ## Generation parameters\n",
        "temperature = 0.7  # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "top_p = 0.9  # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "top_k = 40  # @param {type:\"number\"}\n",
        "max_tokens = 4000  # @param {type:\"number\"}\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_token_ids = torch.tensor(\n",
        "    get_blocked_token_ids(tokenizer, words_to_block),\n",
        "    device=model.device\n",
        ")\n",
        "\n",
        "# Run benchmark without token blocking\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "# Create custom LLM without token blocking\n",
        "llm_unblocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,  # No blocking\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k,\n",
        "    max_tokens=max_tokens,\n",
        "    save_dir=run_dir\n",
        ")\n",
        "\n",
        "# Initialize benchmark\n",
        "benchmark_unblocked = GSM8K(\n",
        "    n_problems=n_problems,\n",
        "    n_shots=n_shots,\n",
        "    enable_cot=enable_cot\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "benchmark_unblocked.evaluate(model=llm_unblocked)\n",
        "\n",
        "# Get statistics\n",
        "unblocked_score = benchmark_unblocked.overall_score\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "# Clear GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Run benchmark with token blocking\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "# Create custom LLM with token blocking\n",
        "llm_blocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,  # With blocking\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k,\n",
        "    max_tokens=max_tokens,\n",
        "    save_dir=run_dir\n",
        ")\n",
        "\n",
        "# Initialize benchmark\n",
        "benchmark_blocked = GSM8K(\n",
        "    n_problems=n_problems,\n",
        "    n_shots=n_shots,\n",
        "    enable_cot=enable_cot\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "benchmark_blocked.evaluate(model=llm_blocked)\n",
        "\n",
        "# Get statistics\n",
        "blocked_score = benchmark_blocked.overall_score\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# Create summary report\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'n_problems': n_problems,\n",
        "    'n_shots': n_shots,\n",
        "    'enable_cot': enable_cot,\n",
        "    'words_blocked': words_to_block,\n",
        "    'generation_params': {\n",
        "        'temperature': temperature,\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'max_tokens': max_tokens\n",
        "    },\n",
        "    'unblocked': {\n",
        "        'score': unblocked_score,\n",
        "        'avg_time': unblocked_stats['avg_time'],\n",
        "        'avg_tokens': unblocked_stats['avg_tokens']\n",
        "    },\n",
        "    'blocked': {\n",
        "        'score': blocked_score,\n",
        "        'avg_time': blocked_stats['avg_time'],\n",
        "        'avg_tokens': blocked_stats['avg_tokens']\n",
        "    },\n",
        "    'difference': {\n",
        "        'score': blocked_score - unblocked_score,\n",
        "        'time': blocked_stats['avg_time'] - unblocked_stats['avg_time'],\n",
        "        'tokens': blocked_stats['avg_tokens'] - unblocked_stats['avg_tokens']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary to file\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "# Create dataframe for display\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        'Method': 'Without Blocking',\n",
        "        'GSM8K Score (%)': unblocked_score,\n",
        "        'Avg Time (s)': unblocked_stats['avg_time'],\n",
        "        'Avg Tokens': unblocked_stats['avg_tokens']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'With Blocking',\n",
        "        'GSM8K Score (%)': blocked_score,\n",
        "        'Avg Time (s)': blocked_stats['avg_time'],\n",
        "        'Avg Tokens': blocked_stats['avg_tokens']\n",
        "    }\n",
        "])\n",
        "\n",
        "# Display results\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nBlocked words: {words_to_block}\")\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "print(f\"Difference in avg time: {blocked_stats['avg_time'] - unblocked_stats['avg_time']:.2f} seconds\")\n",
        "print(f\"Difference in avg tokens: {blocked_stats['avg_tokens'] - unblocked_stats['avg_tokens']:.1f} tokens\")\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score], color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n(DeepSeek-R1-Distill-Qwen-1.5B)')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Plot avg time\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_stats['avg_time'], blocked_stats['avg_time']], color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Generation Time per Problem')\n",
        "plt.ylabel('Time (seconds)')\n",
        "\n",
        "# Plot avg tokens\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_stats['avg_tokens'], blocked_stats['avg_tokens']], color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Tokens Generated per Problem')\n",
        "plt.ylabel('Tokens')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DeepSeek-R1-Distill-Qwen-1.5B GSM8K Benchmark with DeepEval and Token Blocking\n",
        "\n",
        "# Install required packages\n",
        "# !pip install -q transformers torch matplotlib pandas tqdm accelerate\n",
        "!pip install -q deepeval --upgrade\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "import time\n",
        "import re\n",
        "import json\n",
        "from datetime import datetime\n",
        "import os\n",
        "from threading import Thread\n",
        "import gc\n",
        "from tqdm.notebook import tqdm\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from deepeval.benchmarks import GSM8K\n",
        "from deepeval.models.base_model import BaseModel  # Use BaseModel instead of CustomLLM\n",
        "\n",
        "# Mount Google Drive for saving results\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Create results directory in Google Drive\n",
        "base_dir = \"/content/drive/MyDrive/deepseek_gsm8k_results\"\n",
        "results_dir = os.path.join(base_dir, \"block_words_benchmark\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "# Create a timestamp for this run\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define the words to block (using only the original set from your code)\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words_to_block):\n",
        "    \"\"\"Get token IDs for words we want to block\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words_to_block:\n",
        "        # Get all possible token IDs for the word\n",
        "        word_tokens = tokenizer.encode(\" \" + word, add_special_tokens=False)\n",
        "        word_tokens.extend(tokenizer.encode(word, add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(\" \" + word.capitalize(), add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(word.capitalize(), add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(\" \" + word.upper(), add_special_tokens=False))\n",
        "        word_tokens.extend(tokenizer.encode(word.upper(), add_special_tokens=False))\n",
        "        blocked_ids.extend(word_tokens)\n",
        "\n",
        "    # Print the blocked words and their token IDs\n",
        "    print(f\"\\nBlocking these words: {words_to_block}\")\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "\n",
        "    # Print token representations for debugging\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "\n",
        "    return list(set(blocked_ids))\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"Custom logits processor for token blocking\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        # Create a mask of blocked tokens\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        # Set scores to -inf where mask is True\n",
        "        scores = scores.masked_fill(mask, float('-inf'))\n",
        "        return scores\n",
        "\n",
        "class TokenBlockingLLM(BaseModel):\n",
        "    \"\"\"Custom LLM with token blocking for use with deepeval\"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None, temperature=0.7, top_p=0.9, top_k=40, max_tokens=512, save_dir=None):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        # Track statistics\n",
        "        self.responses = []\n",
        "        self.generation_times = []\n",
        "        self.token_counts = []\n",
        "\n",
        "    def complete(self, prompt):\n",
        "        \"\"\"Implementation of the required complete method from BaseModel\"\"\"\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def generate(self, prompt):\n",
        "        # Start timer\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Prepare input\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        input_tokens = inputs['input_ids'][0].cpu().tolist()\n",
        "\n",
        "        # Create logits processor if blocked tokens are provided\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        # Create streamer for token-by-token output\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "\n",
        "        # Prepare generation kwargs\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        # Collect streamed tokens\n",
        "        generated_text = \"\"\n",
        "        output_tokens = []\n",
        "\n",
        "        # Process streamed tokens\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "            # Approximate token tracking\n",
        "            new_token_ids = self.tokenizer.encode(new_text, add_special_tokens=False)\n",
        "            output_tokens.extend(new_token_ids)\n",
        "\n",
        "        # End timer\n",
        "        generation_time = time.time() - start_time\n",
        "\n",
        "        # Record stats\n",
        "        self.responses.append({\n",
        "            'prompt': prompt,\n",
        "            'response': generated_text,\n",
        "            'generation_time': generation_time,\n",
        "            'tokens': len(output_tokens)\n",
        "        })\n",
        "\n",
        "        self.generation_times.append(generation_time)\n",
        "        self.token_counts.append(len(output_tokens))\n",
        "\n",
        "        # Save response if directory is provided\n",
        "        if self.save_dir:\n",
        "            # Create a filename based on prompt hash (to identify the same problems across runs)\n",
        "            import hashlib\n",
        "            prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]\n",
        "            response_id = f\"response_{prompt_hash}_{'blocked' if self.blocked_token_ids is not None else 'unblocked'}\"\n",
        "\n",
        "            response_data = {\n",
        "                'prompt': prompt,\n",
        "                'response': generated_text,\n",
        "                'generation_time': generation_time,\n",
        "                'tokens': len(output_tokens),\n",
        "                'token_blocking': self.blocked_token_ids is not None\n",
        "            }\n",
        "\n",
        "            response_filepath = os.path.join(self.save_dir, f\"{response_id}.json\")\n",
        "            with open(response_filepath, 'w') as f:\n",
        "                json.dump(response_data, f, indent=2)\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        \"\"\"Get average statistics from all generated responses\"\"\"\n",
        "        if not self.generation_times:\n",
        "            return {'avg_time': 0, 'avg_tokens': 0}\n",
        "\n",
        "        return {\n",
        "            'avg_time': sum(self.generation_times) / len(self.generation_times),\n",
        "            'avg_tokens': sum(self.token_counts) / len(self.token_counts)\n",
        "        }\n",
        "\n",
        "# Load the DeepSeek model\n",
        "print(\"Loading DeepSeek-R1-Distill-Qwen-1.5B model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,  # Use half precision to fit in GPU memory\n",
        "    device_map=\"auto\"  # Automatically determine device mapping\n",
        ")\n",
        "\n",
        "# @title Run GSM8K Benchmark with DeepEval (With vs. Without Blocking)\n",
        "# @markdown Configure the benchmark parameters\n",
        "\n",
        "# @markdown ## Number of problems to test\n",
        "n_problems = 50  # @param {type:\"slider\", min:10, max:200, step:10}\n",
        "n_shots = 3  # @param {type:\"slider\", min:0, max:8, step:1}\n",
        "enable_cot = True  # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown ## Generation parameters\n",
        "temperature = 0.7  # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "top_p = 0.9  # @param {type:\"slider\", min:0.1, max:1.0, step:0.1}\n",
        "top_k = 40  # @param {type:\"number\"}\n",
        "max_tokens = 512  # @param {type:\"number\"}\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_token_ids = torch.tensor(\n",
        "    get_blocked_token_ids(tokenizer, words_to_block),\n",
        "    device=model.device\n",
        ")\n",
        "\n",
        "# Run benchmark without token blocking\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "# Create custom LLM without token blocking\n",
        "llm_unblocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,  # No blocking\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k,\n",
        "    max_tokens=max_tokens,\n",
        "    save_dir=run_dir\n",
        ")\n",
        "\n",
        "# Initialize benchmark\n",
        "benchmark_unblocked = GSM8K(\n",
        "    n_problems=n_problems,\n",
        "    n_shots=n_shots,\n",
        "    enable_cot=enable_cot\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "benchmark_unblocked.evaluate(model=llm_unblocked)\n",
        "\n",
        "# Get statistics\n",
        "unblocked_score = benchmark_unblocked.overall_score\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "# Clear GPU memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "# Run benchmark with token blocking\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "# Create custom LLM with token blocking\n",
        "llm_blocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,  # With blocking\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k,\n",
        "    max_tokens=max_tokens,\n",
        "    save_dir=run_dir\n",
        ")\n",
        "\n",
        "# Initialize benchmark\n",
        "benchmark_blocked = GSM8K(\n",
        "    n_problems=n_problems,\n",
        "    n_shots=n_shots,\n",
        "    enable_cot=enable_cot\n",
        ")\n",
        "\n",
        "# Run evaluation\n",
        "benchmark_blocked.evaluate(model=llm_blocked)\n",
        "\n",
        "# Get statistics\n",
        "blocked_score = benchmark_blocked.overall_score\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# Create summary report\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'n_problems': n_problems,\n",
        "    'n_shots': n_shots,\n",
        "    'enable_cot': enable_cot,\n",
        "    'words_blocked': words_to_block,\n",
        "    'generation_params': {\n",
        "        'temperature': temperature,\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'max_tokens': max_tokens\n",
        "    },\n",
        "    'unblocked': {\n",
        "        'score': unblocked_score,\n",
        "        'avg_time': unblocked_stats['avg_time'],\n",
        "        'avg_tokens': unblocked_stats['avg_tokens']\n",
        "    },\n",
        "    'blocked': {\n",
        "        'score': blocked_score,\n",
        "        'avg_time': blocked_stats['avg_time'],\n",
        "        'avg_tokens': blocked_stats['avg_tokens']\n",
        "    },\n",
        "    'difference': {\n",
        "        'score': blocked_score - unblocked_score,\n",
        "        'time': blocked_stats['avg_time'] - unblocked_stats['avg_time'],\n",
        "        'tokens': blocked_stats['avg_tokens'] - unblocked_stats['avg_tokens']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary to file\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "# Create dataframe for display\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        'Method': 'Without Blocking',\n",
        "        'GSM8K Score (%)': unblocked_score,\n",
        "        'Avg Time (s)': unblocked_stats['avg_time'],\n",
        "        'Avg Tokens': unblocked_stats['avg_tokens']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'With Blocking',\n",
        "        'GSM8K Score (%)': blocked_score,\n",
        "        'Avg Time (s)': blocked_stats['avg_time'],\n",
        "        'Avg Tokens': blocked_stats['avg_tokens']\n",
        "    }\n",
        "])\n",
        "\n",
        "# Display results\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nBlocked words: {words_to_block}\")\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "print(f\"Difference in avg time: {blocked_stats['avg_time'] - unblocked_stats['avg_time']:.2f} seconds\")\n",
        "print(f\"Difference in avg tokens: {blocked_stats['avg_tokens'] - unblocked_stats['avg_tokens']:.1f} tokens\")\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score], color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n(DeepSeek-R1-Distill-Qwen-1.5B)')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Plot avg time\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_stats['avg_time'], blocked_stats['avg_time']], color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Generation Time per Problem')\n",
        "plt.ylabel('Time (seconds)')\n",
        "\n",
        "# Plot avg tokens\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_stats['avg_tokens'], blocked_stats['avg_tokens']], color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Tokens Generated per Problem')\n",
        "plt.ylabel('Tokens')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "f7nfNBer9_m_",
        "outputId": "cc82cc32-208f-493b-cf92-5c6fdeff5a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'BaseModel' from 'deepeval.models.base_model' (/usr/local/lib/python3.11/dist-packages/deepeval/models/base_model.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-66822d7cbbed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmarks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepeval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m  \u001b[0;31m# Use BaseModel instead of CustomLLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Mount Google Drive for saving results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseModel' from 'deepeval.models.base_model' (/usr/local/lib/python3.11/dist-packages/deepeval/models/base_model.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show lm-eval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCrVUY3BBTeJ",
        "outputId": "7284ecdd-2f9b-4ad7-c454-cb8a0d2e6133"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: lm_eval\n",
            "Version: 0.4.8\n",
            "Summary: A framework for evaluating language models\n",
            "Home-page: https://github.com/EleutherAI/lm-evaluation-harness\n",
            "Author: \n",
            "Author-email: EleutherAI <contact@eleuther.ai>\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: accelerate, datasets, dill, evaluate, jsonlines, more_itertools, numexpr, peft, pybind11, pytablewriter, rouge-score, sacrebleu, scikit-learn, sqlitedict, torch, tqdm-multiprocess, transformers, word2number, zstandard\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lm-eval\n",
        "import lm_eval\n",
        "print(\"Available tasks:\", lm_eval.list_tasks())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "ihjR1Rm9BZvx",
        "outputId": "d7900931-631e-4e72-8d37-389ea628d2e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'lm_eval' has no attribute 'list_tasks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-3606e334e53b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q lm-eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlm_eval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Available tasks:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'lm_eval' has no attribute 'list_tasks'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch matplotlib pandas tqdm accelerate lm-eval\n",
        "!pip install -q --upgrade lm-eval\n",
        "\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "import time, json, os, gc, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For LM-Evals GSM8K task\n",
        "from evals.tasks.gsm8k import GSM8K\n",
        "\n",
        "# --- Helper functions and classes for token blocking ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words_to_block):\n",
        "    \"\"\"Get token IDs for words we want to block.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words_to_block:\n",
        "        # Get all possible token IDs for the word in various forms\n",
        "        for form in [(\" \" + word), word, (\" \" + word.capitalize()), word.capitalize(), (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words_to_block}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"Custom logits processor that sets scores for blocked token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Define a custom LM-Evals model with token blocking ---\n",
        "class TokenBlockingModel:\n",
        "    \"\"\"\n",
        "    Custom model for LM-Evals that wraps a Hugging Face model and applies token blocking.\n",
        "    It implements the __call__ method expected by LM-Evals.\n",
        "    \"\"\"\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None,\n",
        "                 temperature=0.7, top_p=0.9, top_k=40, max_tokens=512, save_dir=None):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "        self.save_dir = save_dir\n",
        "\n",
        "        # Statistics tracking\n",
        "        self.responses = []\n",
        "        self.generation_times = []\n",
        "        self.token_counts = []\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(self.model.device)\n",
        "        input_tokens = inputs['input_ids'][0].cpu().tolist()\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread so we can stream output\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        output_tokens = []\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "            new_token_ids = self.tokenizer.encode(new_text, add_special_tokens=False)\n",
        "            output_tokens.extend(new_token_ids)\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        self.responses.append({\n",
        "            'prompt': prompt,\n",
        "            'response': generated_text,\n",
        "            'generation_time': generation_time,\n",
        "            'tokens': len(output_tokens)\n",
        "        })\n",
        "        self.generation_times.append(generation_time)\n",
        "        self.token_counts.append(len(output_tokens))\n",
        "\n",
        "        if self.save_dir:\n",
        "            prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]\n",
        "            response_id = f\"response_{prompt_hash}_{'blocked' if self.blocked_token_ids is not None else 'unblocked'}\"\n",
        "            response_data = {\n",
        "                'prompt': prompt,\n",
        "                'response': generated_text,\n",
        "                'generation_time': generation_time,\n",
        "                'tokens': len(output_tokens),\n",
        "                'token_blocking': self.blocked_token_ids is not None\n",
        "            }\n",
        "            response_filepath = os.path.join(self.save_dir, f\"{response_id}.json\")\n",
        "            with open(response_filepath, 'w') as f:\n",
        "                json.dump(response_data, f, indent=2)\n",
        "        return generated_text\n",
        "\n",
        "    def __call__(self, prompt: str, **kwargs) -> str:\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        if not self.generation_times:\n",
        "            return {'avg_time': 0, 'avg_tokens': 0}\n",
        "        return {\n",
        "            'avg_time': sum(self.generation_times) / len(self.generation_times),\n",
        "            'avg_tokens': sum(self.token_counts) / len(self.token_counts)\n",
        "        }\n",
        "\n",
        "# --- Set up experiment parameters ---\n",
        "# (Mounting Google Drive and saving results if using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/deepseek_gsm8k_results\"\n",
        "results_dir = os.path.join(base_dir, \"block_words_benchmark\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer\n",
        "print(\"Loading DeepSeek-R1-Distill-Qwen-1.5B model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Generation parameters\n",
        "n_problems = 50      # Number of problems to test\n",
        "n_shots = 3          # Number of in-context examples\n",
        "enable_cot = True    # Enable chain-of-thought prompting\n",
        "\n",
        "temperature = 0.7\n",
        "top_p = 0.9\n",
        "top_k = 40\n",
        "max_tokens = 512\n",
        "\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# --- Create LM-Eval compatible model instances ---\n",
        "# Without token blocking\n",
        "llm_unblocked = TokenBlockingModel(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k,\n",
        "    max_tokens=max_tokens,\n",
        "    save_dir=run_dir\n",
        ")\n",
        "\n",
        "# With token blocking\n",
        "llm_blocked = TokenBlockingModel(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=temperature,\n",
        "    top_p=top_p,\n",
        "    top_k=top_k,\n",
        "    max_tokens=max_tokens,\n",
        "    save_dir=run_dir\n",
        ")\n",
        "\n",
        "# --- Run GSM8K Benchmark using LM-Evals ---\n",
        "# Initialize GSM8K task from LM-Evals. (LM-Evals expects n_shots and chain-of-thought parameters.)\n",
        "gsm8k_unblocked = GSM8K(n_samples=n_problems, n_shots=n_shots, chain_of_thought=enable_cot)\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "gsm8k_unblocked_results = gsm8k_unblocked.run(model=llm_unblocked)\n",
        "unblocked_score = gsm8k_unblocked_results.get(\"score\", 0)  # Assume the result dict contains an overall \"score\"\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "# Clear GPU memory between runs\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "gsm8k_blocked = GSM8K(n_samples=n_problems, n_shots=n_shots, chain_of_thought=enable_cot)\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "gsm8k_blocked_results = gsm8k_blocked.run(model=llm_blocked)\n",
        "blocked_score = gsm8k_blocked_results.get(\"score\", 0)\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# --- Create summary report ---\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'n_problems': n_problems,\n",
        "    'n_shots': n_shots,\n",
        "    'enable_cot': enable_cot,\n",
        "    'words_blocked': words_to_block,\n",
        "    'generation_params': {\n",
        "        'temperature': temperature,\n",
        "        'top_p': top_p,\n",
        "        'top_k': top_k,\n",
        "        'max_tokens': max_tokens\n",
        "    },\n",
        "    'unblocked': {\n",
        "        'score': unblocked_score,\n",
        "        'avg_time': unblocked_stats['avg_time'],\n",
        "        'avg_tokens': unblocked_stats['avg_tokens']\n",
        "    },\n",
        "    'blocked': {\n",
        "        'score': blocked_score,\n",
        "        'avg_time': blocked_stats['avg_time'],\n",
        "        'avg_tokens': blocked_stats['avg_tokens']\n",
        "    },\n",
        "    'difference': {\n",
        "        'score': blocked_score - unblocked_score,\n",
        "        'time': blocked_stats['avg_time'] - unblocked_stats['avg_time'],\n",
        "        'tokens': blocked_stats['avg_tokens'] - unblocked_stats['avg_tokens']\n",
        "    }\n",
        "}\n",
        "\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {\n",
        "        'Method': 'Without Blocking',\n",
        "        'GSM8K Score (%)': unblocked_score,\n",
        "        'Avg Time (s)': unblocked_stats['avg_time'],\n",
        "        'Avg Tokens': unblocked_stats['avg_tokens']\n",
        "    },\n",
        "    {\n",
        "        'Method': 'With Blocking',\n",
        "        'GSM8K Score (%)': blocked_score,\n",
        "        'Avg Time (s)': blocked_stats['avg_time'],\n",
        "        'Avg Tokens': blocked_stats['avg_tokens']\n",
        "    }\n",
        "])\n",
        "\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nBlocked words: {words_to_block}\")\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "print(f\"Difference in avg time: {blocked_stats['avg_time'] - unblocked_stats['avg_time']:.2f} seconds\")\n",
        "print(f\"Difference in avg tokens: {blocked_stats['avg_tokens'] - unblocked_stats['avg_tokens']:.1f} tokens\")\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score], color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n({model_name})')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_stats['avg_time'], blocked_stats['avg_time']], color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Generation Time per Problem')\n",
        "plt.ylabel('Time (s)')\n",
        "\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_stats['avg_tokens'], blocked_stats['avg_tokens']], color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Tokens Generated per Problem')\n",
        "plt.ylabel('Tokens')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "O5l4WJP2ADho",
        "outputId": "a0c663c1-ca80-4d02-8bdc-0481322ed86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'evals'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f4a019027472>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# For LM-Evals GSM8K task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgsm8k\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# --- Helper functions and classes for token blocking ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evals'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers torch matplotlib pandas tqdm accelerate lm-eval\n"
      ],
      "metadata": {
        "id": "gpKLCyrajoNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch lm-eval matplotlib pandas tqdm accelerate lm-eval\n",
        "!pip install --upgrade lm-eval\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "from evals.tasks.gsm8k import GSM8K\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nbWByXfcYqL8",
        "outputId": "2ac6305b-77b8-4120-af97-15271bbbd97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m650.5/664.8 MB\u001b[0m \u001b[31m199.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    unknown package:\n",
            "        Expected sha256 165764f44ef8c61fcdfdfdbe769d687e06374059fbb388b6c89ecb0e28793a6f\n",
            "             Got        a9b5653946eced37998f3e5bbb115c580e37fdbf0d713d99d56e2facb46652ae\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting lm-eval\n",
            "  Using cached lm_eval-0.4.8-py3-none-any.whl.metadata (50 kB)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.3.0)\n",
            "Collecting evaluate (from lm-eval)\n",
            "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.16.0 (from lm-eval)\n",
            "  Using cached datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting jsonlines (from lm-eval)\n",
            "  Using cached jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.14.0)\n",
            "Collecting pybind11>=2.6.2 (from lm-eval)\n",
            "  Using cached pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm-eval)\n",
            "  Using cached pytablewriter-1.2.1-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm-eval)\n",
            "  Using cached rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm-eval)\n",
            "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.6.1)\n",
            "Collecting sqlitedict (from lm-eval)\n",
            "  Using cached sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.6.0+cu124)\n",
            "Collecting tqdm-multiprocess (from lm-eval)\n",
            "  Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (4.48.3)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.23.0)\n",
            "Collecting dill (from lm-eval)\n",
            "  Using cached dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting word2number (from lm-eval)\n",
            "  Using cached word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval) (10.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (18.1.0)\n",
            "Collecting dill (from lm-eval)\n",
            "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (4.67.1)\n",
            "Collecting xxhash (from datasets>=2.16.0->lm-eval)\n",
            "  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->lm-eval)\n",
            "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm-eval) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.11.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.17.0)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval)\n",
            "  Using cached portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.5.0->lm-eval)\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8->lm-eval)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm-eval) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm-eval) (0.21.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->lm-eval) (25.3.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (75.1.0)\n",
            "Collecting DataProperty<2,>=1.1.0 (from pytablewriter->lm-eval)\n",
            "  Using cached DataProperty-1.1.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval)\n",
            "  Using cached mbstrdecoder-1.1.4-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval)\n",
            "  Using cached pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval)\n",
            "  Using cached tabledata-1.3.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval)\n",
            "  Using cached tcolorpy-0.1.7-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval)\n",
            "  Using cached typepy-1.3.4-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.18.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm-eval) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.8)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval) (2025.1)\n",
            "Using cached lm_eval-0.4.8-py3-none-any.whl (3.9 MB)\n",
            "Using cached datasets-3.4.1-py3-none-any.whl (487 kB)\n",
            "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "Using cached pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "Using cached sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Using cached jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Using cached pytablewriter-1.2.1-py3-none-any.whl (91 kB)\n",
            "Using cached tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Using cached DataProperty-1.1.0-py3-none-any.whl (27 kB)\n",
            "Using cached mbstrdecoder-1.1.4-py3-none-any.whl (7.9 kB)\n",
            "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "Using cached pathvalidate-3.2.3-py3-none-any.whl (24 kB)\n",
            "Using cached tabledata-1.3.4-py3-none-any.whl (11 kB)\n",
            "Using cached tcolorpy-0.1.7-py3-none-any.whl (8.1 kB)\n",
            "Using cached typepy-1.3.4-py3-none-any.whl (31 kB)\n",
            "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Using cached portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "Building wheels for collected packages: rouge-score, sqlitedict, word2number\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=58cfc6a38e0dc8d6bf3d8cc745e7d23668f1ea8e6422c3f4e28949e83f9a7868\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=76ca04be393a29f7bcbd29a8307f115a96f4f112c02118ee940601acb1a36c7f\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=10c65ee976f3e4a7c9d1f6a8770794397df2ade41202a42069e216a707d7c755\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
            "Successfully built rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, sqlitedict, xxhash, tcolorpy, pybind11, portalocker, pathvalidate, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mbstrdecoder, jsonlines, dill, colorama, typepy, tqdm-multiprocess, sacrebleu, rouge-score, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, DataProperty, tabledata, evaluate, pytablewriter, lm-eval\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed DataProperty-1.1.0 colorama-0.4.6 datasets-3.4.1 dill-0.3.8 evaluate-0.4.3 jsonlines-4.0.0 lm-eval-0.4.8 mbstrdecoder-1.1.4 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pathvalidate-3.2.3 portalocker-3.1.1 pybind11-2.13.6 pytablewriter-1.2.1 rouge-score-0.1.2 sacrebleu-2.5.1 sqlitedict-2.1.0 tabledata-1.3.4 tcolorpy-0.1.7 tqdm-multiprocess-0.0.11 typepy-1.3.4 word2number-1.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'evals'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fbaf16c42ed9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTextIteratorStreamer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgsm8k\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'evals'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade lm-eval\n",
        "\n",
        "from lm_eval.tasks.gsm8k import GSM8K\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tSELFVEfYpkb",
        "outputId": "a10b2970-d63d-4f70-d13d-c424d80838b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lm-eval in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (3.4.1)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (from lm-eval) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.14.0)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.13.6)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.2.1)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.6.1)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (4.48.3)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.3.8)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.1)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval) (10.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm-eval) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.11.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.17.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm-eval) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm-eval) (0.21.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->lm-eval) (25.3.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (75.1.0)\n",
            "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (1.1.0)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (1.1.4)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (3.2.3)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (1.3.4)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (0.1.7)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (1.3.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.18.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm-eval) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.8)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval) (2025.1)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GSM8K' from 'lm_eval.tasks.gsm8k' (unknown location)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2b0de6602ad1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install --upgrade lm-eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlm_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgsm8k\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GSM8K' from 'lm_eval.tasks.gsm8k' (unknown location)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch lm-eval matplotlib pandas tqdm accelerate lm-eval\n",
        "!pip install --upgrade lm-eval\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "from lm_eval.tasks import gsm8k\n",
        "\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Adapter Class for LM‑Evals Integration ---\n",
        "class TokenBlockingLLMAdapter:\n",
        "    \"\"\"\n",
        "    An adapter that wraps a Hugging Face model and applies token blocking.\n",
        "    It implements the __call__ method required by LM‑Evals (OpenAI Evals).\n",
        "    \"\"\"\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None,\n",
        "                 temperature=0.7, top_p=0.9, top_k=40, max_tokens=512):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024,\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        # (Optional) Track statistics if needed\n",
        "        return generated_text\n",
        "\n",
        "    def __call__(self, prompt: str, **kwargs) -> str:\n",
        "        # This makes the adapter compatible with LM‑Evals, which expects a callable that returns a string.\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        # Placeholder for any statistics you want to track.\n",
        "        return {'avg_time': 0, 'avg_tokens': 0}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# (For saving results on Google Drive in Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block and get token IDs\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (example uses DeepSeek-R1-Distill-Qwen-1.5B)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two adapter instances: one without and one with token blocking.\n",
        "llm_unblocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "# --- Running GSM8K Benchmark using LM‑Evals ---\n",
        "# Import the GSM8K task from LM‑Evals (adjust the import based on your package version)\n",
        "try:\n",
        "    from evals.tasks.gsm8k import GSM8K\n",
        "except ImportError:\n",
        "    print(\"GSM8K not found in evals.tasks.gsm8k. Please ensure you have the latest LM‑Evals installed.\")\n",
        "\n",
        "# Initialize GSM8K task (configure number of samples, in-context examples, and chain-of-thought)\n",
        "# Initialize GSM8K benchmark (using DeepEval's GSM8K)\n",
        "gsm8k_unblocked = gsm8k(n_problems=5, n_shots=1, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "results_unblocked = gsm8k_unblocked.evaluate(model=llm_unblocked)\n",
        "unblocked_score = results_unblocked  # results_unblocked is already a float\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "gsm8k_blocked = gsm8k(n_problems=5, n_shots=1, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "results_blocked = gsm8k_blocked.evaluate(model=llm_blocked)\n",
        "blocked_score = results_blocked\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "\n",
        "# Create summary report\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {'score': unblocked_score},\n",
        "    'blocked': {'score': blocked_score},\n",
        "    'difference': {'score': blocked_score - unblocked_score}\n",
        "}\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {'Method': 'Without Blocking', 'GSM8K Score (%)': unblocked_score},\n",
        "    {'Method': 'With Blocking', 'GSM8K Score (%)': blocked_score}\n",
        "])\n",
        "\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n({model_name})')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0638cb5d85b046a7b1c79a04b49e9056",
            "135362abdd444624904cd74f841a211d",
            "eb1dcb48d76f4d74ae0f3f18d14aafad",
            "ffcd30672434422886003402c10b1aef",
            "94bdf1e557334ff59c20e937bf67b5d8",
            "d50d1ad25c8041e69e00dcf9e4c7baec",
            "02ba9bdd812b4af7b85464a41c8a9cc9",
            "acb47906c4ce4458b4c93551831c4571",
            "9ca0b0e0ddfa43d5b99130c754fee8ae",
            "2220e9e1ada943f4a0eba20e72180297",
            "4a5b94bd08d34404bc82a8b9ed70366a",
            "ef963482c1e84b1bb20a2e5b5b00b2c9",
            "6430e3809be34fe1b3ae3c8e928b35c3",
            "a0d7a051f8934881a89fdb199b5eeed1",
            "0c6885546b1f461dacf786bcfea9b178",
            "6e7d1bb150b54cde9c2dafb96f99f50d",
            "a6fda4ac604e4509b4cedfb83f1f7d3d",
            "55bc8375137840079738526334b9169f",
            "ff74c0a70996453193e3f0d9c80f9e1f",
            "cde9b81a310646548c4b174612e481b1",
            "d9090acf7d704f03918814a9f41943dd",
            "dd2672b6a329470a8b4312b9b03a276a",
            "b2273f2d68e04d25a63b94cd5a822d94",
            "135e331958fd48caac821ac9ddbef887",
            "e18c7f6974df4813aa6f1c7226f6da68",
            "1b5ef91638b0446aabea4c49632ad8b9",
            "36fbc2bcd1b04b6a9e21941851e9a67c",
            "30b2b9dd5d884c618ac269dd44a9a08f",
            "a893ade49a4d4d89ad0bab2a37d1a174",
            "31bf4cbdfdc64834adcccd65581d23ce",
            "fe539e2c11614662a7c662ebbdf58263",
            "97b25a3d00a048b5b8ff067ffd2d1555",
            "ee1a453208a14c29925a0dfb82b13c6f",
            "d772aa50d13f40d68e71dd8c38ae5b38",
            "4fe1509d34b746bb84ab7e02bff26eaa",
            "47b77bc2da92493ea9660b93c037619c",
            "0fbff518c05c4e05aa1a3c337693c84f",
            "0fcbdc7801c54a8eb44589b1d517e662",
            "2509247ae3f640338f9fa77b1b4792ff",
            "014befbbfacf41eb9ef3c8ab8567f621",
            "c511b4e642c6491ea3170636556d7516",
            "b570508086de4906b0a130d923b90be6",
            "f1d327f827564b44bdd20a12246fdae4",
            "5502d673c8a24885a2519bde0b9517f4",
            "839c703776d84da18315f108363ebf90",
            "d1c909d9f0ff4124afba5dcb9fe70d03",
            "ab641fec4724463cb880a7aca89a9f99",
            "973cccc60edc4910adc2720fc803cc6b",
            "ed34297977054ebbaf5d312c3832535d",
            "05ad3f663d7240a68631588552c2e861",
            "7772c82f1a5d44e8ba3a49656ea6da1f",
            "fcc86d44fc4348fb9a007438b309b609",
            "6b8c4b58264a48fa92c43a074b8d866b",
            "de2268f74b3448438a312b1e5b9667df",
            "39bf00e4553f447585fa2b087dbf8f5a"
          ]
        },
        "id": "X2nf5E9aCo8O",
        "outputId": "13e17900-da72-4b7a-d54d-d0c64e32604c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lm-eval in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (3.4.1)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.11/dist-packages (from lm-eval) (4.0.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.10.2)\n",
            "Requirement already satisfied: peft>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.14.0)\n",
            "Requirement already satisfied: pybind11>=2.6.2 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.13.6)\n",
            "Requirement already satisfied: pytablewriter in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.2.1)\n",
            "Requirement already satisfied: rouge-score>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.1.2)\n",
            "Requirement already satisfied: sacrebleu>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.6.1)\n",
            "Requirement already satisfied: sqlitedict in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.1.0)\n",
            "Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm-multiprocess in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.0.11)\n",
            "Requirement already satisfied: transformers>=4.1 in /usr/local/lib/python3.11/dist-packages (from lm-eval) (4.48.3)\n",
            "Requirement already satisfied: zstandard in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from lm-eval) (0.3.8)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.11/dist-packages (from lm-eval) (1.1)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.11/dist-packages (from lm-eval) (10.6.0)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->lm-eval) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (18.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->lm-eval) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.16.0->lm-eval) (3.11.13)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score>=0.0.4->lm-eval) (1.17.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu>=1.5.0->lm-eval) (5.3.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.1->lm-eval) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8->lm-eval) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8->lm-eval) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.1->lm-eval) (0.21.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->lm-eval) (25.3.0)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (75.1.0)\n",
            "Requirement already satisfied: DataProperty<2,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (1.1.0)\n",
            "Requirement already satisfied: mbstrdecoder<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (1.1.4)\n",
            "Requirement already satisfied: pathvalidate<4,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (3.2.3)\n",
            "Requirement already satisfied: tabledata<2,>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (1.3.4)\n",
            "Requirement already satisfied: tcolorpy<1,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from pytablewriter->lm-eval) (0.1.7)\n",
            "Requirement already satisfied: typepy<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (1.3.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.16.0->lm-eval) (1.18.3)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.11/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval) (5.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.16.0->lm-eval) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.11/dist-packages (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval) (2025.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8->lm-eval) (3.0.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score>=0.0.4->lm-eval) (8.1.8)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.16.0->lm-eval) (2025.1)\n",
            "Mounted at /content/drive\n",
            "Results will be saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0638cb5d85b046a7b1c79a04b49e9056"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ef963482c1e84b1bb20a2e5b5b00b2c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2273f2d68e04d25a63b94cd5a822d94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d772aa50d13f40d68e71dd8c38ae5b38"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "839c703776d84da18315f108363ebf90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Blocking these words: ['wait', 'alternatively', 'perhaps', 'maybe']\n",
            "Corresponding to these 33 token IDs: [13824, 71032, 21390, 3090, 36760, 7196, 68387, 39, 44, 8365, 8753, 9654, 49209, 828, 17854, 39230, 3783, 10696, 969, 47945, 11594, 18765, 38478, 7887, 3022, 40412, 11489, 14190, 92014, 31476, 54390, 65272, 10877]\n",
            "Token ID 13824 = ' Wait'\n",
            "Token ID 71032 = 'WAIT'\n",
            "Token ID 21390 = 'Maybe'\n",
            "Token ID 3090 = 'IV'\n",
            "Token ID 36760 = 'maybe'\n",
            "Token ID 7196 = ' maybe'\n",
            "Token ID 68387 = ' alternatively'\n",
            "Token ID 39 = 'H'\n",
            "Token ID 44 = 'M'\n",
            "Token ID 8365 = ' perhaps'\n",
            "Token ID 8753 = ' AL'\n",
            "Token ID 9654 = 'PER'\n",
            "Token ID 49209 = 'ELY'\n",
            "Token ID 828 = 'AT'\n",
            "Token ID 17854 = ' PER'\n",
            "Token ID 39230 = ' MAY'\n",
            "Token ID 3783 = ' wait'\n",
            "Token ID 10696 = ' Maybe'\n",
            "Token ID 969 = 'AL'\n",
            "Token ID 47945 = 'APS'\n",
            "Token ID 11594 = 'BE'\n",
            "Token ID 18765 = ' Perhaps'\n",
            "Token ID 38478 = ' Alternatively'\n",
            "Token ID 7887 = 'atively'\n",
            "Token ID 3022 = 'AY'\n",
            "Token ID 40412 = 'altern'\n",
            "Token ID 11489 = 'wait'\n",
            "Token ID 14190 = 'Wait'\n",
            "Token ID 92014 = 'Alternatively'\n",
            "Token ID 31476 = 'Perhaps'\n",
            "Token ID 54390 = ' WAIT'\n",
            "Token ID 65272 = 'perhaps'\n",
            "Token ID 10877 = 'TERN'\n",
            "GSM8K not found in evals.tasks.gsm8k. Please ensure you have the latest LM‑Evals installed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'module' object is not callable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6b0d14b9cfc6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;31m# Initialize GSM8K task (configure number of samples, in-context examples, and chain-of-thought)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;31m# Initialize GSM8K benchmark (using DeepEval's GSM8K)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m \u001b[0mgsm8k_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsm8k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_problems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_shots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_cot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0mresults_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsm8k_unblocked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_unblocked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "260771QmAq6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch lm-eval matplotlib pandas tqdm accelerate\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Adapter Class for LM‑Evals Integration ---\n",
        "class TokenBlockingLLMAdapter:\n",
        "    \"\"\"\n",
        "    An adapter that wraps a Hugging Face model and applies token blocking.\n",
        "    It implements the __call__ method required by LM‑Evals (OpenAI Evals).\n",
        "    \"\"\"\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None,\n",
        "                 temperature=0.7, top_p=0.9, top_k=40, max_tokens=512):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024,\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        # (Optional) Track statistics if needed\n",
        "        return generated_text\n",
        "\n",
        "    def __call__(self, prompt: str, **kwargs) -> str:\n",
        "        # This makes the adapter compatible with LM‑Evals, which expects a callable that returns a string.\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        # Placeholder for any statistics you want to track.\n",
        "        return {'avg_time': 0, 'avg_tokens': 0}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# (For saving results on Google Drive in Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark_1\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block and get token IDs\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (example uses DeepSeek-R1-Distill-Qwen-1.5B)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two adapter instances: one without and one with token blocking.\n",
        "llm_unblocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "# --- Running GSM8K Benchmark using LM‑Evals ---\n",
        "# Import the GSM8K task from LM‑Evals (adjust the import based on your package version)\n",
        "try:\n",
        "    from evals.tasks.gsm8k import GSM8K\n",
        "except ImportError:\n",
        "    print(\"GSM8K not found in evals.tasks.gsm8k. Please ensure you have the latest LM‑Evals installed.\")\n",
        "\n",
        "# Initialize GSM8K task (configure number of samples, in-context examples, and chain-of-thought)\n",
        "# Initialize GSM8K benchmark (using DeepEval's GSM8K)\n",
        "gsm8k_unblocked = GSM8K(n_problems=1000, n_shots=3, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "results_unblocked = gsm8k_unblocked.evaluate(model=llm_unblocked)\n",
        "unblocked_score = results_unblocked.get(\"score\", 0)\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "gsm8k_blocked = GSM8K(n_problems=1000, n_shots=3, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "results_blocked = gsm8k_blocked.evaluate(model=llm_blocked)\n",
        "blocked_score = results_blocked.get(\"score\", 0)\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "\n",
        "# Create summary report\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {'score': unblocked_score},\n",
        "    'blocked': {'score': blocked_score},\n",
        "    'difference': {'score': blocked_score - unblocked_score}\n",
        "}\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {'Method': 'Without Blocking', 'GSM8K Score (%)': unblocked_score},\n",
        "    {'Method': 'With Blocking', 'GSM8K Score (%)': blocked_score}\n",
        "])\n",
        "\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n({model_name})')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd343d244efe446782349f37a8c44b1f",
            "bef1acf39d514c1b9751ffe5f815bdec",
            "dfa82d0846484668b6fa63ed2ed96ac1",
            "a838650b36284fa081c0b084be9efcee",
            "1d51d7bb864448bfb3a163384e367c81",
            "b18e3ecbf3a9462eb50a4c8a9c72a6d4",
            "9db5487c8f5445b79106709c99c5192a",
            "4d5825fd0ca2482ebbf5f4949e71c098",
            "089b62961ccf461598f7148117975cde",
            "54c452a9f94c495985dc1e932e0df56d",
            "c4b25004e6b64a0ba369ef269b5c707c",
            "ff6fd2ca788c4501a8713e37e6f332c0",
            "62f4b17812f3471185aedf006d57240f",
            "6d13c6a275df42d89c3b58ae1fcf0012",
            "514ca0ff292e446d87a90af42989e9ba",
            "4701b2c98e9d495e8045217d732a9731",
            "0f9422f44f654a428dcf7546f9d8e4ba",
            "fe7db0a58ba24371a03f3bdca6fca024",
            "96ee735bb780404c90e2b197ad1d90a4",
            "5424171c24394ece9d16cca2c74fd8b1",
            "a5d2d77807ba4af9bf471d46b1b4e567",
            "180997ffd2894b6a889b14451cefcde8",
            "11914b25865e4c92abba610765c55017",
            "c13b9ca6aae846d786b63c9fbfeac8c5",
            "8c0b34df0e1c4f6ea121e2361394ed5d",
            "800be8fb509d4e9eae57bae974c41416",
            "6084c56abebd4ae48a9824a2045a2b80",
            "3203e29d18314f2b8dc9cf871bbd1c0f",
            "c0099b03dfac43fd8aae48faba0e7142",
            "15289e49f49a438494fe7cc6b69a9a6f",
            "f25addd45da34893ac9015bb455f7e92",
            "44e0b8af0adc4f2bb79a87d05a7b4c3f",
            "8f2f52ba66b0410797426fa924e21c83",
            "5dbe651647e744df80001b53f374f721",
            "dd70dc58b0db4ab2830418e48e52a82d",
            "0d3a0387b9274ac19e45e158f04a4f5a",
            "9e4e168fe18f4e798392b76b69798422",
            "914a8565f3d04bccb304ff8ea9194d32",
            "ecd67825a4a249478bddcbc2a6181704",
            "5a0ad8426a4f4676b093fea8ddef7c13",
            "adb9353abebf4a6cad0882a172e876bc",
            "4e74d86638074d28954e237067b53a73",
            "b31d28a92fd3499c910007506e34453b",
            "ec68de18b0de45d4939ab24e981d15cd",
            "461fea13ae194bf290ea082f202966b1",
            "8413afd7b78949a6bcec1c68939c6b8a",
            "0ce75217dcde4e1ea61b57499696abde",
            "7339d79da8784287995a204ce9a4a656",
            "8a023b45f8064d4fb6cf3631f6cd3b53",
            "fb7ac77e2bdd449b80f70031b63305ba",
            "6bb2e2112a40423d863c9d506af31d07",
            "8e3bb8247ccd498cae329a91b67471dd",
            "109bfe68d1684c1aadecd326ea186103",
            "82b4f7e581414ffdbaa8be2fdba87fb3",
            "57767e6c8cc2480eb56208689623b468"
          ]
        },
        "id": "YeAMXz1iEKsY",
        "outputId": "753a4d01-f912-4b1a-dba3-9aed74410912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mMounted at /content/drive\n",
            "Results will be saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_1\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd343d244efe446782349f37a8c44b1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff6fd2ca788c4501a8713e37e6f332c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11914b25865e4c92abba610765c55017"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dbe651647e744df80001b53f374f721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "461fea13ae194bf290ea082f202966b1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Blocking these words: ['wait', 'alternatively', 'perhaps', 'maybe']\n",
            "Corresponding to these 33 token IDs: [13824, 71032, 21390, 3090, 36760, 7196, 68387, 39, 44, 8365, 8753, 9654, 49209, 828, 17854, 39230, 3783, 10696, 969, 47945, 11594, 18765, 38478, 7887, 3022, 40412, 11489, 14190, 92014, 31476, 54390, 65272, 10877]\n",
            "Token ID 13824 = ' Wait'\n",
            "Token ID 71032 = 'WAIT'\n",
            "Token ID 21390 = 'Maybe'\n",
            "Token ID 3090 = 'IV'\n",
            "Token ID 36760 = 'maybe'\n",
            "Token ID 7196 = ' maybe'\n",
            "Token ID 68387 = ' alternatively'\n",
            "Token ID 39 = 'H'\n",
            "Token ID 44 = 'M'\n",
            "Token ID 8365 = ' perhaps'\n",
            "Token ID 8753 = ' AL'\n",
            "Token ID 9654 = 'PER'\n",
            "Token ID 49209 = 'ELY'\n",
            "Token ID 828 = 'AT'\n",
            "Token ID 17854 = ' PER'\n",
            "Token ID 39230 = ' MAY'\n",
            "Token ID 3783 = ' wait'\n",
            "Token ID 10696 = ' Maybe'\n",
            "Token ID 969 = 'AL'\n",
            "Token ID 47945 = 'APS'\n",
            "Token ID 11594 = 'BE'\n",
            "Token ID 18765 = ' Perhaps'\n",
            "Token ID 38478 = ' Alternatively'\n",
            "Token ID 7887 = 'atively'\n",
            "Token ID 3022 = 'AY'\n",
            "Token ID 40412 = 'altern'\n",
            "Token ID 11489 = 'wait'\n",
            "Token ID 14190 = 'Wait'\n",
            "Token ID 92014 = 'Alternatively'\n",
            "Token ID 31476 = 'Perhaps'\n",
            "Token ID 54390 = ' WAIT'\n",
            "Token ID 65272 = 'perhaps'\n",
            "Token ID 10877 = 'TERN'\n",
            "GSM8K not found in evals.tasks.gsm8k. Please ensure you have the latest LM‑Evals installed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GSM8K' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9db412d1dc9a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# Initialize GSM8K task (configure number of samples, in-context examples, and chain-of-thought)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;31m# Initialize GSM8K benchmark (using DeepEval's GSM8K)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0mgsm8k_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_problems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_shots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_cot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0mresults_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsm8k_unblocked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_unblocked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GSM8K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch lm-eval matplotlib pandas tqdm accelerate\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Adapter Class for LM‑Evals Integration ---\n",
        "class TokenBlockingLLMAdapter:\n",
        "    \"\"\"\n",
        "    An adapter that wraps a Hugging Face model and applies token blocking.\n",
        "    It implements the __call__ method required by LM‑Evals (OpenAI Evals).\n",
        "    \"\"\"\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None,\n",
        "                 temperature=0.7, top_p=0.9, top_k=40, max_tokens=512):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024,\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        # (Optional) Track statistics if needed.\n",
        "        return generated_text\n",
        "\n",
        "    def __call__(self, prompt: str, **kwargs) -> str:\n",
        "        # This makes the adapter compatible with LM‑Evals, which expects a callable that returns a string.\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        # Placeholder for any statistics you want to track.\n",
        "        return {'avg_time': 0, 'avg_tokens': 0}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# Mount Google Drive (if using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark_1\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (example uses DeepSeek-R1-Distill-Qwen-1.5B)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two adapter instances: one without and one with token blocking.\n",
        "llm_unblocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "# --- Running GSM8K Benchmark using LM‑Evals ---\n",
        "# Import the GSM8K task from LM‑Evals (adjust the import based on your package version)\n",
        "try:\n",
        "    from evals.tasks.gsm8k import GSM8K\n",
        "except ImportError:\n",
        "    print(\"GSM8K not found in evals.tasks.gsm8k. Please ensure you have the latest LM‑Evals installed.\")\n",
        "\n",
        "# Initialize GSM8K benchmark (using parameters: n_problems, n_shots, enable_cot)\n",
        "gsm8k_unblocked = GSM8K(n_problems=1000, n_shots=3, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "results_unblocked = gsm8k_unblocked.evaluate(model=llm_unblocked)\n",
        "unblocked_score = results_unblocked  # evaluate() returns a float\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "gsm8k_blocked = GSM8K(n_problems=1000, n_shots=3, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "results_blocked = gsm8k_blocked.evaluate(model=llm_blocked)\n",
        "blocked_score = results_blocked  # evaluate() returns a float\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# Create summary report\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {'score': unblocked_score},\n",
        "    'blocked': {'score': blocked_score},\n",
        "    'difference': {'score': blocked_score - unblocked_score}\n",
        "}\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {'Method': 'Without Blocking', 'GSM8K Score (%)': unblocked_score},\n",
        "    {'Method': 'With Blocking', 'GSM8K Score (%)': blocked_score}\n",
        "])\n",
        "\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n({model_name})')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "XbGqkCB-Fmgx",
        "outputId": "a282ae63-dc5e-4ef8-8727-54a5da52f8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Results will be saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_1\n",
            "Loading model...\n",
            "\n",
            "Blocking these words: ['wait', 'alternatively', 'perhaps', 'maybe']\n",
            "Corresponding to these 33 token IDs: [13824, 71032, 21390, 3090, 36760, 7196, 68387, 39, 44, 8365, 8753, 9654, 49209, 828, 17854, 39230, 3783, 10696, 969, 47945, 11594, 18765, 38478, 7887, 3022, 40412, 11489, 14190, 92014, 31476, 54390, 65272, 10877]\n",
            "Token ID 13824 = ' Wait'\n",
            "Token ID 71032 = 'WAIT'\n",
            "Token ID 21390 = 'Maybe'\n",
            "Token ID 3090 = 'IV'\n",
            "Token ID 36760 = 'maybe'\n",
            "Token ID 7196 = ' maybe'\n",
            "Token ID 68387 = ' alternatively'\n",
            "Token ID 39 = 'H'\n",
            "Token ID 44 = 'M'\n",
            "Token ID 8365 = ' perhaps'\n",
            "Token ID 8753 = ' AL'\n",
            "Token ID 9654 = 'PER'\n",
            "Token ID 49209 = 'ELY'\n",
            "Token ID 828 = 'AT'\n",
            "Token ID 17854 = ' PER'\n",
            "Token ID 39230 = ' MAY'\n",
            "Token ID 3783 = ' wait'\n",
            "Token ID 10696 = ' Maybe'\n",
            "Token ID 969 = 'AL'\n",
            "Token ID 47945 = 'APS'\n",
            "Token ID 11594 = 'BE'\n",
            "Token ID 18765 = ' Perhaps'\n",
            "Token ID 38478 = ' Alternatively'\n",
            "Token ID 7887 = 'atively'\n",
            "Token ID 3022 = 'AY'\n",
            "Token ID 40412 = 'altern'\n",
            "Token ID 11489 = 'wait'\n",
            "Token ID 14190 = 'Wait'\n",
            "Token ID 92014 = 'Alternatively'\n",
            "Token ID 31476 = 'Perhaps'\n",
            "Token ID 54390 = ' WAIT'\n",
            "Token ID 65272 = 'perhaps'\n",
            "Token ID 10877 = 'TERN'\n",
            "GSM8K not found in evals.tasks.gsm8k. Please ensure you have the latest LM‑Evals installed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GSM8K' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-bac6006b26af>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# Initialize GSM8K benchmark (using parameters: n_problems, n_shots, enable_cot)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0mgsm8k_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_problems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_shots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_cot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0mresults_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsm8k_unblocked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_unblocked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GSM8K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch lm-eval matplotlib pandas tqdm accelerate\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Adapter Class for LM‑Evals Integration ---\n",
        "class TokenBlockingLLMAdapter:\n",
        "    \"\"\"\n",
        "    An adapter that wraps a Hugging Face model and applies token blocking.\n",
        "    It implements the __call__ method required by LM‑Evals (OpenAI Evals).\n",
        "    \"\"\"\n",
        "    def __init__(self, model, tokenizer, blocked_token_ids=None,\n",
        "                 temperature=0.7, top_p=0.9, top_k=40, max_tokens=512):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024,\n",
        "        ).to(self.model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=self.model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        # (Optional) You could track statistics here.\n",
        "        return generated_text\n",
        "\n",
        "    def __call__(self, prompt: str, **kwargs) -> str:\n",
        "        # This makes the adapter compatible with LM‑Evals, which expects a callable that returns a string.\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        # Placeholder for any statistics you want to track.\n",
        "        return {'avg_time': 0, 'avg_tokens': 0}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# Mount Google Drive (if using Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark_1\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (example uses DeepSeek-R1-Distill-Qwen-1.5B)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two adapter instances: one without and one with token blocking.\n",
        "llm_unblocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLMAdapter(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=512\n",
        ")\n",
        "\n",
        "# --- Import GSM8K Benchmark from LM‑Evals ---\n",
        "try:\n",
        "    from evals.tasks.gsm8k import GSM8K\n",
        "except ImportError:\n",
        "    try:\n",
        "        from evals.elsuite.gsm8k import GSM8K\n",
        "    except ImportError:\n",
        "        print(\"GSM8K benchmark not found. Please ensure you have the latest LM‑Evals installed.\")\n",
        "\n",
        "# --- Initialize GSM8K benchmark ---\n",
        "# Here, we set n_problems, n_shots, and enable_cot (chain-of-thought) parameters.\n",
        "gsm8k_unblocked = GSM8K(n_problems=1000, n_shots=3, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\")\n",
        "results_unblocked = gsm8k_unblocked.evaluate(model=llm_unblocked)\n",
        "unblocked_score = results_unblocked  # evaluate() returns a float score\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "gsm8k_blocked = GSM8K(n_problems=1000, n_shots=3, enable_cot=True)\n",
        "print(\"\\n===== Running GSM8K benchmark WITH token blocking =====\")\n",
        "results_blocked = gsm8k_blocked.evaluate(model=llm_blocked)\n",
        "blocked_score = results_blocked  # evaluate() returns a float score\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# --- Create Summary Report and Visualization ---\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {'score': unblocked_score},\n",
        "    'blocked': {'score': blocked_score},\n",
        "    'difference': {'score': blocked_score - unblocked_score}\n",
        "}\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "df = pd.DataFrame([\n",
        "    {'Method': 'Without Blocking', 'GSM8K Score (%)': unblocked_score},\n",
        "    {'Method': 'With Blocking', 'GSM8K Score (%)': blocked_score}\n",
        "])\n",
        "\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df)\n",
        "print(f\"\\nDifference in score: {blocked_score - unblocked_score:.2f} percentage points\")\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'], [unblocked_score, blocked_score],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title(f'GSM8K Score Comparison\\n({model_name})')\n",
        "plt.ylabel('Score (%)')\n",
        "plt.ylim(0, 100)\n",
        "plt.savefig(os.path.join(run_dir, f\"comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 987
        },
        "id": "aJD74-DQcKSC",
        "outputId": "07bc2995-128c-4f20-bedd-68ec92a68e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Results will be saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_1\n",
            "Loading model...\n",
            "\n",
            "Blocking these words: ['wait', 'alternatively', 'perhaps', 'maybe']\n",
            "Corresponding to these 33 token IDs: [13824, 71032, 21390, 3090, 36760, 7196, 68387, 39, 44, 8365, 8753, 9654, 49209, 828, 17854, 39230, 3783, 10696, 969, 47945, 11594, 18765, 38478, 7887, 3022, 40412, 11489, 14190, 92014, 31476, 54390, 65272, 10877]\n",
            "Token ID 13824 = ' Wait'\n",
            "Token ID 71032 = 'WAIT'\n",
            "Token ID 21390 = 'Maybe'\n",
            "Token ID 3090 = 'IV'\n",
            "Token ID 36760 = 'maybe'\n",
            "Token ID 7196 = ' maybe'\n",
            "Token ID 68387 = ' alternatively'\n",
            "Token ID 39 = 'H'\n",
            "Token ID 44 = 'M'\n",
            "Token ID 8365 = ' perhaps'\n",
            "Token ID 8753 = ' AL'\n",
            "Token ID 9654 = 'PER'\n",
            "Token ID 49209 = 'ELY'\n",
            "Token ID 828 = 'AT'\n",
            "Token ID 17854 = ' PER'\n",
            "Token ID 39230 = ' MAY'\n",
            "Token ID 3783 = ' wait'\n",
            "Token ID 10696 = ' Maybe'\n",
            "Token ID 969 = 'AL'\n",
            "Token ID 47945 = 'APS'\n",
            "Token ID 11594 = 'BE'\n",
            "Token ID 18765 = ' Perhaps'\n",
            "Token ID 38478 = ' Alternatively'\n",
            "Token ID 7887 = 'atively'\n",
            "Token ID 3022 = 'AY'\n",
            "Token ID 40412 = 'altern'\n",
            "Token ID 11489 = 'wait'\n",
            "Token ID 14190 = 'Wait'\n",
            "Token ID 92014 = 'Alternatively'\n",
            "Token ID 31476 = 'Perhaps'\n",
            "Token ID 54390 = ' WAIT'\n",
            "Token ID 65272 = 'perhaps'\n",
            "Token ID 10877 = 'TERN'\n",
            "GSM8K benchmark not found. Please ensure you have the latest LM‑Evals installed.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'GSM8K' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dcc7d650750c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;31m# --- Initialize GSM8K benchmark ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;31m# Here, we set n_problems, n_shots, and enable_cot (chain-of-thought) parameters.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m \u001b[0mgsm8k_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGSM8K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_problems\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_shots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_cot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n===== Running GSM8K benchmark WITHOUT token blocking =====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0mresults_unblocked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgsm8k_unblocked\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_unblocked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GSM8K' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch matplotlib pandas tqdm accelerate deepeval datasets\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "from typing import List\n",
        "\n",
        "# Import DeepEval components\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric, ContextualRecallMetric\n",
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.dataset import EvaluationDataset\n",
        "from deepeval.models.base_model import DeepEvalBaseLLM\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Custom DeepEval Model With Token Blocking ---\n",
        "class TokenBlockingLLM(DeepEvalBaseLLM):\n",
        "    \"\"\"\n",
        "    A DeepEval-compatible LLM implementation with token blocking functionality.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        tokenizer,\n",
        "        blocked_token_ids=None,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        top_k=40,\n",
        "        max_tokens=512,\n",
        "        model_name=\"DeepSeek-R1-Distill\"\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "        self._model_name = model_name\n",
        "        self.generation_stats = []\n",
        "\n",
        "    def load_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        model = self.load_model()\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=5000,\n",
        "        ).to(model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        self.generation_stats.append({\n",
        "            'time': generation_time,\n",
        "            'length': len(generated_text)\n",
        "        })\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    async def a_generate(self, prompt: str) -> str:\n",
        "        \"\"\"Async generate implementation required by DeepEval\"\"\"\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def batch_generate(self, prompts: List[str]) -> List[str]:\n",
        "        \"\"\"Batch generation implementation for DeepEval\"\"\"\n",
        "        return [self.generate(prompt) for prompt in prompts]\n",
        "\n",
        "    def get_model_name(self):\n",
        "        \"\"\"Return model name for DeepEval reporting\"\"\"\n",
        "        blocking_status = \"with_blocking\" if self.blocked_token_ids is not None else \"no_blocking\"\n",
        "        return f\"{self._model_name}_{blocking_status}\"\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        \"\"\"Get average statistics from generation runs\"\"\"\n",
        "        if not self.generation_stats:\n",
        "            return {'avg_time': 0, 'avg_length': 0}\n",
        "\n",
        "        avg_time = sum(stat['time'] for stat in self.generation_stats) / len(self.generation_stats)\n",
        "        avg_length = sum(stat['length'] for stat in self.generation_stats) / len(self.generation_stats)\n",
        "\n",
        "        return {'avg_time': avg_time, 'avg_length': avg_length}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# Create directories for results\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"  # Adjust based on your environment\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark_deepeval\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (using DeepSeek-R1-Distill-Qwen-1.5B as in original code)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two model instances: one without and one with token blocking\n",
        "llm_unblocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "# --- Create test dataset with GSM8K problems ---\n",
        "from datasets import load_dataset\n",
        "\n",
        "def create_test_cases_from_gsm8k(num_samples=100):\n",
        "    \"\"\"Create DeepEval test cases from GSM8K dataset\"\"\"\n",
        "    dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
        "    dataset = dataset.shuffle(seed=42).select(range(min(num_samples, len(dataset))))\n",
        "\n",
        "    test_cases = []\n",
        "    for idx, item in enumerate(dataset):\n",
        "        question = item[\"question\"]\n",
        "        answer = item[\"answer\"]\n",
        "\n",
        "        # Extract just the final numeric answer from the GSM8K answer format\n",
        "        final_answer = answer.split(\"####\")[-1].strip()\n",
        "\n",
        "        # Convert context to a list of strings as required by LLMTestCase\n",
        "        context_list = [answer] if answer else None\n",
        "\n",
        "        test_case = LLMTestCase(\n",
        "            input=f\"Solve this math problem step by step: {question}\",\n",
        "            actual_output=\"\",  # Will be filled during evaluation\n",
        "            expected_output=final_answer,\n",
        "            context=context_list  # Context must be a list of strings\n",
        "        )\n",
        "        test_cases.append(test_case)\n",
        "\n",
        "    return test_cases\n",
        "\n",
        "# Removed fallback test cases function as requested\n",
        "\n",
        "# Create an evaluation dataset\n",
        "print(\"Creating evaluation dataset from GSM8K benchmark...\")\n",
        "# You can adjust the number of samples as needed for your experiment\n",
        "test_cases = create_test_cases_from_gsm8k(num_samples=100)\n",
        "evaluation_dataset = EvaluationDataset(test_cases=test_cases)\n",
        "\n",
        "# --- Custom Metrics for Direct Answer Evaluation ---\n",
        "class MathProblemAccuracyEvaluator:\n",
        "    \"\"\"\n",
        "    Simple evaluator that checks if the model's answer contains the correct answer.\n",
        "    No OpenAI API or external services required.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.results = []\n",
        "\n",
        "    def evaluate(self, model, test_cases):\n",
        "        print(f\"Evaluating {len(test_cases)} problems...\")\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.results = []\n",
        "\n",
        "        for i, test_case in enumerate(test_cases):\n",
        "            print(f\"Problem {i+1}/{len(test_cases)}\", end=\"\\r\")\n",
        "            prompt = test_case.input\n",
        "            expected = test_case.expected_output.strip()\n",
        "\n",
        "            # Generate answer using the model\n",
        "            model_answer = model.generate(prompt)\n",
        "\n",
        "            # Simple exact match check - could be improved for more robust checking\n",
        "            contains_answer = expected in model_answer\n",
        "\n",
        "            # Track results\n",
        "            result = {\n",
        "                \"prompt\": prompt,\n",
        "                \"expected\": expected,\n",
        "                \"model_answer\": model_answer,\n",
        "                \"is_correct\": contains_answer\n",
        "            }\n",
        "\n",
        "            self.results.append(result)\n",
        "\n",
        "            if contains_answer:\n",
        "                self.correct_count += 1\n",
        "            self.total_count += 1\n",
        "\n",
        "        accuracy = self.correct_count / self.total_count if self.total_count > 0 else 0\n",
        "        print(f\"\\nEvaluation complete. Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "        return {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"correct_count\": self.correct_count,\n",
        "            \"total_count\": self.total_count,\n",
        "            \"detailed_results\": self.results\n",
        "        }\n",
        "\n",
        "# --- Run evaluations ---\n",
        "print(\"\\n===== Running evaluation WITHOUT token blocking =====\")\n",
        "evaluator = MathProblemAccuracyEvaluator()\n",
        "unblocked_results = evaluator.evaluate(\n",
        "    model=llm_unblocked,\n",
        "    test_cases=test_cases\n",
        ")\n",
        "\n",
        "# Clean up memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"\\n===== Running evaluation WITH token blocking =====\")\n",
        "evaluator = MathProblemAccuracyEvaluator()\n",
        "blocked_results = evaluator.evaluate(\n",
        "    model=llm_blocked,\n",
        "    test_cases=test_cases\n",
        ")\n",
        "\n",
        "# --- Collect and analyze results ---\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# Create result summary\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {\n",
        "        'accuracy': unblocked_results['accuracy'],\n",
        "        'correct_count': unblocked_results['correct_count'],\n",
        "        'total_count': unblocked_results['total_count'],\n",
        "        'avg_response_time': unblocked_stats['avg_time'],\n",
        "        'avg_response_length': unblocked_stats['avg_length']\n",
        "    },\n",
        "    'blocked': {\n",
        "        'accuracy': blocked_results['accuracy'],\n",
        "        'correct_count': blocked_results['correct_count'],\n",
        "        'total_count': blocked_results['total_count'],\n",
        "        'avg_response_time': blocked_stats['avg_time'],\n",
        "        'avg_response_length': blocked_stats['avg_length']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary to file\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "# Save detailed results for further analysis\n",
        "detailed_results_filepath = os.path.join(run_dir, f\"detailed_results_{timestamp}.json\")\n",
        "with open(detailed_results_filepath, 'w') as f:\n",
        "    json.dump({\n",
        "        \"unblocked_results\": unblocked_results[\"detailed_results\"],\n",
        "        \"blocked_results\": blocked_results[\"detailed_results\"]\n",
        "    }, f, indent=2)\n",
        "\n",
        "# Create comparison dataframe\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Metric': 'Accuracy',\n",
        "        'Without Blocking': summary['unblocked']['accuracy'],\n",
        "        'With Blocking': summary['blocked']['accuracy'],\n",
        "        'Difference': summary['blocked']['accuracy'] - summary['unblocked']['accuracy']\n",
        "    },\n",
        "    {\n",
        "        'Metric': 'Avg Response Time (s)',\n",
        "        'Without Blocking': summary['unblocked']['avg_response_time'],\n",
        "        'With Blocking': summary['blocked']['avg_response_time'],\n",
        "        'Difference': summary['blocked']['avg_response_time'] - summary['unblocked']['avg_response_time']\n",
        "    },\n",
        "    {\n",
        "        'Metric': 'Avg Response Length',\n",
        "        'Without Blocking': summary['unblocked']['avg_response_length'],\n",
        "        'With Blocking': summary['blocked']['avg_response_length'],\n",
        "        'Difference': summary['blocked']['avg_response_length'] - summary['unblocked']['avg_response_length']\n",
        "    }\n",
        "]\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df_comparison)\n",
        "\n",
        "# Save comparison to CSV\n",
        "df_comparison.to_csv(os.path.join(run_dir, f\"comparison_{timestamp}.csv\"), index=False)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['accuracy'], summary['blocked']['accuracy']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.xlabel('Model Configuration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'GSM8K Problem Solving Accuracy\\n({model_name})')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add accuracy values on top of bars\n",
        "for i, v in enumerate([summary['unblocked']['accuracy'], summary['blocked']['accuracy']]):\n",
        "    plt.text(i, v + 0.02, f\"{v:.2%}\", ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"accuracy_comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "# Additional visualization for response time and length\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['avg_response_time'], summary['blocked']['avg_response_time']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Response Time')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['avg_response_length'], summary['blocked']['avg_response_length']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Response Length')\n",
        "plt.ylabel('Characters')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"performance_comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n",
        "\n",
        "# --- Optional: Run a simple test to verify token blocking works ---\n",
        "def test_token_blocking():\n",
        "    print(\"\\n===== Simple Token Blocking Test =====\")\n",
        "    test_prompt = \"What approach should I take to solve this problem?\"\n",
        "\n",
        "    print(\"Without blocking:\")\n",
        "    unblocked_response = llm_unblocked.generate(test_prompt)\n",
        "    print(unblocked_response)\n",
        "\n",
        "    print(\"\\nWith blocking:\")\n",
        "    blocked_response = llm_blocked.generate(test_prompt)\n",
        "    print(blocked_response)\n",
        "\n",
        "    # Count occurrences of blocked words\n",
        "    blocked_word_counts_unblocked = {word: unblocked_response.lower().count(word.lower()) for word in words_to_block}\n",
        "    blocked_word_counts_blocked = {word: blocked_response.lower().count(word.lower()) for word in words_to_block}\n",
        "\n",
        "    print(\"\\nBlocked word counts in unblocked response:\")\n",
        "    print(blocked_word_counts_unblocked)\n",
        "\n",
        "    print(\"\\nBlocked word counts in blocked response:\")\n",
        "    print(blocked_word_counts_blocked)\n",
        "\n",
        "# Run the test at the end\n",
        "test_token_blocking()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "64a1a93826484a69955d47b4dfeaba6c",
            "a801f4f4f90c4cc4815a5f18e9dd0b58",
            "6d4808427e3142d2ac2702ddcfdce9d8",
            "1b41db0dd39d40bd8d07074036bac250",
            "13b4ddddf3f94fb3b9debfab21951538",
            "bf7515b47a104809a8b8c6059f2fbd14",
            "f2f148fc4a6b48db9426833cb92b2018",
            "bfc43c1efc8f49e49d2b28547d168f0c",
            "05f38c0cb153435d8f72fe41ad1c1df7",
            "52ad18a33e3740fa99984262e35f6d60",
            "3de282c27bd84032be34d290ce53b0d4",
            "12d0277a06084a36b6d40fd88ca50418",
            "cb77a68187714a91a9feec676a2fe01d",
            "519c7bf1df494f03b8db6c096f10e0e0",
            "cc081272143f4430a0a6d5920b90b6c0",
            "b19b071b9723435094c45ef760b6e074",
            "38cdedb23f144e8da05da8a19a6fec2d",
            "e732c042ccba4727afe80fccfceaabc1",
            "1bf3631ffe774cf9812bacce7262533e",
            "7f39470adb7b49f6955129252c756792",
            "0b07b4c9c9134a5eb1678598ddf4da83",
            "191a251d35b94e7bb9991a62219a826d",
            "a504479262e94a459d9f3bb19448269c",
            "41260f9d2f854389a35f18a8488e357b",
            "55466afcd80648019af1f170835475c6",
            "52c8ac63dea94b54acd47dfbd956a1a3",
            "5bd81d2972f6433aa926a8b65762def1",
            "2b1a0482df424161879bbd3a20b2eed1",
            "87b04eefe1fe4b41baa173928d81df7a",
            "84178162a8db48e0abc60be1eee05546",
            "d7ccfc10746f41349769307962e22a47",
            "e0c55112ec224c2cb6362c35d26d24b4",
            "98dac2f0f81145ce8d81048b713f636e",
            "4d82d549634b4614a27954a2dc102b1a",
            "3fcddc8268024d8abc4d2a70b6a94966",
            "5c55922f0d1b4cb48ba148a553c4c857",
            "babda70d1d5d49ebac15d33191d40a29",
            "8f1c5440328f4b9498f8393bf605b021",
            "ad10ac4db7d04603b877eb6ad86a6437",
            "389d2b81257a4db8991acdafc7a3c00b",
            "0381c3fb42c248f7af6dc14ce5b582d6",
            "164d28a42b4647cda3d4d45a23bf89cf",
            "635683a3f7a34794a0a2184192e8bbee",
            "6261f6f1a4d743faac04281c0ff563ab",
            "331ebd97d4ea4902875b8976a0db4062",
            "6056aebac181427b9ecea05210d14b07",
            "0c85af66a1694ce6a2db40b44a923208",
            "97b36e7cc4384687bce2f72ccbb933f8",
            "187c7321268347b88dd5e468bf86df07",
            "39f8a993f6a942b0971608ebe538003d",
            "eae2d1c12c4e4088b36a1c358ba18d0b",
            "5373edae1d6d44c3b83d537501ac883e",
            "fe302a7098b348d282cbf6549cb131c3",
            "45741fcd9d48466f97ad0b6e1ec0646b",
            "4fc6129aaf0947daa673ed2f5f9aa9ea"
          ]
        },
        "id": "hHM6Dpqcck4d",
        "outputId": "1438a774-ad00-4812-83fd-02709a1bac48"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results will be saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_deepeval\n",
            "Loading model...\n",
            "\n",
            "Blocking these words: ['wait', 'alternatively', 'perhaps', 'maybe']\n",
            "Corresponding to these 33 token IDs: [13824, 71032, 21390, 3090, 36760, 7196, 68387, 39, 44, 8365, 8753, 9654, 49209, 828, 17854, 39230, 3783, 10696, 969, 47945, 11594, 18765, 38478, 7887, 3022, 40412, 11489, 14190, 92014, 31476, 54390, 65272, 10877]\n",
            "Token ID 13824 = ' Wait'\n",
            "Token ID 71032 = 'WAIT'\n",
            "Token ID 21390 = 'Maybe'\n",
            "Token ID 3090 = 'IV'\n",
            "Token ID 36760 = 'maybe'\n",
            "Token ID 7196 = ' maybe'\n",
            "Token ID 68387 = ' alternatively'\n",
            "Token ID 39 = 'H'\n",
            "Token ID 44 = 'M'\n",
            "Token ID 8365 = ' perhaps'\n",
            "Token ID 8753 = ' AL'\n",
            "Token ID 9654 = 'PER'\n",
            "Token ID 49209 = 'ELY'\n",
            "Token ID 828 = 'AT'\n",
            "Token ID 17854 = ' PER'\n",
            "Token ID 39230 = ' MAY'\n",
            "Token ID 3783 = ' wait'\n",
            "Token ID 10696 = ' Maybe'\n",
            "Token ID 969 = 'AL'\n",
            "Token ID 47945 = 'APS'\n",
            "Token ID 11594 = 'BE'\n",
            "Token ID 18765 = ' Perhaps'\n",
            "Token ID 38478 = ' Alternatively'\n",
            "Token ID 7887 = 'atively'\n",
            "Token ID 3022 = 'AY'\n",
            "Token ID 40412 = 'altern'\n",
            "Token ID 11489 = 'wait'\n",
            "Token ID 14190 = 'Wait'\n",
            "Token ID 92014 = 'Alternatively'\n",
            "Token ID 31476 = 'Perhaps'\n",
            "Token ID 54390 = ' WAIT'\n",
            "Token ID 65272 = 'perhaps'\n",
            "Token ID 10877 = 'TERN'\n",
            "Creating evaluation dataset from GSM8K benchmark...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "64a1a93826484a69955d47b4dfeaba6c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12d0277a06084a36b6d40fd88ca50418",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a504479262e94a459d9f3bb19448269c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4d82d549634b4614a27954a2dc102b1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "331ebd97d4ea4902875b8976a0db4062",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Running evaluation WITHOUT token blocking =====\n",
            "Evaluating 100 problems...\n",
            "Problem 1/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 2/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 3/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 4/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 5/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 6/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 7/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 8/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 9/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 10/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 11/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 12/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 13/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 14/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 15/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 16/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 17/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 18/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 19/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 20/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 21/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 22/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 23/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 24/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 25/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 26/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 27/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 28/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 29/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 30/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 31/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 32/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 33/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 34/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 35/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 36/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 37/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 38/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 39/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 40/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 41/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 42/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 43/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 44/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 45/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 46/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 47/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 48/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 49/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 50/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 51/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 52/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 53/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 54/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 55/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 56/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 57/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 58/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 59/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 60/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 61/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 62/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 63/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 64/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 65/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 66/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 67/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 68/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 69/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 70/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 71/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 72/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 73/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 74/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 75/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 76/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 77/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 78/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 79/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 80/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 81/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 82/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 83/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 84/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 85/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 86/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 87/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 88/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 89/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 90/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 91/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 92/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 93/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 94/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 95/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 96/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 97/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 98/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 99/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 100/100\r\n",
            "Evaluation complete. Accuracy: 85.00%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Running evaluation WITH token blocking =====\n",
            "Evaluating 100 problems...\n",
            "Problem 1/100\r"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Problem 2/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 3/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 4/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 5/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 6/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 7/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 8/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 9/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 10/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 11/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 12/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 13/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 14/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 15/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 16/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 17/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 18/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 19/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 20/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 21/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 22/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 23/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 24/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 25/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 26/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 27/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 28/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 29/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 30/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 31/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 32/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 33/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 34/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 35/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 36/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 37/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 38/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 39/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 40/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 41/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 42/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 43/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 44/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 45/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 46/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 47/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 48/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 49/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 50/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 51/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 52/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 53/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 54/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 55/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 56/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 57/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 58/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 59/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 60/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 61/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 62/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 63/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 64/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 65/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 66/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 67/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 68/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 69/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 70/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 71/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 72/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 73/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 74/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 75/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 76/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 77/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 78/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 79/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 80/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 81/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 82/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 83/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 84/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 85/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 86/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 87/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 88/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 89/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 90/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 91/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 92/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 93/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 94/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 95/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 96/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 97/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 98/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 99/100\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 100/100\r\n",
            "Evaluation complete. Accuracy: 81.00%\n",
            "\n",
            "===== Final Results =====\n",
            "                  Metric  Without Blocking  With Blocking   Difference\n",
            "0               Accuracy          0.850000       0.810000    -0.040000\n",
            "1  Avg Response Time (s)         91.036972      70.906854   -20.130118\n",
            "2    Avg Response Length       7561.080000    6366.140000 -1194.940000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All results saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_deepeval/run_20250321_023511\n",
            "\n",
            "===== Simple Token Blocking Test =====\n",
            "Without blocking:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " I'm trying to find the number of positive integers n ≤ X such that n! is divisible by n^k, where k is a positive integer. Hmm, okay, let's see.\n",
            "To start, I need to understand what the problem is asking. I need to find the number of positive integers n ≤ X such that n! is divisible by n^k. Hmm, so n! is divisible by n^k, which means that n^k divides n!. That is, n^k | n!. So, we can write this as n^k divides n factorial. So, for each n, I need to check whether n^k divides n!, and then count the number of such n's that satisfy this condition.\n",
            "\n",
            "But wait, n is a positive integer less than or equal to X, so for each n from 1 to X, I need to check whether n^k divides n!. But that seems computationally intensive if X is large because factorials can get very big, and checking divisibility for each n might be time-consuming.\n",
            "\n",
            "Alternatively, maybe there's a mathematical approach or formula to compute this without checking each n individually. Let me think about the properties of factorials and divisibility.\n",
            "\n",
            "First, n! is the product of all integers from 1 to n. So, n! = 1 × 2 × 3 × ... × n. Now, n^k is n multiplied by itself k times. So, n^k = n × n × ... × n (k times). Therefore, for n^k to divide n!, each prime factor in n^k must be present in n! with at least the same multiplicity.\n",
            "\n",
            "But wait, n! includes all integers from 1 to n, so the prime factors of n! include all primes less than or equal to n. Now, n^k is n raised to the power k. So, the exponents of the primes in n^k will depend on the exponents in n.\n",
            "\n",
            "Let me think about the exponents of a prime p in n^k. For a prime p, the exponent in n is equal to the sum of the digits in the base-p representation of n. Wait, no, that's not correct. Actually, the exponent of p in n is the sum of the digits of n when written in base p. But perhaps it's better to recall Legendre's formula, which gives the exponent of a prime p in n!.\n",
            "\n",
            "Legendre's formula states that the exponent of a prime p in n! is given by the sum from i=1 to infinity of floor(n / p^i). So, it's a way to calculate the exponent of p in n!.\n",
            "\n",
            "So, for n^k to divide n!, the exponent of each prime p in n^k must be less than or equal to the exponent of p in n!.\n",
            "\n",
            "But n^k is equal to n × n × ... × n (k times). So, the exponent of p in n^k is equal to k times the exponent of p in n.\n",
            "\n",
            "Therefore, for each prime p, the exponent of p in n^k is k * v_p(n), where v_p(n) is the exponent of p in n.\n",
            "\n",
            "So, for n^k to divide n!, we need that for each prime p ≤ n, the exponent of p in n! is at least k * v_p(n).\n",
            "\n",
            "But wait, let me check that. Because n^k is a product of n's, so each n contributes v_p(n) to the exponent of p in n^k.\n",
            "\n",
            "But in n!, each number from 1 to n contributes their own v_p(n). So, the total exponent of p in n! is the sum of v_p(m) for m from 1 to n. So, to have n^k divide n!, we need that for each prime p, the sum of v_p(m) for m from 1 to n is at least k * v_p(n).\n",
            "\n",
            "So, the condition is that for each prime p, sum_{m=1}^n v_p(m) ≥ k * v_p(n).\n",
            "\n",
            "Hmm, that seems a bit complicated, but maybe we can find a way to compute this.\n",
            "\n",
            "Alternatively, perhaps we can think in terms of Legendre's formula. For each prime p, the exponent in n! is sum_{i=1}^∞ floor(n / p^i). So, for each prime p, we need sum_{i=1}^∞ floor(n / p^i) ≥ k * v_p(n). Hmm.\n",
            "\n",
            "But wait, maybe we can consider the exponent of p in n^k, which is k * v_p(n), and the exponent in n! is sum_{i=1}^∞ floor(n / p^i). So, for each p, we need that sum_{i=1}^∞ floor(n / p^i) ≥ k * v_p(n).\n",
            "\n",
            "Alternatively, perhaps we can use the concept of the highest power of p dividing n! and comparing it with k times the highest power of p dividing n.\n",
            "\n",
            "Wait, but n is a variable here, so perhaps for each prime p, we can determine whether the exponent in n! is at least k times the exponent in n.\n",
            "\n",
            "But perhaps it's better to think about each prime p separately.\n",
            "\n",
            "So, for each prime p, we can compute the exponent of p in n! as sum_{i=1}^∞ floor(n / p^i). The exponent of p in n is v_p(n) = sum_{i=1}^∞ floor(n / p^i) - floor(n / p^{i+1}) for some i, but maybe that's more complicated.\n",
            "\n",
            "Wait, no, actually, the exponent of p in n is the sum of the digits of n in base p, but that's only when n is in base p. Wait, no, Legendre's formula is sum_{i=1}^∞ floor(n / p^i). So, for example, the exponent of 2 in 8 is 3 because 8 is 2^3.\n",
            "\n",
            "But perhaps for a given prime p, to compute v_p(n), we can use Legendre's formula.\n",
            "\n",
            "So, to check whether n^k divides n!, for each prime p, the exponent of p in n! must be at least k times the exponent of p in n.\n",
            "\n",
            "Therefore, for each prime p, we need sum_{i=1}^∞ floor(n / p^i) ≥ k * v_p(n).\n",
            "\n",
            "So, perhaps we can compute this condition for each prime p ≤ n, and then the overall condition is satisfied if all these conditions are met for each p.\n",
            "\n",
            "But this seems a bit abstract. Maybe we can find a way to compute for each n whether all these conditions are satisfied, and then count the number of n ≤ X satisfying this.\n",
            "\n",
            "Alternatively, perhaps we can find an expression for n such that n^k divides n!, and then count how many such n are ≤ X.\n",
            "\n",
            "But perhaps it's better to consider that n^k divides n! if and only if for each prime p ≤ n, the exponent of p in n! is at least k times the exponent of p in n.\n",
            "\n",
            "So, for each n, we can factorize n into its prime factors, compute v_p(n) for each p, then compute the exponent of p in n! using Legendre's formula, and check whether it's at least k * v_p(n).\n",
            "\n",
            "If this holds for all primes p ≤ n, then n^k divides n!, and we can count such n's.\n",
            "\n",
            "But this seems computationally intensive, especially for large X.\n",
            "\n",
            "Alternatively, perhaps we can find a way to characterize n such that n^k divides n!.\n",
            "\n",
            "Wait, let me think about small values of k.\n",
            "\n",
            "Suppose k = 1. Then, n^1 divides n!, which is always true because n! = 1 × 2 × ... × n, so it's a multiple of n. Therefore, for k = 1, every n ≤ X satisfies the condition, so the count is X.\n",
            "\n",
            "But for k ≥ 2, it's more complicated.\n",
            "\n",
            "Let me take an example with k = 2.\n",
            "\n",
            "So, for each n, we need to check if n^2 divides n!.\n",
            "\n",
            "But let's compute for n = 1: 1^2 = 1 divides 1! = 1. So, yes.\n",
            "\n",
            "n = 2: 2^2 = 4. 2! = 2, which is not divisible by 4. So, no.\n",
            "\n",
            "n = 3: 3^2 = 9. 3! = 6, which is not divisible by 9. So, no.\n",
            "\n",
            "n = 4: 4^2 = 16. 4! = 24, which is 24. 24 divided by 16 is 1.5, which is not an integer. So, no.\n",
            "\n",
            "n = 5: 5^2 = 25. 5! = 120. 120 divided by 25 is 4.8, not integer. No.\n",
            "\n",
            "n = 6: 6^2 = 36. 6! = 720. 720 divided by 36 is 20, which is integer. So, yes.\n",
            "\n",
            "Wait, so n = 6 is okay. Let me check.\n",
            "\n",
            "n = 7: 7^2 = 49. 7! = 5040. 5040 / 49 is 102.857..., which is not integer. So, no.\n",
            "\n",
            "n = 8: 8^2 = 64. 8! = 40320. 40320 / 64 = 630, which is integer. So, yes.\n",
            "\n",
            "Wait, so n = 8 is okay.\n",
            "\n",
            "Wait, but 8! = 40320, which is 64 × 630 = 40320.\n",
            "\n",
            "Hmm, okay, so for k = 2, n = 6, 8, 10, etc., satisfy the condition.\n",
            "\n",
            "Wait, but let me check n = 9: 9^2 = 81. 9! = 362880. 362880 / 81 = 4480, which is integer. So, yes, n = 9 is okay.\n",
            "\n",
            "Wait, but 9! is 362880, which is 9 × 8 × 7 × 6 × 5 × 4 × 3 × 2 × 1, which includes 9 as a factor. So, 9^2 divides 9!.\n",
            "\n",
            "Wait, but 9! includes 9, but 9^2 is 81, which is 9 × 9. So, to have 81 divide 9!, we need to check if 9 appears at least twice in the prime factors of 9!.\n",
            "\n",
            "In 9!, the prime factors include 3^4, because:\n",
            "\n",
            "Number of 3s in 9! is floor(9/3) + floor(9/9) = 3 + 1 = 4.\n",
            "\n",
            "So, 3^4 is a factor. So, 3^4 × 2^3 × 5 × 7 × ... = 9! So, 9! has 3^4, which is 81, so 81 divides 9!.\n",
            "\n",
            "So, 9! / 81 is an integer.\n",
            "\n",
            "Similarly, 10^2 = 100. 10! includes 10 as a factor, but how many 2s and 5s are there?\n",
            "\n",
            "In 10!, there are 2^8 × 5^2 × ... So, 5^2 is 25, which is a factor of 100, so 25 divides 10!, so 100 divides 10! as well.\n",
            "\n",
            "Wait, but 100 is 10 × 10, so 10! must have at least two 10s in its prime factors? No, 10! includes 10 as a single factor. But 10! includes 10 × 10 as a product, but actually, 10! includes 10 as a single number, but when we factor into primes, 10 is 2 × 5, so 10! includes 2 × 5 twice, once from 10 and once from the other numbers. So, 10! has 2^8 × 5^2 × ... So, 100 is 2^2 × 5^2, which is a factor of 10!, so 100 divides 10!.\n",
            "\n",
            "Wait, but 10! is 3628800. 3628800 / 100 = 36288, which is an integer. So, yes, 100 divides 10!.\n",
            "\n",
            "Wait, but 10^2 = 100, and 10! has 2^8 × 5^2, which is exactly 100. So, yes, 100 divides 10!.\n",
            "\n",
            "So, for k = 2, n = 6, 8, 9, 10 are okay.\n",
            "\n",
            "Wait, let me check n = 12. 12^2 = 144. 12! is 479001600. 479001600 / 144 = 331800, which is integer. So, yes.\n",
            "\n",
            "Wait, but 12! has 12 as a factor, but to have 12^2 divide 12!, we need 12 × 12 to divide 12!, so 12^2 = 144. 12! includes 12 × 11 × ... × 1, so 12! includes 12 as a single factor, but does it have another 12? No, because 12! is 12 × 11 × 10 × 9 × 8 × 7 × 6 × 5 × 4 × 3 × 2 × 1. So, it's 12 × (11 × 10 × 9 × ... × 1). So, the number of 12s in 12! is only one. Therefore, 12! has 12 × 12 as a factor only if 12! includes 12 × 12, which would require 12 to be present twice in the prime factors.\n",
            "\n",
            "But 12! has 12 as a single factor, so it's only 12 × (other factors). Therefore, 12! does not have 12^2 as a factor, so 12^2 does not divide 12!.\n",
            "\n",
            "Wait, that contradicts my earlier calculation. Wait, 12! is 479001600. 479001600 divided by 144 is 331800, which is an integer. So, why is that? Because 12! includes 12 as a single factor, but in the prime factorization, 12 is 2^2 × 3, so 12! includes 2^10 × 3^5 × ... etc. Wait, but 12^2 is 2^4 × 3^2. So, 12! includes 2^10 and 3^5, so 12! includes 2^4 and 3^2, so 12^2 divides 12!.\n",
            "\n",
            "Wait, so perhaps my earlier reasoning was incorrect because I thought that 12! only had one 12, but in reality, it has 12 as a single factor, but in the prime factors, it's 2^2 × 3, which is 12, and 12! includes 2^10 × 3^5, so 12^2 is 2^4 × 3^2, which is indeed a factor of 12!.\n",
            "\n",
            "Wait, so perhaps n^k divides n! for any n when k ≥ 2? But that can't be the case, because when n is a prime number, n^k would require that n^k divides n!, but n! includes n once, so n^k would require that n is present k times, which is impossible unless k = 1. So, for prime n, n^k does not divide n! because n! only has n^1 in its prime factors.\n",
            "\n",
            "So, for example, take n = 5. 5^2 = 25. 5! = 120. 120 divided by 25 is 4.8, which is not an integer. So, 25 does not divide 120, so 5^2 does not divide 5!.\n",
            "\n",
            "Similarly, for n = 7, 7^2 = 49. 7! = 5040. 5040 divided by 49 is 102.857..., which is not an integer. So, 49 does not divide 5040.\n",
            "\n",
            "So, in the case of prime numbers, n^k does not divide n! for any k ≥ 2.\n",
            "\n",
            "So, for k ≥ 2, n must be composite, or at least have enough factors to cover n^k.\n",
            "\n",
            "Wait, but n can be composite, but not necessarily square-free. So, perhaps the approach is to find for each n whether the exponents of all primes in n^k are less than or equal to their exponents in n!.\n",
            "\n",
            "So, perhaps the problem can be approached by considering that for n^k to divide n!, all primes p dividing n must have their exponents in n! at least k times their exponents in n.\n",
            "\n",
            "Wait, but n is the base, so n^k is n multiplied by itself k times. So, for each prime p, the exponent of p in n^k is k times the exponent of p in n.\n",
            "\n",
            "So, the condition is that for each prime p, the exponent of p in n! is at least k times the exponent of p in n.\n",
            "\n",
            "Therefore, for each n, we can compute v_p(n) for each prime p ≤ n, and then check if sum_{i=1}^∞ floor(n / p^i) ≥ k * v_p(n) for each p.\n",
            "\n",
            "If this is true for all primes p, then n^k divides n!.\n",
            "\n",
            "So, the approach is:\n",
            "\n",
            "1. For each n from 1 to X, check whether for every prime p ≤ n, the exponent of p in n! is at least k times the exponent of p in n.\n",
            "\n",
            "2. If this condition holds for all p, then count n.\n",
            "\n",
            "But for large X, this approach is computationally intensive because for each n, we have to factorize n into primes, compute v_p(n) for each p, then compute the sum of floor(n / p^i) for each p, and check if it's at least k * v_p(n).\n",
            "\n",
            "Alternatively, perhaps we can find a way to compute this without checking each n individually.\n",
            "\n",
            "Wait, perhaps the number of n's that satisfy the condition is equal to the number of n's where n is a product of primes such that their exponents in n are sufficiently covered by n! when raised to the power k.\n",
            "\n",
            "But I'm not sure.\n",
            "\n",
            "Wait, maybe let's think about n = m^k, for some m. Then, n^k = (m^k)^k = m^{k^2}, and n! = (m^k)!.\n",
            "\n",
            "So, to have n^k divide n!, we need that m^{k^2} divides (m^k)!.\n",
            "\n",
            "But, for example, let m = 2 and k = 2. Then, n = 4, and n! = 24. n^2 = 16, which does not divide 24, so that approach doesn't work.\n",
            "\n",
            "Alternatively, perhaps n is a multiple of n^k, which is only possible if n^k divides n!, which seems only possible when n is 1, but n=1, 1^k = 1, and 1! = 1, so it works.\n",
            "\n",
            "Wait, but for n=1, 1^k = 1, and 1! = 1, so it's okay.\n",
            "\n",
            "Wait, perhaps I can think in terms of the multiplicity of n in n!.\n",
            "\n",
            "Wait, but perhaps it's better to look for a mathematical formula or approach to compute the number of n's ≤ X such that n^k divides n!.\n",
            "\n",
            "Alternatively, perhaps I can find that for each prime p, the exponent of p in n! is at least k times the exponent of p in n.\n",
            "\n",
            "So, for each prime p, the exponent in n! is sum_{i=1}^∞ floor(n / p^i).\n",
            "\n",
            "The exponent in n is v_p(n) = sum_{i=1}^∞ floor(n / p^i) - floor(n / p^{i+1}).\n",
            "\n",
            "Wait, but perhaps for a given p, the exponent in n! is always greater than or equal to the exponent in n multiplied by k.\n",
            "\n",
            "Wait, but perhaps not, because when n is a multiple of p, then v_p(n) is at least 1, but v_p(n!) is more than that.\n",
            "\n",
            "Wait, perhaps we can find for each prime p, the minimal n such that sum_{i=1}^∞ floor(n / p^i) < k * v_p(n).\n",
            "\n",
            "Wait, but that's not helpful.\n",
            "\n",
            "Alternatively, perhaps for each prime p, the exponent in n! is at least k times the exponent in n, so for each prime p, we can write:\n",
            "\n",
            "sum_{i=1}^∞ floor(n / p^i) ≥ k * v_p(n).\n",
            "\n",
            "But v_p(n) is the exponent of p in n, which is sum_{i=1}^∞ floor(n / p^i) - floor(n / p^{i+1}).\n",
            "\n",
            "Wait, maybe that's too complicated.\n",
            "\n",
            "Alternatively, perhaps we can note that for each prime p, the exponent in n! is at least k times the exponent in n.\n",
            "\n",
            "So, perhaps for each n, the condition is that for each prime p ≤ n, sum_{i=1}^∞ floor(n / p^i) ≥ k * v_p(n).\n",
            "\n",
            "But this seems difficult to compute for each n.\n",
            "\n",
            "Wait, maybe for each n, the condition is equivalent to sum_{i=1}^∞ floor(n / p^i) ≥ k * sum_{i=1}^∞ floor(n / p^{i+1}).\n",
            "\n",
            "Wait, because v_p(n) = sum_{i=1}^∞ floor(n / p^i) - floor(n / p^{i+1}).\n",
            "\n",
            "Wait, so perhaps we can write:\n",
            "\n",
            "sum_{i=1}^∞ floor(n / p^i) ≥ k * (sum_{i=1}^∞ floor(n / p^{i+1})).\n",
            "\n",
            "Which is sum_{i=1}^∞ floor(n / p^i) ≥ k * sum_{i=2}^∞ floor(n / p^i).\n",
            "\n",
            "Hmm, which simplifies to floor(n / p) ≥ (k) * floor(n / p^2).\n",
            "\n",
            "Wait, that's an interesting condition.\n",
            "\n",
            "So, for each prime p, and each n, the condition floor(n / p) ≥ k * floor(n / p^2).\n",
            "\n",
            "Wait, but this is a necessary condition for the exponent in n! to be at least k times the exponent in n.\n",
            "\n",
            "Wait, but perhaps we can use this to find for each n, whether it satisfies\n",
            "\n",
            "With blocking:\n",
            " The problem is: Let $X_1, X_2, \\dots, X_n$ be random variables such that for each $i$, $X_i$ is either 0 or 1, and $E[X_i] = p_i$ for each $i$. Let $A$ be the event that $X_1 + X_2 + \\dots + X_n \\leq t$. Let $B$ be the event that $X_1 + X_2 + \\dots + X_n \\geq s$. Let $C$ be the event that $X_1 + X_2 + \\dots + X_n \\leq t$ or $X_1 + X_2 + \\dots + X_n \\geq s$. Suppose that $A$, $B$, and C are mutually exclusive. What is the probability that $X_1 + X_2 + \\dots + X_n \\leq t$ or $X_1 + X_2 + \\dots + X_n \\geq s$?\n",
            "\n",
            "To solve this problem, I need to take...?\n",
            "</think>\n",
            "\n",
            "To solve this problem, let's outline the approach step by step.\n",
            "\n",
            "**Problem Statement:**\n",
            "We have random variables \\( X_1, X_2, \\dots, X_n \\) where each \\( X_i \\) is either 0 or 1, and the expected value \\( E[X_i] = p_i \\) for each \\( i \\). We are given events:\n",
            "- \\( A \\): \\( X_1 + X_2 + \\dots + X_n \\leq t \\)\n",
            "- \\( B \\): \\( X_1 + X_2 + \\dots + X_n \\geq s \\)\n",
            "- \\( C \\): \\( X_1 + X_2 + \\dots + X_n \\leq t \\) or \\( X_1 + X_2 + \\dots + X_n \\geq s \\)\n",
            "\n",
            "It is given that \\( A \\), \\( B \\), and \\( C \\) are mutually exclusive. The goal is to find the probability that \\( X_1 + X_2 + \\dots + X_n \\leq t \\) or \\( X_1 + X_2 + \\dots + X_n \\geq s \\).\n",
            "\n",
            "**Approach:**\n",
            "\n",
            "1. **Understanding Mutual Exclusivity:**\n",
            "   Since \\( A \\), \\( B \\), and \\( C \\) are mutually exclusive, they cannot occur simultaneously. This implies:\n",
            "   - \\( A \\) and \\( B \\) cannot both be true.\n",
            "   - \\( A \\) and \\( C \\) cannot both be true.\n",
            "   - \\( B \\) and \\( C \\) cannot both be true.\n",
            "\n",
            "2. **Analyzing the Union of \\( A \\) and \\( B \\):**\n",
            "   The event \\( C \\) represents the union of \\( A \\) and \\( B \\), i.e., \\( C = A \\cup B \\). However, since \\( A \\) and \\( B \\) are mutually exclusive, \\( C \\) simplifies to \\( C = A + B \\).\n",
            "\n",
            "3. **Calculating the Probability of \\( C \\):**\n",
            "   Since \\( A \\), \\( B \\), and \\( C \\) are mutually exclusive, the probability of their union is the sum of their individual probabilities:\n",
            "   \\[\n",
            "   P(C) = P(A) + P(B) + P(C)\n",
            "   \\]\n",
            "   However, since \\( C \\) is the union of \\( A \\) and \\( B \\), and they are mutually exclusive, this simplifies to:\n",
            "   \\[\n",
            "   P(C) = P(A) + P(B)\n",
            "   \\]\n",
            "   But since \\( C = A \\cup B \\), and they are mutually exclusive, \\( P(C) = P(A) + P(B) \\).\n",
            "\n",
            "4. **Expressing the Desired Probability:**\n",
            "   The desired probability is \\( P(C) = P(A \\cup B) \\). Since \\( A \\), \\( B \\), and \\( C \\) are mutually exclusive, this is simply the sum of their probabilities:\n",
            "   \\[\n",
            "   P(A \\cup B) = P(A) + P(B) + P(C)\n",
            "   \\]\n",
            "   However, since \\( A \\), \\( B \\), and \\( C \\) are mutually exclusive, \\( P(C) = P(A) + P(B) \\), so:\n",
            "   \\[\n",
            "   P(A \\cup B) = P(A) + P(B) + (P(A) + P(B)) = 2P(A) + 2P(B)\n",
            "   \\]\n",
            "   But since \\( A \\) and \\( B \\) are mutually exclusive, \\( P(A \\cup B) = P(A) + P(B) \\).\n",
            "\n",
            "5. **Conclusion:**\n",
            "   Therefore, the probability that \\( X_1 + X_2 + \\dots + X_n \\leq t \\) or \\( X_1 + X_2 + \\dots + X_n \\geq s \\) is simply \\( P(A) + P(B) \\).\n",
            "\n",
            "**Answer:**\n",
            "\n",
            "\\boxed{P(A) + P(B)}\n",
            "\n",
            "Blocked word counts in unblocked response:\n",
            "{'wait': 43, 'alternatively': 10, 'perhaps': 28, 'maybe': 8}\n",
            "\n",
            "Blocked word counts in blocked response:\n",
            "{'wait': 0, 'alternatively': 0, 'perhaps': 0, 'maybe': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "id": "ezkUyoHienMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q transformers torch matplotlib pandas tqdm accelerate deepeval\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "from typing import List\n",
        "\n",
        "# Import DeepEval components\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric, ContextualRecallMetric\n",
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.dataset import EvaluationDataset\n",
        "from deepeval.models.base_model import DeepEvalBaseLLM\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Custom DeepEval Model With Token Blocking ---\n",
        "class TokenBlockingLLM(DeepEvalBaseLLM):\n",
        "    \"\"\"\n",
        "    A DeepEval-compatible LLM implementation with token blocking functionality.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        tokenizer,\n",
        "        blocked_token_ids=None,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        top_k=40,\n",
        "        max_tokens=512,\n",
        "        model_name=\"DeepSeek-R1-Distill\"\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "        self._model_name = model_name\n",
        "        self.generation_stats = []\n",
        "\n",
        "    def load_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        model = self.load_model()\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=5000,\n",
        "        ).to(model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        self.generation_stats.append({\n",
        "            'time': generation_time,\n",
        "            'length': len(generated_text)\n",
        "        })\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    async def a_generate(self, prompt: str) -> str:\n",
        "        \"\"\"Async generate implementation required by DeepEval\"\"\"\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def batch_generate(self, prompts: List[str]) -> List[str]:\n",
        "        \"\"\"Batch generation implementation for DeepEval\"\"\"\n",
        "        return [self.generate(prompt) for prompt in prompts]\n",
        "\n",
        "    def get_model_name(self):\n",
        "        \"\"\"Return model name for DeepEval reporting\"\"\"\n",
        "        blocking_status = \"with_blocking\" if self.blocked_token_ids is not None else \"no_blocking\"\n",
        "        return f\"{self._model_name}_{blocking_status}\"\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        \"\"\"Get average statistics from generation runs\"\"\"\n",
        "        if not self.generation_stats:\n",
        "            return {'avg_time': 0, 'avg_length': 0}\n",
        "\n",
        "        avg_time = sum(stat['time'] for stat in self.generation_stats) / len(self.generation_stats)\n",
        "        avg_length = sum(stat['length'] for stat in self.generation_stats) / len(self.generation_stats)\n",
        "\n",
        "        return {'avg_time': avg_time, 'avg_length': avg_length}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# Create directories for results\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"  # Adjust based on your environment\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark_deepeval\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (using DeepSeek-R1-Distill-Qwen-1.5B as in original code)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two model instances: one without and one with token blocking\n",
        "llm_unblocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "# --- Create test dataset with GSM8K problems ---\n",
        "from datasets import load_dataset\n",
        "\n",
        "def create_test_cases_from_gsm8k(num_samples=8000):\n",
        "    \"\"\"Create DeepEval test cases from GSM8K dataset\"\"\"\n",
        "    dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
        "    dataset = dataset.shuffle(seed=42).select(range(min(num_samples, len(dataset))))\n",
        "\n",
        "    test_cases = []\n",
        "    for idx, item in enumerate(dataset):\n",
        "        question = item[\"question\"]\n",
        "        answer = item[\"answer\"]\n",
        "\n",
        "        # Extract just the final numeric answer from the GSM8K answer format\n",
        "        final_answer = answer.split(\"####\")[-1].strip()\n",
        "\n",
        "        # Convert context to a list of strings as required by LLMTestCase\n",
        "        context_list = [answer] if answer else None\n",
        "\n",
        "        test_case = LLMTestCase(\n",
        "            input=f\"Solve this math problem step by step: {question}\",\n",
        "            actual_output=\"\",  # Will be filled during evaluation\n",
        "            expected_output=final_answer,\n",
        "            context=context_list  # Context must be a list of strings\n",
        "        )\n",
        "        test_cases.append(test_case)\n",
        "\n",
        "    return test_cases\n",
        "\n",
        "# Removed fallback test cases function as requested\n",
        "\n",
        "# Create an evaluation dataset\n",
        "print(\"Creating evaluation dataset from GSM8K benchmark...\")\n",
        "# You can adjust the number of samples as needed for your experiment\n",
        "test_cases = create_test_cases_from_gsm8k(num_samples=8000)\n",
        "evaluation_dataset = EvaluationDataset(test_cases=test_cases)\n",
        "\n",
        "# --- Custom Metrics for Direct Answer Evaluation ---\n",
        "class MathProblemAccuracyEvaluator:\n",
        "    \"\"\"\n",
        "    Simple evaluator that checks if the model's answer contains the correct answer.\n",
        "    No OpenAI API or external services required.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.results = []\n",
        "\n",
        "    def evaluate(self, model, test_cases):\n",
        "        print(f\"Evaluating {len(test_cases)} problems...\")\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.results = []\n",
        "\n",
        "        for i, test_case in enumerate(test_cases):\n",
        "            print(f\"Problem {i+1}/{len(test_cases)}\", end=\"\\r\")\n",
        "            prompt = test_case.input\n",
        "            expected = test_case.expected_output.strip()\n",
        "\n",
        "            # Generate answer using the model\n",
        "            model_answer = model.generate(prompt)\n",
        "\n",
        "            # Simple exact match check - could be improved for more robust checking\n",
        "            contains_answer = expected in model_answer\n",
        "\n",
        "            # Track results\n",
        "            result = {\n",
        "                \"prompt\": prompt,\n",
        "                \"expected\": expected,\n",
        "                \"model_answer\": model_answer,\n",
        "                \"is_correct\": contains_answer\n",
        "            }\n",
        "\n",
        "            self.results.append(result)\n",
        "\n",
        "            if contains_answer:\n",
        "                self.correct_count += 1\n",
        "            self.total_count += 1\n",
        "\n",
        "        accuracy = self.correct_count / self.total_count if self.total_count > 0 else 0\n",
        "        print(f\"\\nEvaluation complete. Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "        return {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"correct_count\": self.correct_count,\n",
        "            \"total_count\": self.total_count,\n",
        "            \"detailed_results\": self.results\n",
        "        }\n",
        "\n",
        "# --- Run evaluations ---\n",
        "print(\"\\n===== Running evaluation WITHOUT token blocking =====\")\n",
        "evaluator = MathProblemAccuracyEvaluator()\n",
        "unblocked_results = evaluator.evaluate(\n",
        "    model=llm_unblocked,\n",
        "    test_cases=test_cases\n",
        ")\n",
        "\n",
        "# Clean up memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"\\n===== Running evaluation WITH token blocking =====\")\n",
        "evaluator = MathProblemAccuracyEvaluator()\n",
        "blocked_results = evaluator.evaluate(\n",
        "    model=llm_blocked,\n",
        "    test_cases=test_cases\n",
        ")\n",
        "\n",
        "# --- Collect and analyze results ---\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "# Create result summary\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {\n",
        "        'accuracy': unblocked_results['accuracy'],\n",
        "        'correct_count': unblocked_results['correct_count'],\n",
        "        'total_count': unblocked_results['total_count'],\n",
        "        'avg_response_time': unblocked_stats['avg_time'],\n",
        "        'avg_response_length': unblocked_stats['avg_length']\n",
        "    },\n",
        "    'blocked': {\n",
        "        'accuracy': blocked_results['accuracy'],\n",
        "        'correct_count': blocked_results['correct_count'],\n",
        "        'total_count': blocked_results['total_count'],\n",
        "        'avg_response_time': blocked_stats['avg_time'],\n",
        "        'avg_response_length': blocked_stats['avg_length']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary to file\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "# Save detailed results for further analysis\n",
        "detailed_results_filepath = os.path.join(run_dir, f\"detailed_results_{timestamp}.json\")\n",
        "with open(detailed_results_filepath, 'w') as f:\n",
        "    json.dump({\n",
        "        \"unblocked_results\": unblocked_results[\"detailed_results\"],\n",
        "        \"blocked_results\": blocked_results[\"detailed_results\"]\n",
        "    }, f, indent=2)\n",
        "\n",
        "# Create comparison dataframe\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Metric': 'Accuracy',\n",
        "        'Without Blocking': summary['unblocked']['accuracy'],\n",
        "        'With Blocking': summary['blocked']['accuracy'],\n",
        "        'Difference': summary['blocked']['accuracy'] - summary['unblocked']['accuracy']\n",
        "    },\n",
        "    {\n",
        "        'Metric': 'Avg Response Time (s)',\n",
        "        'Without Blocking': summary['unblocked']['avg_response_time'],\n",
        "        'With Blocking': summary['blocked']['avg_response_time'],\n",
        "        'Difference': summary['blocked']['avg_response_time'] - summary['unblocked']['avg_response_time']\n",
        "    },\n",
        "    {\n",
        "        'Metric': 'Avg Response Length',\n",
        "        'Without Blocking': summary['unblocked']['avg_response_length'],\n",
        "        'With Blocking': summary['blocked']['avg_response_length'],\n",
        "        'Difference': summary['blocked']['avg_response_length'] - summary['unblocked']['avg_response_length']\n",
        "    }\n",
        "]\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df_comparison)\n",
        "\n",
        "# Save comparison to CSV\n",
        "df_comparison.to_csv(os.path.join(run_dir, f\"comparison_{timestamp}.csv\"), index=False)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['accuracy'], summary['blocked']['accuracy']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.xlabel('Model Configuration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'GSM8K Problem Solving Accuracy\\n({model_name})')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Add accuracy values on top of bars\n",
        "for i, v in enumerate([summary['unblocked']['accuracy'], summary['blocked']['accuracy']]):\n",
        "    plt.text(i, v + 0.02, f\"{v:.2%}\", ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"accuracy_comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "# Additional visualization for response time and length\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['avg_response_time'], summary['blocked']['avg_response_time']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Response Time')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['avg_response_length'], summary['blocked']['avg_response_length']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Response Length')\n",
        "plt.ylabel('Characters')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"performance_comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n",
        "\n",
        "# --- Optional: Run a simple test to verify token blocking works ---\n",
        "def test_token_blocking():\n",
        "    print(\"\\n===== Simple Token Blocking Test =====\")\n",
        "    test_prompt = \"What approach should I take to solve this problem?\"\n",
        "\n",
        "    print(\"Without blocking:\")\n",
        "    unblocked_response = llm_unblocked.generate(test_prompt)\n",
        "    print(unblocked_response)\n",
        "\n",
        "    print(\"\\nWith blocking:\")\n",
        "    blocked_response = llm_blocked.generate(test_prompt)\n",
        "    print(blocked_response)\n",
        "\n",
        "    # Count occurrences of blocked words\n",
        "    blocked_word_counts_unblocked = {word: unblocked_response.lower().count(word.lower()) for word in words_to_block}\n",
        "    blocked_word_counts_blocked = {word: blocked_response.lower().count(word.lower()) for word in words_to_block}\n",
        "\n",
        "    print(\"\\nBlocked word counts in unblocked response:\")\n",
        "    print(blocked_word_counts_unblocked)\n",
        "\n",
        "    print(\"\\nBlocked word counts in blocked response:\")\n",
        "    print(blocked_word_counts_blocked)\n",
        "\n",
        "# Run the test at the end\n",
        "test_token_blocking()"
      ],
      "metadata": {
        "id": "KQ3P2fnnkrhA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test of 10"
      ],
      "metadata": {
        "id": "CIAlcnKpZb0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (for Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install -q transformers torch matplotlib pandas tqdm accelerate deepeval datasets\n",
        "\n",
        "import time, os, json, gc, torch, hashlib\n",
        "from datetime import datetime\n",
        "from threading import Thread\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextIteratorStreamer\n",
        "from typing import List\n",
        "\n",
        "# Import DeepEval components\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import HallucinationMetric, AnswerRelevancyMetric, ContextualRecallMetric\n",
        "from deepeval.test_case import LLMTestCase\n",
        "from deepeval.dataset import EvaluationDataset\n",
        "from deepeval.models.base_model import DeepEvalBaseLLM\n",
        "\n",
        "# --- Token Blocking Helper Functions and Classes ---\n",
        "\n",
        "def get_blocked_token_ids(tokenizer, words):\n",
        "    \"\"\"Get unique token IDs for the given words in various cases.\"\"\"\n",
        "    blocked_ids = []\n",
        "    for word in words:\n",
        "        for form in [(\" \" + word), word,\n",
        "                     (\" \" + word.capitalize()), word.capitalize(),\n",
        "                     (\" \" + word.upper()), word.upper()]:\n",
        "            blocked_ids.extend(tokenizer.encode(form, add_special_tokens=False))\n",
        "    unique_ids = list(set(blocked_ids))\n",
        "    print(f\"\\nBlocking these words: {words}\")\n",
        "    print(f\"Corresponding to these {len(unique_ids)} token IDs: {unique_ids}\")\n",
        "    for token_id in unique_ids:\n",
        "        print(f\"Token ID {token_id} = '{tokenizer.decode([token_id])}'\")\n",
        "    return unique_ids\n",
        "\n",
        "class TokenBlockLogitsProcessor:\n",
        "    \"\"\"A logits processor that sets scores for specified token IDs to -inf.\"\"\"\n",
        "    def __init__(self, blocked_token_ids):\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        mask = torch.zeros_like(scores, dtype=torch.bool)\n",
        "        mask[:, self.blocked_token_ids] = True\n",
        "        return scores.masked_fill(mask, float('-inf'))\n",
        "\n",
        "# --- Custom DeepEval Model With Token Blocking ---\n",
        "class TokenBlockingLLM(DeepEvalBaseLLM):\n",
        "    \"\"\"\n",
        "    A DeepEval-compatible LLM implementation with token blocking functionality.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        tokenizer,\n",
        "        blocked_token_ids=None,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        top_k=40,\n",
        "        max_tokens=512,\n",
        "        model_name=\"DeepSeek-R1-Distill\"\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.blocked_token_ids = blocked_token_ids\n",
        "        self.temperature = temperature\n",
        "        self.top_p = top_p\n",
        "        self.top_k = top_k\n",
        "        self.max_tokens = max_tokens\n",
        "        self._model_name = model_name\n",
        "        self.generation_stats = []\n",
        "\n",
        "    def load_model(self):\n",
        "        return self.model\n",
        "\n",
        "    def generate(self, prompt: str) -> str:\n",
        "        start_time = time.time()\n",
        "        model = self.load_model()\n",
        "\n",
        "        inputs = self.tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=5000,\n",
        "        ).to(model.device)\n",
        "\n",
        "        logits_processors = []\n",
        "        if self.blocked_token_ids is not None:\n",
        "            logits_processors.append(TokenBlockLogitsProcessor(self.blocked_token_ids))\n",
        "\n",
        "        streamer = TextIteratorStreamer(self.tokenizer, skip_special_tokens=True, skip_prompt=True)\n",
        "        generation_kwargs = dict(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.max_tokens,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            do_sample=True,\n",
        "            streamer=streamer,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            logits_processor=logits_processors if logits_processors else None\n",
        "        )\n",
        "\n",
        "        # Run generation in a separate thread to stream output token-by-token.\n",
        "        thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "        thread.start()\n",
        "\n",
        "        generated_text = \"\"\n",
        "        for new_text in streamer:\n",
        "            generated_text += new_text\n",
        "\n",
        "        generation_time = time.time() - start_time\n",
        "        self.generation_stats.append({\n",
        "            'time': generation_time,\n",
        "            'length': len(generated_text)\n",
        "        })\n",
        "\n",
        "        return generated_text\n",
        "\n",
        "    async def a_generate(self, prompt: str) -> str:\n",
        "        \"\"\"Async generate implementation required by DeepEval\"\"\"\n",
        "        return self.generate(prompt)\n",
        "\n",
        "    def batch_generate(self, prompts: List[str]) -> List[str]:\n",
        "        \"\"\"Batch generation implementation for DeepEval\"\"\"\n",
        "        return [self.generate(prompt) for prompt in prompts]\n",
        "\n",
        "    def get_model_name(self):\n",
        "        \"\"\"Return model name for DeepEval reporting\"\"\"\n",
        "        blocking_status = \"with_blocking\" if self.blocked_token_ids is not None else \"no_blocking\"\n",
        "        return f\"{self._model_name}_{blocking_status}\"\n",
        "\n",
        "    def get_avg_stats(self):\n",
        "        \"\"\"Get average statistics from generation runs\"\"\"\n",
        "        if not self.generation_stats:\n",
        "            return {'avg_time': 0, 'avg_length': 0}\n",
        "\n",
        "        avg_time = sum(stat['time'] for stat in self.generation_stats) / len(self.generation_stats)\n",
        "        avg_length = sum(stat['length'] for stat in self.generation_stats) / len(self.generation_stats)\n",
        "\n",
        "        return {'avg_time': avg_time, 'avg_length': avg_length}\n",
        "\n",
        "# --- Experiment Setup and Running Benchmark ---\n",
        "\n",
        "# Create directories for results\n",
        "base_dir = \"/content/drive/MyDrive/llm_eval_results\"  # Adjust based on your environment\n",
        "results_dir = os.path.join(base_dir, \"token_blocking_benchmark_deepeval\")\n",
        "os.makedirs(results_dir, exist_ok=True)\n",
        "print(f\"Results will be saved to: {results_dir}\")\n",
        "\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "run_dir = os.path.join(results_dir, f\"run_{timestamp}\")\n",
        "os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "# Define words to block\n",
        "words_to_block = [\"wait\", \"alternatively\", \"perhaps\", \"maybe\"]\n",
        "\n",
        "# Load model and tokenizer (using DeepSeek-R1-Distill-Qwen-1.5B as in original code)\n",
        "print(\"Loading model...\")\n",
        "model_name = \"deepseek-ai/deepseek-r1-distill-qwen-1.5b\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# Get blocked token IDs\n",
        "blocked_ids = get_blocked_token_ids(tokenizer, words_to_block)\n",
        "blocked_token_ids = torch.tensor(blocked_ids, device=model.device)\n",
        "\n",
        "# Create two model instances: one without and one with token blocking\n",
        "llm_unblocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=None,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "llm_blocked = TokenBlockingLLM(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    blocked_token_ids=blocked_token_ids,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    top_k=40,\n",
        "    max_tokens=5120\n",
        ")\n",
        "\n",
        "# --- Create test dataset with GSM8K problems ---\n",
        "from datasets import load_dataset\n",
        "\n",
        "def create_test_cases_from_gsm8k(num_samples=10):\n",
        "    \"\"\"Create DeepEval test cases from GSM8K dataset\"\"\"\n",
        "    dataset = load_dataset(\"gsm8k\", \"main\", split=\"test\")\n",
        "    dataset = dataset.shuffle(seed=42).select(range(min(num_samples, len(dataset))))\n",
        "\n",
        "    test_cases = []\n",
        "    for idx, item in enumerate(dataset):\n",
        "        question = item[\"question\"]\n",
        "        answer = item[\"answer\"]\n",
        "\n",
        "        # Extract just the final numeric answer from the GSM8K answer format\n",
        "        final_answer = answer.split(\"####\")[-1].strip()\n",
        "\n",
        "        # Convert context to a list of strings as required by LLMTestCase\n",
        "        context_list = [answer] if answer else None\n",
        "\n",
        "        test_case = LLMTestCase(\n",
        "            input=f\"Solve this math problem step by step: {question}\",\n",
        "            actual_output=\"\",  # Will be filled during evaluation\n",
        "            expected_output=final_answer,\n",
        "            context=context_list  # Context must be a list of strings\n",
        "        )\n",
        "        test_cases.append(test_case)\n",
        "\n",
        "    return test_cases\n",
        "\n",
        "print(\"Creating evaluation dataset from GSM8K benchmark...\")\n",
        "test_cases = create_test_cases_from_gsm8k(num_samples=10)\n",
        "evaluation_dataset = EvaluationDataset(test_cases=test_cases)\n",
        "\n",
        "# --- Custom Metrics for Direct Answer Evaluation ---\n",
        "class MathProblemAccuracyEvaluator:\n",
        "    \"\"\"\n",
        "    Simple evaluator that checks if the model's answer contains the correct answer.\n",
        "    No OpenAI API or external services required.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.results = []\n",
        "\n",
        "    def evaluate(self, model, test_cases, save_responses_dir=None):\n",
        "        print(f\"Evaluating {len(test_cases)} problems...\")\n",
        "        self.correct_count = 0\n",
        "        self.total_count = 0\n",
        "        self.results = []\n",
        "\n",
        "        # If a directory is provided to save responses, create it\n",
        "        if save_responses_dir is not None:\n",
        "            os.makedirs(save_responses_dir, exist_ok=True)\n",
        "\n",
        "        for i, test_case in enumerate(test_cases):\n",
        "            print(f\"Problem {i+1}/{len(test_cases)}\", end=\"\\r\")\n",
        "            prompt = test_case.input\n",
        "            expected = test_case.expected_output.strip()\n",
        "\n",
        "            # Generate answer using the model\n",
        "            model_answer = model.generate(prompt)\n",
        "\n",
        "            # Save each response to drive if directory provided\n",
        "            if save_responses_dir is not None:\n",
        "                response_filepath = os.path.join(save_responses_dir, f\"response_{i+1}.txt\")\n",
        "                with open(response_filepath, \"w\") as f:\n",
        "                    f.write(model_answer)\n",
        "\n",
        "            # Simple exact match check - could be improved for more robust checking\n",
        "            contains_answer = expected in model_answer\n",
        "\n",
        "            # Track results\n",
        "            result = {\n",
        "                \"prompt\": prompt,\n",
        "                \"expected\": expected,\n",
        "                \"model_answer\": model_answer,\n",
        "                \"is_correct\": contains_answer\n",
        "            }\n",
        "\n",
        "            self.results.append(result)\n",
        "\n",
        "            if contains_answer:\n",
        "                self.correct_count += 1\n",
        "            self.total_count += 1\n",
        "\n",
        "        accuracy = self.correct_count / self.total_count if self.total_count > 0 else 0\n",
        "        print(f\"\\nEvaluation complete. Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "        return {\n",
        "            \"accuracy\": accuracy,\n",
        "            \"correct_count\": self.correct_count,\n",
        "            \"total_count\": self.total_count,\n",
        "            \"detailed_results\": self.results\n",
        "        }\n",
        "\n",
        "# --- Run evaluations ---\n",
        "print(\"\\n===== Running evaluation WITHOUT token blocking =====\")\n",
        "evaluator = MathProblemAccuracyEvaluator()\n",
        "# Save responses for unblocked model in a separate folder\n",
        "unblocked_responses_dir = os.path.join(run_dir, \"unblocked_responses\")\n",
        "unblocked_results = evaluator.evaluate(\n",
        "    model=llm_unblocked,\n",
        "    test_cases=test_cases,\n",
        "    save_responses_dir=unblocked_responses_dir\n",
        ")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "print(\"\\n===== Running evaluation WITH token blocking =====\")\n",
        "evaluator = MathProblemAccuracyEvaluator()\n",
        "# Save responses for blocked model in a separate folder\n",
        "blocked_responses_dir = os.path.join(run_dir, \"blocked_responses\")\n",
        "blocked_results = evaluator.evaluate(\n",
        "    model=llm_blocked,\n",
        "    test_cases=test_cases,\n",
        "    save_responses_dir=blocked_responses_dir\n",
        ")\n",
        "\n",
        "# --- Collect and analyze results ---\n",
        "unblocked_stats = llm_unblocked.get_avg_stats()\n",
        "blocked_stats = llm_blocked.get_avg_stats()\n",
        "\n",
        "summary = {\n",
        "    'model': model_name,\n",
        "    'timestamp': timestamp,\n",
        "    'words_blocked': words_to_block,\n",
        "    'unblocked': {\n",
        "        'accuracy': unblocked_results['accuracy'],\n",
        "        'correct_count': unblocked_results['correct_count'],\n",
        "        'total_count': unblocked_results['total_count'],\n",
        "        'avg_response_time': unblocked_stats['avg_time'],\n",
        "        'avg_response_length': unblocked_stats['avg_length']\n",
        "    },\n",
        "    'blocked': {\n",
        "        'accuracy': blocked_results['accuracy'],\n",
        "        'correct_count': blocked_results['correct_count'],\n",
        "        'total_count': blocked_results['total_count'],\n",
        "        'avg_response_time': blocked_stats['avg_time'],\n",
        "        'avg_response_length': blocked_stats['avg_length']\n",
        "    }\n",
        "}\n",
        "\n",
        "summary_filepath = os.path.join(run_dir, f\"summary_{timestamp}.json\")\n",
        "with open(summary_filepath, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "detailed_results_filepath = os.path.join(run_dir, f\"detailed_results_{timestamp}.json\")\n",
        "with open(detailed_results_filepath, 'w') as f:\n",
        "    json.dump({\n",
        "        \"unblocked_results\": unblocked_results[\"detailed_results\"],\n",
        "        \"blocked_results\": blocked_results[\"detailed_results\"]\n",
        "    }, f, indent=2)\n",
        "\n",
        "comparison_data = [\n",
        "    {\n",
        "        'Metric': 'Accuracy',\n",
        "        'Without Blocking': summary['unblocked']['accuracy'],\n",
        "        'With Blocking': summary['blocked']['accuracy'],\n",
        "        'Difference': summary['blocked']['accuracy'] - summary['unblocked']['accuracy']\n",
        "    },\n",
        "    {\n",
        "        'Metric': 'Avg Response Time (s)',\n",
        "        'Without Blocking': summary['unblocked']['avg_response_time'],\n",
        "        'With Blocking': summary['blocked']['avg_response_time'],\n",
        "        'Difference': summary['blocked']['avg_response_time'] - summary['unblocked']['avg_response_time']\n",
        "    },\n",
        "    {\n",
        "        'Metric': 'Avg Response Length',\n",
        "        'Without Blocking': summary['unblocked']['avg_response_length'],\n",
        "        'With Blocking': summary['blocked']['avg_response_length'],\n",
        "        'Difference': summary['blocked']['avg_response_length'] - summary['unblocked']['avg_response_length']\n",
        "    }\n",
        "]\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\n===== Final Results =====\")\n",
        "print(df_comparison)\n",
        "\n",
        "df_comparison.to_csv(os.path.join(run_dir, f\"comparison_{timestamp}.csv\"), index=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['accuracy'], summary['blocked']['accuracy']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.xlabel('Model Configuration')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(f'GSM8K Problem Solving Accuracy\\n({model_name})')\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "for i, v in enumerate([summary['unblocked']['accuracy'], summary['blocked']['accuracy']]):\n",
        "    plt.text(i, v + 0.02, f\"{v:.2%}\", ha='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"accuracy_comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['avg_response_time'], summary['blocked']['avg_response_time']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Response Time')\n",
        "plt.ylabel('Time (seconds)')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(['Without Blocking', 'With Blocking'],\n",
        "        [summary['unblocked']['avg_response_length'], summary['blocked']['avg_response_length']],\n",
        "        color=['skyblue', 'lightgreen'])\n",
        "plt.title('Average Response Length')\n",
        "plt.ylabel('Characters')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(run_dir, f\"performance_comparison_{timestamp}.png\"))\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nAll results saved to: {run_dir}\")\n",
        "\n",
        "def test_token_blocking():\n",
        "    print(\"\\n===== Simple Token Blocking Test =====\")\n",
        "    test_prompt = \"What approach should I take to solve this problem?\"\n",
        "\n",
        "    print(\"Without blocking:\")\n",
        "    unblocked_response = llm_unblocked.generate(test_prompt)\n",
        "    print(unblocked_response)\n",
        "\n",
        "    print(\"\\nWith blocking:\")\n",
        "    blocked_response = llm_blocked.generate(test_prompt)\n",
        "    print(blocked_response)\n",
        "\n",
        "    blocked_word_counts_unblocked = {word: unblocked_response.lower().count(word.lower()) for word in words_to_block}\n",
        "    blocked_word_counts_blocked = {word: blocked_response.lower().count(word.lower()) for word in words_to_block}\n",
        "\n",
        "    print(\"\\nBlocked word counts in unblocked response:\")\n",
        "    print(blocked_word_counts_unblocked)\n",
        "\n",
        "    print(\"\\nBlocked word counts in blocked response:\")\n",
        "    print(blocked_word_counts_blocked)\n",
        "\n",
        "test_token_blocking()\n"
      ],
      "metadata": {
        "id": "EyjI84kKk3XJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b618ddb86ac14b3b9078e0ca46eaa628",
            "5b945717644546f38b7e71fca23d7bfa",
            "05929196d983400f87e3b13e4fd086fd",
            "60566639033549809e118e96eff8d460",
            "0daa4dd3a03446c3adb7de013f7d569b",
            "4f262ba2ea734e439e423080b0e8c6d6",
            "23a0a2ad5a7a41e1802add690a312c8c",
            "0e255b016ef544ae9b297e08b953d42a",
            "3056436c9f05425db18d8430d5effde0",
            "0d804e76fcea4767884b15f3683c25ec",
            "fbe518932528436b85531d7b0e1126ae",
            "61d7bb1f02e346a2881a078f4577f7a1",
            "de420b16e2554bc282e2ec9ae4e3b15d",
            "337f50a93b094383b922d9264ceff83e",
            "28453b54ac204ca4aa35d34d4456f242",
            "7429fd93cabe40ceb96032680ad1c43f",
            "d2576a8054e64192b3845d52291639a7",
            "677107d1348c4e0b8fe22e9306f7c12f",
            "ae8708d1b6934e18bafdb850c1a5e91a",
            "07de03ce130d46d4b99b1afe8499d08e",
            "cc6733c82d5046b6b2aa114c5c6d2817",
            "982cac743c964534b6e570f533b7904a",
            "434a2d7aa1a945c6938a9f15e0a0ba59",
            "24301c71c24e49bd9b75911dedb0f40a",
            "71ddb00f4a9944bf98012a013f8791d5",
            "bb65ec63d7a44899a3ca91e98c24710f",
            "49cda68d57a74b3fb2e4318b94ebee82",
            "061b72cd47884fdc994e945ea4beea7f",
            "961953911fc54b9eb4fd2492210f7419",
            "bb97ab4c51f441f4b5dc28022f65b3e2",
            "2ebbca9bb868445fb10b52cb9edf58af",
            "626c5a03a56e4ea7a3ef6c4a8029bd54",
            "568c94b453d7491e8f9176c08a97e856",
            "26c3572232904595b4cd8774e9c292c0",
            "3fc9968ebcb04384a2a947dae8e508e2",
            "1c019cd7594c42beb053f1b04d752e60",
            "0a461c13470248409daee7cdef58f98f",
            "9d9d30cf32bd41d5a3406d493c293df7",
            "460c13ffa55e46609f383d200286b7f7",
            "17b561fc4aa44dfcbc068546639ee07d",
            "d9d70042bd204e89a93a99843e9e0261",
            "400fe213db9b4f7eb53c1aa06827ab84",
            "c24b739a64cd4cf098ceb80f3ae515b4",
            "cd75a9bbd3504de4bdce7a658988bb0d",
            "8d0bef810e964a25adb3ddafcf006f0f",
            "778da6ec30d14d6b8320f4d8b7d55ae3",
            "2db6a7edfd574d078e55d64f0261b8da",
            "dbd63ab1bbf44234813b8c8df1a20be0",
            "838b49b9175f4752a8c14895079b25d1",
            "17fcd41a1deb4d3187324b2599faa1f9",
            "658c259a989f493f8c9f02683693a5a2",
            "3a8ea004c2a74d16bee8999d682e74e4",
            "53f7ccbb9b704b18959238034c8990c3",
            "79966d9f9b80419d910ed3098b441719",
            "4f4a3d3f3e214375b285dc6e4ed31024",
            "01e5d07ac38947fb8cfac5d7dac780e7",
            "9f8c0f2420ec4931af19be7df0ea1291",
            "1891f8d02d3a44248ad03d73e082f3f4",
            "086a72c4868043e2bfea5deb8369b82f",
            "835640eb84614ae2948ab4429880ce75",
            "7d7d71d1b045436496c78418a7450748",
            "a9805dc407ef44a6a14cccd3cb3189a9",
            "eb930387f16148eba75d088dff54e582",
            "ee8ec5bfcccb408bae39ba8ab5fcfafd",
            "877f683fd9594b708248877161893d43",
            "c9098791327c4d42a148d01be33047b3",
            "67a0dc07b9cc43a3a8037146ac80cc29",
            "0d84cfe1e306480ca2a583727493c974",
            "eced3593afa947398d4a183532787bac",
            "ec80074d1275435bb342eddec48a7e40",
            "dfc647e676ee4a688233de567cc46458",
            "e24a3eadd41c499a95d8f04ace748b94",
            "12362137b47649e09834f2fb75f2e97c",
            "50895d27a505421784cb3c9fe4e006af",
            "c6056f62f65c4a76989b2d6646a30be6",
            "d9b01b57576d41f1bfc973807be3527a",
            "efb224d762aa4fdab4dbcb62cc32e278",
            "bfda57e0907442c98c4fa0866058975c",
            "fe34075248024515bd996a2293ece72e",
            "1b74377d2f1740f9a9e424a096cdb6a9",
            "b93549cfd222478fbcab758545d7d92e",
            "d5f7c10e4c5e45d0889420182f440699",
            "beb0dfaad67f4da997c787808b7f5c48",
            "911bd745766748758f8955ac38fcc758",
            "673eb025bd064827b53f5a6c63a573d0",
            "52bff0fcdb1c47fba7b79d583d4ac443",
            "07f3de2642124b0eab8e4a8d8f1b57dd",
            "2ba06121b6f64c2d9153821e8dd4c27a",
            "f92721234ae84e11b0b16b84d1ff217f",
            "b77bca8be82c4451afc8dbf758d781ff",
            "73ae8dfd8c2f4f89808f1a337746e755",
            "0abddaa683f44bea912c4c5e2b45d91e",
            "313d70dc06654636a9c64646a8c5290d",
            "05c996940e7e41ecae1b828fff1abd81",
            "b496b0449a414ea1bbe36825cfcd2b59",
            "3f191cd417ab4333992c821d439a7a62",
            "653eba1f5dc843f48951ae4f0d9a1058",
            "15b51a0f84314383aadda1eeb753b329",
            "322c2cdce4ff453eb6c4b84f4706bc48",
            "5cd25d673726418bbb8bb4cc333d78ae",
            "62afb66abed04c79a80e5ec358c23731",
            "faba9bd2538345cb8748f6b8b7e06b2d",
            "5b8a210756e349d6b92b7ed5229c0272",
            "cdcdd14483bc4bb7a6b66d74b4e46d19",
            "f64612f065e14f7abf22e8587033c057",
            "73b16be897fb4855aa9f79eb2b96f499",
            "b189e044e9bf43908bde7a52743faed4",
            "191ee79266de486480dd3696040ca04f",
            "bc6cde09fb06496e808d0fa0749ec88d",
            "ccc10687c8c444989ee9cc6f0e434942"
          ]
        },
        "outputId": "ea0bb9c5-5bff-4375-f66c-fdc7d3333093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.5/571.5 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.6/345.6 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.5/264.5 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.0/739.0 kB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.3/302.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mResults will be saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_deepeval\n",
            "Loading model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/3.07k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b618ddb86ac14b3b9078e0ca46eaa628"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d7bb1f02e346a2881a078f4577f7a1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/679 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "434a2d7aa1a945c6938a9f15e0a0ba59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26c3572232904595b4cd8774e9c292c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d0bef810e964a25adb3ddafcf006f0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Blocking these words: ['wait', 'alternatively', 'perhaps', 'maybe']\n",
            "Corresponding to these 33 token IDs: [13824, 71032, 21390, 3090, 36760, 7196, 68387, 39, 44, 8365, 8753, 9654, 49209, 828, 17854, 39230, 3783, 10696, 969, 47945, 11594, 18765, 38478, 7887, 3022, 40412, 11489, 14190, 92014, 31476, 54390, 65272, 10877]\n",
            "Token ID 13824 = ' Wait'\n",
            "Token ID 71032 = 'WAIT'\n",
            "Token ID 21390 = 'Maybe'\n",
            "Token ID 3090 = 'IV'\n",
            "Token ID 36760 = 'maybe'\n",
            "Token ID 7196 = ' maybe'\n",
            "Token ID 68387 = ' alternatively'\n",
            "Token ID 39 = 'H'\n",
            "Token ID 44 = 'M'\n",
            "Token ID 8365 = ' perhaps'\n",
            "Token ID 8753 = ' AL'\n",
            "Token ID 9654 = 'PER'\n",
            "Token ID 49209 = 'ELY'\n",
            "Token ID 828 = 'AT'\n",
            "Token ID 17854 = ' PER'\n",
            "Token ID 39230 = ' MAY'\n",
            "Token ID 3783 = ' wait'\n",
            "Token ID 10696 = ' Maybe'\n",
            "Token ID 969 = 'AL'\n",
            "Token ID 47945 = 'APS'\n",
            "Token ID 11594 = 'BE'\n",
            "Token ID 18765 = ' Perhaps'\n",
            "Token ID 38478 = ' Alternatively'\n",
            "Token ID 7887 = 'atively'\n",
            "Token ID 3022 = 'AY'\n",
            "Token ID 40412 = 'altern'\n",
            "Token ID 11489 = 'wait'\n",
            "Token ID 14190 = 'Wait'\n",
            "Token ID 92014 = 'Alternatively'\n",
            "Token ID 31476 = 'Perhaps'\n",
            "Token ID 54390 = ' WAIT'\n",
            "Token ID 65272 = 'perhaps'\n",
            "Token ID 10877 = 'TERN'\n",
            "Creating evaluation dataset from GSM8K benchmark...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/7.94k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01e5d07ac38947fb8cfac5d7dac780e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67a0dc07b9cc43a3a8037146ac80cc29"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "test-00000-of-00001.parquet:   0%|          | 0.00/419k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfda57e0907442c98c4fa0866058975c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/7473 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f92721234ae84e11b0b16b84d1ff217f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1319 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5cd25d673726418bbb8bb4cc333d78ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running evaluation WITHOUT token blocking =====\n",
            "Evaluating 10 problems...\n",
            "Problem 1/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 2/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 3/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 4/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 5/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 6/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 7/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 8/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 9/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 10/10\r\n",
            "Evaluation complete. Accuracy: 70.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Running evaluation WITH token blocking =====\n",
            "Evaluating 10 problems...\n",
            "Problem 1/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 2/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 3/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 4/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 5/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 6/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 7/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 8/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 9/10\r"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Problem 10/10\r\n",
            "Evaluation complete. Accuracy: 80.00%\n",
            "\n",
            "===== Final Results =====\n",
            "                  Metric  Without Blocking  With Blocking   Difference\n",
            "0               Accuracy          0.700000        0.80000     0.100000\n",
            "1  Avg Response Time (s)         91.730564       61.82886   -29.901704\n",
            "2    Avg Response Length       8833.000000     6256.60000 -2576.400000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All results saved to: /content/drive/MyDrive/llm_eval_results/token_blocking_benchmark_deepeval/run_20250321_155334\n",
            "\n",
            "===== Simple Token Blocking Test =====\n",
            "Without blocking:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Let me explain the problem.\n",
            "\n",
            "I have a binary matrix, which is n x m. Each element is 0 or 1. I need to find the maximum sum of a submatrix, where the sum is defined as the number of 1s in that submatrix. So, the submatrix is a contiguous block of elements. It's given that n and m can be up to 1e5, and the sum of n and m can be up to 1e5. So, the approach should be efficient.\n",
            "\n",
            "I have to write a Python code that implements this.\n",
            "\n",
            "First, I need to think about the approach. Let's consider the problem of finding the maximum sum of a submatrix in a binary matrix. The standard approach for this is to use the sliding window technique, which allows us to compute the sum in O(1) time after some initial preprocessing.\n",
            "\n",
            "But in this problem, the matrix can be as large as 1e5 x 1e5, which makes it impossible to compute the sum for every possible submatrix. So, the solution needs to find an approach that can compute the maximum sum efficiently, without checking every possible submatrix.\n",
            "\n",
            "Wait, the problem statement says that the sum can be up to 1e5, but n and m can be up to 1e5 as well. So, the maximum possible submatrix is the entire matrix, which would be n*m. But computing that for each test case is not feasible for large matrices.\n",
            "\n",
            "Hmm, perhaps the key is to find the maximum number of 1s in any submatrix, and the approach should be to find the maximum in O(n*m) time. But that would be too slow for large matrices.\n",
            "\n",
            "Wait, the problem is asking for the maximum sum, which is the count of 1s. So, the maximum sum is the maximum number of 1s in any contiguous submatrix. So, perhaps the problem reduces to finding the maximum number of 1s in any rectangle in the matrix.\n",
            "\n",
            "Wait, but in that case, for a binary matrix, the maximum submatrix sum is the same as the maximum number of 1s in any rectangle.\n",
            "\n",
            "But I'm not sure. Let me think again.\n",
            "\n",
            "So, the standard approach to find the maximum number of 1s in any rectangle is to use the inclusion-exclusion principle with the help of prefix sums. That is, for each cell, we can compute the sum of the rectangle that starts from the top-left corner to the current cell, and then for each row, keep track of the minimum prefix sum, and compute the maximum difference.\n",
            "\n",
            "But with a 1e5 x 1e5 matrix, this approach is O(n*m), which would be too slow.\n",
            "\n",
            "So, we need a more efficient approach.\n",
            "\n",
            "Wait, but the problem is about a binary matrix, which is n x m. Each cell is 0 or 1.\n",
            "\n",
            "Another thought: the maximum submatrix sum is equal to the maximum number of 1s in any rectangle. So, perhaps we can find the maximum number of 1s in any submatrix using the sliding window approach, which is O(n*m) time.\n",
            "\n",
            "But again, for a 1e5 x 1e5 matrix, that's not feasible.\n",
            "\n",
            "So, perhaps the solution is to find the maximum number of 1s in any row, and then find the maximum such row's maximum, but that's not correct because the submatrix can span multiple rows.\n",
            "\n",
            "Wait, no, because if all the rows have a certain number of 1s, but in some columns, they can form a larger rectangle.\n",
            "\n",
            "Alternatively, perhaps the maximum submatrix sum is the maximum between:\n",
            "\n",
            "1. The maximum number of 1s in any single row.\n",
            "\n",
            "2. The maximum number of 1s in any single column.\n",
            "\n",
            "3. The maximum number of 1s in any rectangle that is formed by the intersection of two rows and two columns.\n",
            "\n",
            "Wait, but perhaps the maximum submatrix sum can be found by considering the maximum sum in any row, the maximum sum in any column, and the maximum sum in any pair of rows and columns.\n",
            "\n",
            "Wait, perhaps the solution is to compute the maximum number of 1s in any row, the maximum in any column, and then the maximum number of 1s in any pair of rows and columns, and take the maximum of all three.\n",
            "\n",
            "But I'm not sure.\n",
            "\n",
            "Wait, let's think about this. For any submatrix, it's determined by its top-left and bottom-right corners. So, perhaps the maximum can be found by considering the maximum in rows, the maximum in columns, and the maximum in the corners.\n",
            "\n",
            "Alternatively, perhaps the maximum can be found by considering for each row the maximum number of 1s in any subarray, and then taking the maximum across all rows. Similarly, for each column, the maximum number of 1s in any subarray, and then taking the maximum across all columns.\n",
            "\n",
            "Wait, but that would give the maximum number of 1s in any subarray of a single row or a single column. But the maximum submatrix could be a rectangle that is not a single row or column.\n",
            "\n",
            "So, perhaps the maximum submatrix sum can be found by taking the maximum of:\n",
            "\n",
            "- The maximum number of 1s in any row.\n",
            "\n",
            "- The maximum number of 1s in any column.\n",
            "\n",
            "- The maximum number of 1s in any pair of rows and columns, which is the sum of the number of 1s in the rows between the two rows, and the number of 1s in the columns between the two columns.\n",
            "\n",
            "But that seems complicated.\n",
            "\n",
            "Alternatively, perhaps the maximum number of 1s in any submatrix can be found by considering for each possible pair of rows, the number of columns where the rows have 1s in the same columns, and then the maximum for each pair of rows is the number of columns where both have 1s. But that's not necessarily the maximum.\n",
            "\n",
            "Wait, perhaps I should think of the problem in terms of the maximum submatrix sum. Since the matrix is binary, the sum is the count of 1s. So, the maximum sum is the maximum number of 1s in any submatrix.\n",
            "\n",
            "So, perhaps the approach is to find the maximum number of 1s in any rectangle.\n",
            "\n",
            "I remember that for the maximum sum rectangle in a binary matrix, the standard approach is to use the inclusion-exclusion method with prefix sums. That method can compute the maximum sum in O(n*m) time, but for 1e5 x 1e5 matrices, that's not feasible.\n",
            "\n",
            "So, what's the alternative?\n",
            "\n",
            "Wait, perhaps the problem can be solved by considering that the maximum submatrix sum can be found by considering the maximum number of 1s in any row, any column, or any rectangle formed by the intersection of two rows and two columns.\n",
            "\n",
            "But I'm not sure how to compute that efficiently.\n",
            "\n",
            "Another thought: perhaps the maximum number of 1s in any submatrix can be found by considering the maximum number of 1s in any row, the maximum in any column, and the maximum in any 2x2 square.\n",
            "\n",
            "But I'm not sure if that's sufficient.\n",
            "\n",
            "Alternatively, perhaps the maximum can be found by considering the maximum number of 1s in any row, the maximum in any column, and then the maximum number of 1s in any rectangle that is formed by the intersection of two rows and two columns, and then taking the maximum of all these.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any row, the maximum in any column, and the maximum in any 2x2 square, and then take the maximum of all three. But I'm not sure if that's correct.\n",
            "\n",
            "Wait, for example, consider a matrix where all rows are all 1s. Then the maximum submatrix sum is n*m, which is the entire matrix. So, in this case, the maximum number of 1s in any row is m, and the maximum in any column is n, but the maximum in any 2x2 square is n*m.\n",
            "\n",
            "So, in that case, the maximum of the three is n*m, which is correct.\n",
            "\n",
            "Another example: a matrix where each row is all 1s except for the last element, which is 0. Then, the maximum row sum is m-1, the maximum column sum is n, and the maximum 2x2 square is n-1. So, the maximum of the three is n, which is the maximum column sum.\n",
            "\n",
            "But wait, the maximum submatrix sum in this case is (n-1)*m, because the last column has all 1s except for the last row, which is 0. So, the submatrix that excludes the last row and last column would have (n-1)*(m-1) 1s, but the submatrix that includes the last row would have (n-1)*m 1s. So, the maximum is (n-1)*m, which is not captured by the maximum row sum, maximum column sum, or the maximum 2x2 square.\n",
            "\n",
            "So, that approach would not capture the correct maximum.\n",
            "\n",
            "Hmm, so that suggests that the approach of considering maximum row sum, maximum column sum, and maximum 2x2 square is insufficient.\n",
            "\n",
            "So, perhaps the solution is to find the maximum number of 1s in any row, the maximum in any column, and the maximum in any rectangle formed by the intersection of two rows and two columns, and then take the maximum of all these.\n",
            "\n",
            "But how to compute that efficiently.\n",
            "\n",
            "Alternatively, perhaps the solution is to find the maximum number of 1s in any row, the maximum in any column, and the maximum in any pair of rows and columns, but I'm not sure how to compute that.\n",
            "\n",
            "Wait, perhaps the problem is to find the maximum sum submatrix, which is the maximum number of 1s in any submatrix.\n",
            "\n",
            "So, perhaps the maximum can be found by considering all possible pairs of rows and columns and computing the number of 1s in their intersection, but that's O(n^2) which is not feasible.\n",
            "\n",
            "Wait, but perhaps for each pair of rows, we can find the maximum number of 1s in any column that intersects both rows, and then keep track of the maximum across all such pairs.\n",
            "\n",
            "But that would be O(n^2 * m), which is not feasible.\n",
            "\n",
            "Hmm, perhaps the problem requires a different approach.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum can be found by considering the maximum number of 1s in any row, the maximum in any column, and then the maximum in any rectangle that is formed by the intersection of two rows and two columns.\n",
            "\n",
            "But I'm not sure.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix by considering all possible submatrices of 2x2 size and then taking the maximum of those, and also considering the maximum number of 1s in any row, any column, or any submatrix of size 1xk or kx1.\n",
            "\n",
            "Wait, that might be a way.\n",
            "\n",
            "Wait, but the problem is that the submatrix can be any size, not just 2x2.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the solution is to find the maximum number of 1s in any submatrix of size up to 2x2, and then compare it with the maximum in rows and columns.\n",
            "\n",
            "But that would miss larger submatrices.\n",
            "\n",
            "Wait, perhaps the maximum can be found by considering the maximum in rows, the maximum in columns, and the maximum in any 2x2 square.\n",
            "\n",
            "But as I saw earlier, that's insufficient.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum is the maximum number of 1s in any rectangle, and that can be found by considering all possible pairs of rows and columns, but that's not feasible for large matrices.\n",
            "\n",
            "Wait, but perhaps there's a way to compute this in O(n + m) time, which is the maximum sum of n and m.\n",
            "\n",
            "Wait, but I'm not sure.\n",
            "\n",
            "Alternatively, perhaps the problem is to find the maximum sum of a submatrix in a binary matrix, which can be done by using the sliding window approach for each row, but I'm not sure.\n",
            "\n",
            "Wait, perhaps the solution is to use the standard method for finding the maximum rectangle in a histogram, but applied to the rows and columns.\n",
            "\n",
            "Wait, let me think about that.\n",
            "\n",
            "In the standard approach for the maximum rectangle in a histogram, each bar contributes to the height of a histogram, and then we find the maximum rectangle for each bar.\n",
            "\n",
            "So, perhaps for each row, we can compute the histogram of 1s and then find the maximum rectangle in that histogram, which would give the maximum number of 1s in a submatrix that includes that row.\n",
            "\n",
            "But then, the maximum submatrix could be formed by the intersection of two such histograms.\n",
            "\n",
            "But that would require considering all pairs of rows, which is O(n^2), which is not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, but perhaps the problem can be solved by considering that for each column, the maximum number of 1s in any submatrix that starts at that column and extends to the right, and then finding the maximum across all columns.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Alternatively, perhaps the solution is to realize that the maximum submatrix sum can be found by considering the maximum in any row, any column, or any 1x1, 1xk, kx1, or 2x2 submatrix.\n",
            "\n",
            "But I'm not sure.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any row, any column, any 1xk, any kx1, or any 2x2 square, and then take the maximum of all these.\n",
            "\n",
            "But I'm not sure if that would capture all possible submatrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the solution is to compute the maximum number of 1s in any row, the maximum in any column, the maximum in any pair of rows and columns, and then take the maximum.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Wait, perhaps the solution is to compute the maximum number of 1s in any row, the maximum in any column, and then for each possible pair of rows, compute the maximum number of 1s in any column that is common to both rows, and take the maximum.\n",
            "\n",
            "But again, for large matrices, this would be O(n^2 * m), which is not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the problem is to find the maximum number of 1s in any submatrix, and the solution is to find the maximum in any row, the maximum in any column, and the maximum in any 2x2 square, and then take the maximum of all these.\n",
            "\n",
            "But as I saw earlier, this is insufficient.\n",
            "\n",
            "So, perhaps the solution is to find the maximum number of 1s in any submatrix of size up to 2x2, and then compare it with the maximum in rows and columns.\n",
            "\n",
            "But that would miss larger submatrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix that is a rectangle of size 1x1, 1xk, kx1, or 2x2, and then take the maximum.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Hmm, perhaps I should look for an alternative approach.\n",
            "\n",
            "Wait, perhaps the problem can be solved by considering that the maximum submatrix sum is the maximum number of 1s in any rectangle, and that can be found by considering all possible pairs of rows and columns, but for 1e5 x 1e5 matrices, this is not feasible.\n",
            "\n",
            "So, perhaps the solution is to find an approach that runs in O(n + m) time.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum can be found by considering the maximum in any row, any column, and any pair of rows and columns, but I'm not sure.\n",
            "\n",
            "Wait, perhaps the solution is to use the sliding window approach for each row, but that's O(n*m), which is not feasible.\n",
            "\n",
            "Wait, but perhaps the problem can be reduced to considering the maximum in any row and any column, and then the maximum in any pair of rows and columns, but again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum is the maximum of the following:\n",
            "\n",
            "- The maximum number of 1s in any row.\n",
            "\n",
            "- The maximum number of 1s in any column.\n",
            "\n",
            "- The maximum number of 1s in any pair of rows and columns, which is the sum of the number of 1s in the rows between the two rows, and the number of 1s in the columns between the two columns.\n",
            "\n",
            "But this approach is O(n^2 * m), which is not feasible.\n",
            "\n",
            "Wait, but perhaps the maximum can be found by considering all possible pairs of rows and columns, but for large matrices, that's not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the solution is to find the maximum number of 1s in any row, the maximum in any column, and the maximum in any pair of rows and columns, but again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the solution is to compute the maximum number of 1s in any submatrix of size 1xk, kx1, 2x2, and then take the maximum.\n",
            "\n",
            "But I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps I should think differently.\n",
            "\n",
            "Suppose I have a binary matrix. The maximum submatrix sum is the maximum number of 1s in any submatrix.\n",
            "\n",
            "So, the problem reduces to finding the maximum number of 1s in any submatrix.\n",
            "\n",
            "So, perhaps the approach is to find the maximum number of 1s in any submatrix, which can be found by considering all possible pairs of rows and columns, but for 1e5 x 1e5 matrices, that's not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any row, the maximum in any column, and the maximum in any 2x2 square, and then take the maximum of all these.\n",
            "\n",
            "But as I saw earlier, that's insufficient.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum can be found by considering the maximum in any row, any column, and any pair of rows and columns, but again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps I should think about the problem differently. Maybe the maximum number of 1s in any submatrix can be found by considering the maximum in any row, the maximum in any column, and the maximum in any pair of rows and columns, but the way to compute the maximum in any pair of rows and columns is to find the maximum number of 1s in any column that is common to both rows.\n",
            "\n",
            "But again, for large matrices, this is not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the solution is to find the maximum number of 1s in any submatrix of size up to 2x2, and then take the maximum of all these.\n",
            "\n",
            "But again, this would miss larger submatrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum can be found by considering the maximum in any row, any column, and any 2x2 square, and then take the maximum of all these.\n",
            "\n",
            "But as I saw earlier, this is insufficient.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm, perhaps the solution is to find the maximum number of 1s in any submatrix, which can be done by considering the maximum in any row, the maximum in any column, and the maximum in any 2x2 square, and then take the maximum of all these.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Alternatively, perhaps the solution is to compute the maximum number of 1s in any submatrix of size 1xk, kx1, or 2x2, and then take the maximum of all these.\n",
            "\n",
            "But that would miss larger submatrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to compute the maximum number of 1s in any submatrix of size up to 2x2, and then take the maximum of all these.\n",
            "\n",
            "But that would miss larger submatrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix of size 1xk, kx1, or 2x2, and then take the maximum of all these.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum is the maximum number of 1s in any submatrix, which can be found by considering all possible pairs of rows and columns, but that's not feasible for large matrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to use the sliding window approach for each row, but that's O(n*m), which is not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any row, the maximum in any column, and then the maximum in any pair of rows and columns, and then take the maximum of all these.\n",
            "\n",
            "But again, for large matrices, that's not feasible.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix of size up to 2x2, and then take the maximum of all these.\n",
            "\n",
            "But that's insufficient.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum is the maximum number of 1s in any submatrix, which can be found by considering all possible pairs of rows and columns, but that's not feasible for large matrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix of size 1xk, kx1, or 2x2, and then take the maximum of all these.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix of size up to 2x2, and then compare it with the maximum in rows and columns.\n",
            "\n",
            "But again, that's insufficient.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to realize that the maximum submatrix sum is the maximum number of 1s in any submatrix, which can be found by considering all possible pairs of rows and columns, but that's not feasible for large matrices.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Wait, perhaps the solution is to find the maximum number of 1s in any submatrix of size up to 2x2, and then take the maximum of all these.\n",
            "\n",
            "But again, I'm not sure.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "Hmm.\n",
            "\n",
            "\n",
            "\n",
            "With blocking:\n",
            " I need to determine whether a given number is a perfect square or not. I have to write a Python function for this.\n",
            "\n",
            "Okay, let me think about this step by step.\n",
            "Alright, so I need to write a Python function called is_perfect_square that takes a number as input and returns True if it's a perfect square, False otherwise.\n",
            "\n",
            "First, I should think about what a perfect square is. A perfect square is an integer that is the square of another integer. For example, 16 is a perfect square because it's 4 squared.\n",
            "\n",
            "So, my function needs to determine if the input number is a square of some integer. How can I check that?\n",
            "\n",
            "One approach is to take the square root of the number and then see if that square root is an integer. Because if the square root is an integer, then the number is a perfect square.\n",
            "\n",
            "But how do I compute the square root in Python and check if it's an integer? I remember that the math module has a sqrt function, but it returns a float. So, for example, sqrt(16) returns 4.0.\n",
            "\n",
            "So, if I take the square root, then check if it is equal to an integer, that would indicate that the number is a perfect square.\n",
            "\n",
            "But how do I check if the square root is an integer? Well, if I cast it to an integer, and then square it again, it should equal the original number if it's a perfect square.\n",
            "\n",
            "So, for example, sqrt(16) is 4.0. Casting to int gives 4. Then, 4 squared is 16, which equals the original number, so it's a perfect square.\n",
            "\n",
            "But what about negative numbers? Because the square of a negative number is positive, but the square root of a negative number in Python would be a complex number. So, if the input is negative, we can immediately return False.\n",
            "\n",
            "So, first step: Check if the input is a non-negative integer. If it's negative, return False.\n",
            "\n",
            "Then, compute the square root. If the square root is an integer, return True; else, False.\n",
            "\n",
            "But how do I handle cases where the square root is not an integer but very close due to floating point precision? For example, numbers that are perfect squares but have a square root that's a very long decimal might cause issues when converted to an integer.\n",
            "\n",
            "For instance, 25.0 is exactly 5.0, but numbers like 25.0000000001 might be problematic. So, I should be careful with such cases.\n",
            "\n",
            "Hmm, so to avoid floating point inaccuracies, I can compute the square root, round it to the nearest integer, and then check if squaring it gives back the original number.\n",
            "\n",
            "But how precise should this be? Since in Python, the math.sqrt function returns a float, which has limited precision, but for integers, it should be precise up to a point.\n",
            "\n",
            "So, another approach: Compute the integer square root of the number and then square it to see if it equals the original number.\n",
            "\n",
            "I remember that Python has a math.isqrt function which returns the integer square root (the floor of the exact square root) for non-negative integers. So, for example, math.isqrt(16) returns 4, and math.isqrt(17) returns 4.\n",
            "\n",
            "So, the steps for the function could be:\n",
            "\n",
            "1. Check if the input is a non-negative integer. If not, return False.\n",
            "\n",
            "2. Compute the integer square root of the number using math.isqrt.\n",
            "\n",
            "3. Check if the square of this integer square root equals the original number.\n",
            "\n",
            "If all these steps pass, return True; else, False.\n",
            "\n",
            "But what about when the input is 0? Well, 0 is a perfect square because 0 squared is 0. So, the function should return True.\n",
            "\n",
            "So, putting it all together:\n",
            "\n",
            "Import math.\n",
            "\n",
            "Function is_perfect_square(n):\n",
            "\n",
            "- if n is negative, return False.\n",
            "\n",
            "- if n is 0, return True.\n",
            "\n",
            "- compute s = math.isqrt(n)\n",
            "\n",
            "- if s * s == n, return True.\n",
            "\n",
            "- else, return False.\n",
            "\n",
            "But what about when n is a very large number? Does math.isqrt handle that? I think it does, as it's implemented in Python.\n",
            "\n",
            "Let me test this logic with some examples.\n",
            "\n",
            "Test case 1: n = 16\n",
            "\n",
            "s = math.isqrt(16) = 4\n",
            "\n",
            "4*4 = 16, so return True.\n",
            "\n",
            "Test case 2: n = 15\n",
            "\n",
            "s = math.isqrt(15) = 3\n",
            "\n",
            "3*3 = 9 !=15, so return False.\n",
            "\n",
            "Test case 3: n = 0\n",
            "\n",
            "return True.\n",
            "\n",
            "Test case 4: n = 1\n",
            "\n",
            "s =1, 1*1=1, return True.\n",
            "\n",
            "Test case 5: n = 2\n",
            "\n",
            "s=1, 1*1=1 !=2, return False.\n",
            "\n",
            "Test case 6: n = 25\n",
            "\n",
            "s=5, 5*5=25, return True.\n",
            "\n",
            "Test case 7: n = 26\n",
            "\n",
            "s=5, 5*5=25 !=26, return False.\n",
            "\n",
            "Test case 8: n = 25.0\n",
            "\n",
            "Well, in Python, math.sqrt(25.0) is 5.0, and math.isqrt(25.0) is 5. So, s=5, 5*5=25, which is equal to 25. So, returns True.\n",
            "\n",
            "But what if n is passed as a float that is an integer, like 25.0?\n",
            "\n",
            "Does the function correctly return True?\n",
            "\n",
            "In the function, the first check is if n is negative. If n is 25.0, it's not negative, so it proceeds. Then, math.isqrt(n) is called. But math.isqrt expects an integer. So, if n is a float, say 25.0, math.isqrt will throw an error.\n",
            "\n",
            "Oh, that's a problem. So, in the function, n should be an integer. So, how can I handle cases where n is passed as a float, but is actually an integer?\n",
            "\n",
            "So, in the function, I should first check if n is an integer. So, how to do that?\n",
            "\n",
            "In Python, I can check if n is an integer by seeing if n is equal to int(n) and n >=0.\n",
            "\n",
            "So, the function should be modified to:\n",
            "\n",
            "def is_perfect_square(n):\n",
            "\n",
            "    # Check if n is an integer and non-negative\n",
            "\n",
            "    if not isinstance(n, int) or n <0:\n",
            "\n",
            "        return False\n",
            "\n",
            "    # Compute integer square root\n",
            "\n",
            "    s = math.isqrt(n)\n",
            "\n",
            "    return s * s == n\n",
            "\n",
            "Yes, that should handle cases where n is passed as a float that is an integer.\n",
            "\n",
            "For example, n =25.0 would be considered an integer, so the function proceeds. s is 5, 5*5=25, so returns True.\n",
            "\n",
            "So, the function now should handle all cases.\n",
            "\n",
            "Another test case: n =2.5, which is not integer, returns False.\n",
            "\n",
            "Another test case: n = -3, returns False.\n",
            "\n",
            "n=1, returns True.\n",
            "\n",
            "n=0, returns True.\n",
            "\n",
            "n=16, returns True.\n",
            "\n",
            "n=25.0, returns True.\n",
            "\n",
            "n=25, returns True.\n",
            "\n",
            "n=26, returns False.\n",
            "\n",
            "n=25.5, returns False.\n",
            "\n",
            "n=1.25, returns False.\n",
            "\n",
            "So, I think this should cover all the cases.\n",
            "\n",
            "Another edge case: n=1.0.\n",
            "\n",
            "math.isqrt(1.0) is 1, 1*1=1, so returns True.\n",
            "\n",
            "So, the function should correctly handle that.\n",
            "\n",
            "Another test case: n=2^30, which is 1073741824.\n",
            "\n",
            "s = math.isqrt(1073741824) should be 32768, since 32768^2 is 1073741824. So, returns True.\n",
            "\n",
            "What about n=32768^2? It should return True.\n",
            "\n",
            "So, I think this function should work.\n",
            "\n",
            "So, the steps are:\n",
            "\n",
            "1. Check if the input is an integer and non-negative.\n",
            "\n",
            "2. Compute the integer square root.\n",
            "\n",
            "3. Check if the square of the integer square root equals the original number.\n",
            "\n",
            "If all these are true, return True; else, False.\n",
            "\n",
            "So, the Python function should be written accordingly.\n",
            "</think>\n",
            "\n",
            "To solve this problem, we need to determine whether a given number is a perfect square. A perfect square is an integer that is the square of another integer. For example, 16 is a perfect square because it is 4 squared.\n",
            "\n",
            "### Approach\n",
            "1. **Check if the input is a non-negative integer**: If the input is a negative number or a non-integer, it cannot be a perfect square, so we return False.\n",
            "2. **Compute the integer square root**: Using Python's `math.isqrt` function, which returns the largest integer less than or equal to the exact square root of the number.\n",
            "3. **Check if the square of the integer square root equals the original number**: If the square of the integer square root equals the original number, it means the original number is a perfect square.\n",
            "\n",
            "### Solution Code\n",
            "```python\n",
            "import math\n",
            "\n",
            "def is_perfect_square(n):\n",
            "    if not isinstance(n, int) or n < 0:\n",
            "        return False\n",
            "    s = math.isqrt(n)\n",
            "    return s * s == n\n",
            "```\n",
            "\n",
            "### Explanation\n",
            "1. **Input Validation**: The function first checks if the input `n` is a non-negative integer. If not, it returns False.\n",
            "2. **Integer Square Root Calculation**: Using `math.isqrt(n)`, we compute the integer square root of `n`. This function returns the largest integer less than or equal to the exact square root of `n`.\n",
            "3. **Perfect Square Check**: We then check if squaring the integer square root gives back the original number. If it does, `n` is a perfect square, and the function returns True. Otherwise, it returns False.\n",
            "\n",
            "This approach efficiently handles all edge cases, including very large numbers and floating-point inputs that are effectively integers.\n",
            "\n",
            "Blocked word counts in unblocked response:\n",
            "{'wait': 52, 'alternatively': 14, 'perhaps': 70, 'maybe': 1}\n",
            "\n",
            "Blocked word counts in blocked response:\n",
            "{'wait': 0, 'alternatively': 0, 'perhaps': 0, 'maybe': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YTsPsFyVZj5Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}